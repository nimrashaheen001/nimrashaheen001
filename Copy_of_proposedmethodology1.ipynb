{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNAvCZn+VhlLYRtwPdzzgam",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nimrashaheen001/nimrashaheen001/blob/main/Copy_of_proposedmethodology1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Example: copy your project folder from Drive to Colab\n",
        "!cp -r \"/content/drive/MyDrive/project_TransUNet_modified.zip\" /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ApT25kE3bTo",
        "outputId": "f9a22c14-05bc-404a-b30c-687f91c51e59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZTo4bb6mENx",
        "outputId": "a541ba78-76b8-4c40-8dff-53f3e7287215"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction complete.\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = '/content/project_TransUNet_modified.zip'\n",
        "extract_path = '/content/project_TransUNet'\n",
        "\n",
        "if zipfile.is_zipfile(zip_path):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(\"Extraction complete.\")\n",
        "else:\n",
        "    print(\"❌ The file is not a valid zip file.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ml-collections"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80TWnE-HmLDf",
        "outputId": "aa2cc6d4-90fc-4555-ba23-02a7aa4c6644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ml-collections\n",
            "  Downloading ml_collections-1.1.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from ml-collections) (1.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from ml-collections) (6.0.2)\n",
            "Downloading ml_collections-1.1.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ml-collections\n",
            "Successfully installed ml-collections-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3_gjKvwmOWz",
        "outputId": "71cc14d0-fdc0-485f-8d75-701959da8e63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from tensorboardX) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboardX) (25.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.12/dist-packages (from tensorboardX) (5.29.5)\n",
            "Downloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/87.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install medpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObErUrNwmRZg",
        "outputId": "e981ed96-3ab0-414c-e779-8b27ab5af15d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting medpy\n",
            "  Downloading medpy-0.5.2.tar.gz (156 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/156.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.3/156.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.12/dist-packages (from medpy) (1.16.1)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from medpy) (2.0.2)\n",
            "Collecting SimpleITK>=2.1 (from medpy)\n",
            "  Downloading simpleitk-2.5.2-cp311-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.2 kB)\n",
            "Downloading simpleitk-2.5.2-cp311-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (52.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: medpy\n",
            "  Building wheel for medpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for medpy: filename=MedPy-0.5.2-py3-none-any.whl size=224710 sha256=afbc88d1687ac20045e003ea32e51f10d77f4569029da9f86248976bf6f65adc\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/5a/f8/b3def53b9c2133d2f8698ea2173bb5df63bd8e761ce8e9aec9\n",
            "Successfully built medpy\n",
            "Installing collected packages: SimpleITK, medpy\n",
            "Successfully installed SimpleITK-2.5.2 medpy-0.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fileinput\n",
        "\n",
        "config_path = \"/content/project_TransUNet/project_TransUNet/TransUNet/networks/vit_seg_configs.py\"\n",
        "new_path = \"/content/project_TransUNet/project_TransUNet/model/vit_checkpoint/imagenet21k/R50+ViT-B_16.npz\"\n",
        "\n",
        "for line in fileinput.input(config_path, inplace=True):\n",
        "    if \"pretrained_path\" in line:\n",
        "        print(f'    config_vit.pretrained_path = \"{new_path}\"')\n",
        "    else:\n",
        "        print(line, end=\"\")"
      ],
      "metadata": {
        "id": "dTIaXocmmURq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!touch /content/project_TransUNet/project_TransUNet/TransUNet/datasets/__init__.py"
      ],
      "metadata": {
        "id": "JhlJgwFPtz4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/project_TransUNet/project_TransUNet/data/Synapse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CM5YB1KPuSEa",
        "outputId": "03cd6077-0e89-43af-a9a4-26e1cb69e2bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_vol_h5  train_npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KwYNP4oDunUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/project_TransUNet/project_TransUNet/TransUNet/lists/lists_Synapse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfsyeUxEuqBI",
        "outputId": "c1314bea-c74d-4a8b-f9a6-c920d79b55d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all.lst  test_vol.txt  train.txt  val.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/project_TransUNet/project_TransUNet/TransUNet\")"
      ],
      "metadata": {
        "id": "npqsoPNAyegY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/project_TransUNet/project_TransUNet/TransUNet/train.py \\\n",
        "    --root_path /content/project_TransUNet/project_TransUNet/data/Synapse/train_npz \\\n",
        "    --list_dir /content/project_TransUNet/project_TransUNet/TransUNet/lists/lists_Synapse"
      ],
      "metadata": {
        "id": "0dLoPe22t6j3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n_jhW3GusVKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/project_TransUNet/project_TransUNet/TransUNet/train.py \\\n",
        "  --dataset Synapse \\\n",
        "  --vit_name R50-ViT-B_16 \\\n",
        "  --root_path /content/project_TransUNet/data/Synapse \\\n",
        "  --vit_patches_size 16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-wwmCddmXye",
        "outputId": "ecb2ff9a-b289-48b3-8f53-d292b4c78895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "iteration 6105 : loss : 0.025827, loss_ce: 0.007954\n",
            "iteration 6106 : loss : 0.031587, loss_ce: 0.013254\n",
            "iteration 6107 : loss : 0.024314, loss_ce: 0.009614\n",
            "iteration 6108 : loss : 0.040159, loss_ce: 0.014695\n",
            "iteration 6109 : loss : 0.030026, loss_ce: 0.008623\n",
            "iteration 6110 : loss : 0.023852, loss_ce: 0.010578\n",
            "iteration 6111 : loss : 0.028061, loss_ce: 0.010557\n",
            "iteration 6112 : loss : 0.026018, loss_ce: 0.008282\n",
            "iteration 6113 : loss : 0.048740, loss_ce: 0.006858\n",
            "iteration 6114 : loss : 0.030809, loss_ce: 0.012479\n",
            "iteration 6115 : loss : 0.028661, loss_ce: 0.008312\n",
            "iteration 6116 : loss : 0.026979, loss_ce: 0.007090\n",
            "iteration 6117 : loss : 0.031858, loss_ce: 0.010117\n",
            "iteration 6118 : loss : 0.070788, loss_ce: 0.007305\n",
            "iteration 6119 : loss : 0.029076, loss_ce: 0.008931\n",
            "iteration 6120 : loss : 0.029632, loss_ce: 0.013251\n",
            "iteration 6121 : loss : 0.040268, loss_ce: 0.008118\n",
            "iteration 6122 : loss : 0.073115, loss_ce: 0.006848\n",
            "iteration 6123 : loss : 0.025554, loss_ce: 0.006945\n",
            "iteration 6124 : loss : 0.027074, loss_ce: 0.006857\n",
            "iteration 6125 : loss : 0.028900, loss_ce: 0.007790\n",
            "iteration 6126 : loss : 0.027856, loss_ce: 0.009906\n",
            "iteration 6127 : loss : 0.028106, loss_ce: 0.007621\n",
            "iteration 6128 : loss : 0.031279, loss_ce: 0.007988\n",
            "iteration 6129 : loss : 0.029348, loss_ce: 0.012123\n",
            "iteration 6130 : loss : 0.030264, loss_ce: 0.007441\n",
            "iteration 6131 : loss : 0.028822, loss_ce: 0.012929\n",
            "iteration 6132 : loss : 0.032191, loss_ce: 0.009513\n",
            "iteration 6133 : loss : 0.032438, loss_ce: 0.011854\n",
            "iteration 6134 : loss : 0.027682, loss_ce: 0.009020\n",
            "iteration 6135 : loss : 0.030370, loss_ce: 0.008436\n",
            "iteration 6136 : loss : 0.033567, loss_ce: 0.011943\n",
            "iteration 6137 : loss : 0.062679, loss_ce: 0.010104\n",
            "iteration 6138 : loss : 0.026003, loss_ce: 0.009500\n",
            "iteration 6139 : loss : 0.078787, loss_ce: 0.010180\n",
            "iteration 6140 : loss : 0.026892, loss_ce: 0.010987\n",
            "iteration 6141 : loss : 0.024016, loss_ce: 0.007487\n",
            "iteration 6142 : loss : 0.034197, loss_ce: 0.016843\n",
            " 55%|██████████████▉            | 83/150 [2:29:49<2:00:55, 108.29s/it]iteration 6143 : loss : 0.038223, loss_ce: 0.009614\n",
            "iteration 6144 : loss : 0.025027, loss_ce: 0.008799\n",
            "iteration 6145 : loss : 0.030665, loss_ce: 0.006338\n",
            "iteration 6146 : loss : 0.029161, loss_ce: 0.008186\n",
            "iteration 6147 : loss : 0.030520, loss_ce: 0.014280\n",
            "iteration 6148 : loss : 0.028314, loss_ce: 0.011334\n",
            "iteration 6149 : loss : 0.029319, loss_ce: 0.011236\n",
            "iteration 6150 : loss : 0.035667, loss_ce: 0.009013\n",
            "iteration 6151 : loss : 0.028164, loss_ce: 0.009367\n",
            "iteration 6152 : loss : 0.041277, loss_ce: 0.011849\n",
            "iteration 6153 : loss : 0.028305, loss_ce: 0.013309\n",
            "iteration 6154 : loss : 0.026033, loss_ce: 0.006485\n",
            "iteration 6155 : loss : 0.030002, loss_ce: 0.010914\n",
            "iteration 6156 : loss : 0.037818, loss_ce: 0.009740\n",
            "iteration 6157 : loss : 0.029884, loss_ce: 0.012271\n",
            "iteration 6158 : loss : 0.034002, loss_ce: 0.008527\n",
            "iteration 6159 : loss : 0.027317, loss_ce: 0.007568\n",
            "iteration 6160 : loss : 0.033941, loss_ce: 0.010111\n",
            "iteration 6161 : loss : 0.028114, loss_ce: 0.012500\n",
            "iteration 6162 : loss : 0.025308, loss_ce: 0.008068\n",
            "iteration 6163 : loss : 0.026056, loss_ce: 0.008392\n",
            "iteration 6164 : loss : 0.022490, loss_ce: 0.006949\n",
            "iteration 6165 : loss : 0.024826, loss_ce: 0.005782\n",
            "iteration 6166 : loss : 0.033162, loss_ce: 0.013648\n",
            "iteration 6167 : loss : 0.033314, loss_ce: 0.013689\n",
            "iteration 6168 : loss : 0.025976, loss_ce: 0.012337\n",
            "iteration 6169 : loss : 0.075296, loss_ce: 0.006587\n",
            "iteration 6170 : loss : 0.043536, loss_ce: 0.006469\n",
            "iteration 6171 : loss : 0.027061, loss_ce: 0.008882\n",
            "iteration 6172 : loss : 0.028395, loss_ce: 0.008988\n",
            "iteration 6173 : loss : 0.078185, loss_ce: 0.008582\n",
            "iteration 6174 : loss : 0.078323, loss_ce: 0.012078\n",
            "iteration 6175 : loss : 0.029636, loss_ce: 0.010493\n",
            "iteration 6176 : loss : 0.023402, loss_ce: 0.005208\n",
            "iteration 6177 : loss : 0.033935, loss_ce: 0.015889\n",
            "iteration 6178 : loss : 0.027892, loss_ce: 0.008719\n",
            "iteration 6179 : loss : 0.036420, loss_ce: 0.011935\n",
            "iteration 6180 : loss : 0.026595, loss_ce: 0.009355\n",
            "iteration 6181 : loss : 0.033733, loss_ce: 0.011080\n",
            "iteration 6182 : loss : 0.027221, loss_ce: 0.010599\n",
            "iteration 6183 : loss : 0.023700, loss_ce: 0.009596\n",
            "iteration 6184 : loss : 0.077151, loss_ce: 0.008516\n",
            "iteration 6185 : loss : 0.034567, loss_ce: 0.014497\n",
            "iteration 6186 : loss : 0.029424, loss_ce: 0.008458\n",
            "iteration 6187 : loss : 0.041167, loss_ce: 0.010283\n",
            "iteration 6188 : loss : 0.030081, loss_ce: 0.008594\n",
            "iteration 6189 : loss : 0.030056, loss_ce: 0.013396\n",
            "iteration 6190 : loss : 0.024458, loss_ce: 0.011551\n",
            "iteration 6191 : loss : 0.024971, loss_ce: 0.006978\n",
            "iteration 6192 : loss : 0.028102, loss_ce: 0.011651\n",
            "iteration 6193 : loss : 0.080193, loss_ce: 0.004261\n",
            "iteration 6194 : loss : 0.025457, loss_ce: 0.007739\n",
            "iteration 6195 : loss : 0.030246, loss_ce: 0.009236\n",
            "iteration 6196 : loss : 0.035441, loss_ce: 0.008302\n",
            "iteration 6197 : loss : 0.032703, loss_ce: 0.011643\n",
            "iteration 6198 : loss : 0.025730, loss_ce: 0.006214\n",
            "iteration 6199 : loss : 0.030565, loss_ce: 0.008560\n",
            "iteration 6200 : loss : 0.033978, loss_ce: 0.011915\n",
            "iteration 6201 : loss : 0.078322, loss_ce: 0.009183\n",
            "iteration 6202 : loss : 0.033835, loss_ce: 0.008533\n",
            "iteration 6203 : loss : 0.032975, loss_ce: 0.009668\n",
            "iteration 6204 : loss : 0.034112, loss_ce: 0.013723\n",
            "iteration 6205 : loss : 0.055359, loss_ce: 0.009413\n",
            "iteration 6206 : loss : 0.027302, loss_ce: 0.009749\n",
            "iteration 6207 : loss : 0.032483, loss_ce: 0.009033\n",
            "iteration 6208 : loss : 0.035424, loss_ce: 0.010139\n",
            "iteration 6209 : loss : 0.029466, loss_ce: 0.009951\n",
            "iteration 6210 : loss : 0.033542, loss_ce: 0.015191\n",
            "iteration 6211 : loss : 0.034773, loss_ce: 0.015340\n",
            "iteration 6212 : loss : 0.038462, loss_ce: 0.014709\n",
            "iteration 6213 : loss : 0.033226, loss_ce: 0.013874\n",
            "iteration 6214 : loss : 0.025207, loss_ce: 0.008267\n",
            "iteration 6215 : loss : 0.026882, loss_ce: 0.009764\n",
            "iteration 6216 : loss : 0.088203, loss_ce: 0.009320\n",
            " 56%|███████████████            | 84/150 [2:31:37<1:58:45, 107.97s/it]iteration 6217 : loss : 0.031726, loss_ce: 0.009431\n",
            "iteration 6218 : loss : 0.089266, loss_ce: 0.006472\n",
            "iteration 6219 : loss : 0.037673, loss_ce: 0.012697\n",
            "iteration 6220 : loss : 0.035294, loss_ce: 0.011453\n",
            "iteration 6221 : loss : 0.033881, loss_ce: 0.008428\n",
            "iteration 6222 : loss : 0.039861, loss_ce: 0.013037\n",
            "iteration 6223 : loss : 0.037838, loss_ce: 0.014534\n",
            "iteration 6224 : loss : 0.038899, loss_ce: 0.007651\n",
            "iteration 6225 : loss : 0.036283, loss_ce: 0.015865\n",
            "iteration 6226 : loss : 0.038974, loss_ce: 0.015527\n",
            "iteration 6227 : loss : 0.038383, loss_ce: 0.016339\n",
            "iteration 6228 : loss : 0.034136, loss_ce: 0.014955\n",
            "iteration 6229 : loss : 0.035816, loss_ce: 0.008254\n",
            "iteration 6230 : loss : 0.035417, loss_ce: 0.016156\n",
            "iteration 6231 : loss : 0.040616, loss_ce: 0.007606\n",
            "iteration 6232 : loss : 0.033036, loss_ce: 0.010850\n",
            "iteration 6233 : loss : 0.036285, loss_ce: 0.010856\n",
            "iteration 6234 : loss : 0.030097, loss_ce: 0.007532\n",
            "iteration 6235 : loss : 0.034837, loss_ce: 0.019766\n",
            "iteration 6236 : loss : 0.030883, loss_ce: 0.013157\n",
            "iteration 6237 : loss : 0.029459, loss_ce: 0.009078\n",
            "iteration 6238 : loss : 0.033487, loss_ce: 0.009202\n",
            "iteration 6239 : loss : 0.040863, loss_ce: 0.012016\n",
            "iteration 6240 : loss : 0.032134, loss_ce: 0.010739\n",
            "iteration 6241 : loss : 0.030597, loss_ce: 0.014369\n",
            "iteration 6242 : loss : 0.028818, loss_ce: 0.009066\n",
            "iteration 6243 : loss : 0.036520, loss_ce: 0.016202\n",
            "iteration 6244 : loss : 0.032815, loss_ce: 0.012321\n",
            "iteration 6245 : loss : 0.035723, loss_ce: 0.008683\n",
            "iteration 6246 : loss : 0.027920, loss_ce: 0.011485\n",
            "iteration 6247 : loss : 0.035735, loss_ce: 0.009060\n",
            "iteration 6248 : loss : 0.051273, loss_ce: 0.006597\n",
            "iteration 6249 : loss : 0.036973, loss_ce: 0.012587\n",
            "iteration 6250 : loss : 0.048728, loss_ce: 0.009629\n",
            "iteration 6251 : loss : 0.037066, loss_ce: 0.011211\n",
            "iteration 6252 : loss : 0.040362, loss_ce: 0.014810\n",
            "iteration 6253 : loss : 0.035282, loss_ce: 0.010206\n",
            "iteration 6254 : loss : 0.029634, loss_ce: 0.009431\n",
            "iteration 6255 : loss : 0.080133, loss_ce: 0.009184\n",
            "iteration 6256 : loss : 0.033021, loss_ce: 0.012637\n",
            "iteration 6257 : loss : 0.048140, loss_ce: 0.008498\n",
            "iteration 6258 : loss : 0.030576, loss_ce: 0.008678\n",
            "iteration 6259 : loss : 0.044381, loss_ce: 0.013780\n",
            "iteration 6260 : loss : 0.031494, loss_ce: 0.012863\n",
            "iteration 6261 : loss : 0.031303, loss_ce: 0.012844\n",
            "iteration 6262 : loss : 0.042936, loss_ce: 0.011474\n",
            "iteration 6263 : loss : 0.036128, loss_ce: 0.009752\n",
            "iteration 6264 : loss : 0.080434, loss_ce: 0.009780\n",
            "iteration 6265 : loss : 0.033207, loss_ce: 0.013873\n",
            "iteration 6266 : loss : 0.036365, loss_ce: 0.011201\n",
            "iteration 6267 : loss : 0.035904, loss_ce: 0.010172\n",
            "iteration 6268 : loss : 0.033586, loss_ce: 0.010962\n",
            "iteration 6269 : loss : 0.036383, loss_ce: 0.015557\n",
            "iteration 6270 : loss : 0.031933, loss_ce: 0.010192\n",
            "iteration 6271 : loss : 0.026827, loss_ce: 0.009906\n",
            "iteration 6272 : loss : 0.025716, loss_ce: 0.007366\n",
            "iteration 6273 : loss : 0.030025, loss_ce: 0.010516\n",
            "iteration 6274 : loss : 0.031309, loss_ce: 0.017821\n",
            "iteration 6275 : loss : 0.027216, loss_ce: 0.007824\n",
            "iteration 6276 : loss : 0.028622, loss_ce: 0.008228\n",
            "iteration 6277 : loss : 0.027754, loss_ce: 0.005779\n",
            "iteration 6278 : loss : 0.082548, loss_ce: 0.009629\n",
            "iteration 6279 : loss : 0.029428, loss_ce: 0.011506\n",
            "iteration 6280 : loss : 0.032735, loss_ce: 0.008313\n",
            "iteration 6281 : loss : 0.039116, loss_ce: 0.006074\n",
            "iteration 6282 : loss : 0.030882, loss_ce: 0.009829\n",
            "iteration 6283 : loss : 0.029948, loss_ce: 0.009309\n",
            "iteration 6284 : loss : 0.125559, loss_ce: 0.004269\n",
            "iteration 6285 : loss : 0.028340, loss_ce: 0.010080\n",
            "iteration 6286 : loss : 0.036908, loss_ce: 0.007428\n",
            "iteration 6287 : loss : 0.026350, loss_ce: 0.008318\n",
            "iteration 6288 : loss : 0.035610, loss_ce: 0.010234\n",
            "iteration 6289 : loss : 0.031320, loss_ce: 0.010647\n",
            "iteration 6290 : loss : 0.031201, loss_ce: 0.010122\n",
            " 57%|███████████████▎           | 85/150 [2:33:25<1:57:15, 108.23s/it]iteration 6291 : loss : 0.033945, loss_ce: 0.014933\n",
            "iteration 6292 : loss : 0.028835, loss_ce: 0.009413\n",
            "iteration 6293 : loss : 0.033567, loss_ce: 0.005907\n",
            "iteration 6294 : loss : 0.034879, loss_ce: 0.015255\n",
            "iteration 6295 : loss : 0.039465, loss_ce: 0.010136\n",
            "iteration 6296 : loss : 0.067276, loss_ce: 0.014238\n",
            "iteration 6297 : loss : 0.029985, loss_ce: 0.011948\n",
            "iteration 6298 : loss : 0.033056, loss_ce: 0.008929\n",
            "iteration 6299 : loss : 0.027756, loss_ce: 0.005781\n",
            "iteration 6300 : loss : 0.028481, loss_ce: 0.009475\n",
            "iteration 6301 : loss : 0.040614, loss_ce: 0.011087\n",
            "iteration 6302 : loss : 0.032799, loss_ce: 0.008715\n",
            "iteration 6303 : loss : 0.027315, loss_ce: 0.007153\n",
            "iteration 6304 : loss : 0.039265, loss_ce: 0.006196\n",
            "iteration 6305 : loss : 0.028120, loss_ce: 0.009130\n",
            "iteration 6306 : loss : 0.078584, loss_ce: 0.005983\n",
            "iteration 6307 : loss : 0.032697, loss_ce: 0.013163\n",
            "iteration 6308 : loss : 0.036790, loss_ce: 0.013594\n",
            "iteration 6309 : loss : 0.044325, loss_ce: 0.009010\n",
            "iteration 6310 : loss : 0.031918, loss_ce: 0.013508\n",
            "iteration 6311 : loss : 0.035418, loss_ce: 0.010989\n",
            "iteration 6312 : loss : 0.031974, loss_ce: 0.014819\n",
            "iteration 6313 : loss : 0.048951, loss_ce: 0.006307\n",
            "iteration 6314 : loss : 0.025309, loss_ce: 0.010321\n",
            "iteration 6315 : loss : 0.051014, loss_ce: 0.013078\n",
            "iteration 6316 : loss : 0.029300, loss_ce: 0.010274\n",
            "iteration 6317 : loss : 0.032585, loss_ce: 0.015264\n",
            "iteration 6318 : loss : 0.029860, loss_ce: 0.009924\n",
            "iteration 6319 : loss : 0.033813, loss_ce: 0.007588\n",
            "iteration 6320 : loss : 0.032482, loss_ce: 0.012170\n",
            "iteration 6321 : loss : 0.030077, loss_ce: 0.007743\n",
            "iteration 6322 : loss : 0.032941, loss_ce: 0.013418\n",
            "iteration 6323 : loss : 0.034732, loss_ce: 0.010644\n",
            "iteration 6324 : loss : 0.031714, loss_ce: 0.007420\n",
            "iteration 6325 : loss : 0.026219, loss_ce: 0.007968\n",
            "iteration 6326 : loss : 0.038530, loss_ce: 0.007780\n",
            "iteration 6327 : loss : 0.032640, loss_ce: 0.006570\n",
            "iteration 6328 : loss : 0.030966, loss_ce: 0.011825\n",
            "iteration 6329 : loss : 0.036598, loss_ce: 0.007798\n",
            "iteration 6330 : loss : 0.027460, loss_ce: 0.008633\n",
            "iteration 6331 : loss : 0.032605, loss_ce: 0.015896\n",
            "iteration 6332 : loss : 0.033890, loss_ce: 0.015162\n",
            "iteration 6333 : loss : 0.029011, loss_ce: 0.009541\n",
            "iteration 6334 : loss : 0.023980, loss_ce: 0.007383\n",
            "iteration 6335 : loss : 0.028920, loss_ce: 0.008958\n",
            "iteration 6336 : loss : 0.028359, loss_ce: 0.009643\n",
            "iteration 6337 : loss : 0.028620, loss_ce: 0.013931\n",
            "iteration 6338 : loss : 0.027723, loss_ce: 0.004736\n",
            "iteration 6339 : loss : 0.079355, loss_ce: 0.007608\n",
            "iteration 6340 : loss : 0.036833, loss_ce: 0.011155\n",
            "iteration 6341 : loss : 0.036338, loss_ce: 0.012583\n",
            "iteration 6342 : loss : 0.043232, loss_ce: 0.012272\n",
            "iteration 6343 : loss : 0.030516, loss_ce: 0.012766\n",
            "iteration 6344 : loss : 0.035316, loss_ce: 0.008673\n",
            "iteration 6345 : loss : 0.029431, loss_ce: 0.011107\n",
            "iteration 6346 : loss : 0.026739, loss_ce: 0.006842\n",
            "iteration 6347 : loss : 0.032297, loss_ce: 0.010598\n",
            "iteration 6348 : loss : 0.040567, loss_ce: 0.010797\n",
            "iteration 6349 : loss : 0.112452, loss_ce: 0.007326\n",
            "iteration 6350 : loss : 0.036216, loss_ce: 0.012953\n",
            "iteration 6351 : loss : 0.041902, loss_ce: 0.010009\n",
            "iteration 6352 : loss : 0.033428, loss_ce: 0.009807\n",
            "iteration 6353 : loss : 0.041508, loss_ce: 0.011313\n",
            "iteration 6354 : loss : 0.042681, loss_ce: 0.012688\n",
            "iteration 6355 : loss : 0.031608, loss_ce: 0.010235\n",
            "iteration 6356 : loss : 0.032077, loss_ce: 0.010900\n",
            "iteration 6357 : loss : 0.034386, loss_ce: 0.007301\n",
            "iteration 6358 : loss : 0.035187, loss_ce: 0.007965\n",
            "iteration 6359 : loss : 0.034014, loss_ce: 0.016083\n",
            "iteration 6360 : loss : 0.036839, loss_ce: 0.016690\n",
            "iteration 6361 : loss : 0.036841, loss_ce: 0.013778\n",
            "iteration 6362 : loss : 0.035955, loss_ce: 0.014842\n",
            "iteration 6363 : loss : 0.033210, loss_ce: 0.012704\n",
            "iteration 6364 : loss : 0.034536, loss_ce: 0.005843\n",
            " 57%|███████████████▍           | 86/150 [2:35:15<1:55:48, 108.57s/it]iteration 6365 : loss : 0.048112, loss_ce: 0.011502\n",
            "iteration 6366 : loss : 0.034796, loss_ce: 0.010227\n",
            "iteration 6367 : loss : 0.032399, loss_ce: 0.009108\n",
            "iteration 6368 : loss : 0.034424, loss_ce: 0.015059\n",
            "iteration 6369 : loss : 0.033046, loss_ce: 0.014791\n",
            "iteration 6370 : loss : 0.036688, loss_ce: 0.013177\n",
            "iteration 6371 : loss : 0.030059, loss_ce: 0.011343\n",
            "iteration 6372 : loss : 0.031994, loss_ce: 0.012882\n",
            "iteration 6373 : loss : 0.026391, loss_ce: 0.007117\n",
            "iteration 6374 : loss : 0.045322, loss_ce: 0.010633\n",
            "iteration 6375 : loss : 0.041064, loss_ce: 0.011125\n",
            "iteration 6376 : loss : 0.081739, loss_ce: 0.006971\n",
            "iteration 6377 : loss : 0.034545, loss_ce: 0.013044\n",
            "iteration 6378 : loss : 0.080816, loss_ce: 0.004992\n",
            "iteration 6379 : loss : 0.037949, loss_ce: 0.011888\n",
            "iteration 6380 : loss : 0.080139, loss_ce: 0.008770\n",
            "iteration 6381 : loss : 0.027723, loss_ce: 0.008776\n",
            "iteration 6382 : loss : 0.036455, loss_ce: 0.021003\n",
            "iteration 6383 : loss : 0.083293, loss_ce: 0.009800\n",
            "iteration 6384 : loss : 0.023732, loss_ce: 0.007502\n",
            "iteration 6385 : loss : 0.035054, loss_ce: 0.015392\n",
            "iteration 6386 : loss : 0.035186, loss_ce: 0.011254\n",
            "iteration 6387 : loss : 0.030671, loss_ce: 0.010661\n",
            "iteration 6388 : loss : 0.036019, loss_ce: 0.009832\n",
            "iteration 6389 : loss : 0.028718, loss_ce: 0.010921\n",
            "iteration 6390 : loss : 0.025396, loss_ce: 0.006289\n",
            "iteration 6391 : loss : 0.037759, loss_ce: 0.012213\n",
            "iteration 6392 : loss : 0.041600, loss_ce: 0.008871\n",
            "iteration 6393 : loss : 0.030942, loss_ce: 0.011860\n",
            "iteration 6394 : loss : 0.040372, loss_ce: 0.008479\n",
            "iteration 6395 : loss : 0.030717, loss_ce: 0.008589\n",
            "iteration 6396 : loss : 0.027483, loss_ce: 0.009240\n",
            "iteration 6397 : loss : 0.031952, loss_ce: 0.009634\n",
            "iteration 6398 : loss : 0.028680, loss_ce: 0.010549\n",
            "iteration 6399 : loss : 0.027935, loss_ce: 0.011448\n",
            "iteration 6400 : loss : 0.129791, loss_ce: 0.004864\n",
            "iteration 6401 : loss : 0.035632, loss_ce: 0.013080\n",
            "iteration 6402 : loss : 0.038310, loss_ce: 0.009694\n",
            "iteration 6403 : loss : 0.027498, loss_ce: 0.010422\n",
            "iteration 6404 : loss : 0.077635, loss_ce: 0.005897\n",
            "iteration 6405 : loss : 0.027766, loss_ce: 0.011913\n",
            "iteration 6406 : loss : 0.034858, loss_ce: 0.006591\n",
            "iteration 6407 : loss : 0.038327, loss_ce: 0.018802\n",
            "iteration 6408 : loss : 0.031776, loss_ce: 0.012101\n",
            "iteration 6409 : loss : 0.039636, loss_ce: 0.016853\n",
            "iteration 6410 : loss : 0.031489, loss_ce: 0.008651\n",
            "iteration 6411 : loss : 0.032171, loss_ce: 0.011436\n",
            "iteration 6412 : loss : 0.037124, loss_ce: 0.011416\n",
            "iteration 6413 : loss : 0.030860, loss_ce: 0.015057\n",
            "iteration 6414 : loss : 0.032318, loss_ce: 0.012821\n",
            "iteration 6415 : loss : 0.028879, loss_ce: 0.007729\n",
            "iteration 6416 : loss : 0.031786, loss_ce: 0.010553\n",
            "iteration 6417 : loss : 0.033156, loss_ce: 0.013480\n",
            "iteration 6418 : loss : 0.031017, loss_ce: 0.010567\n",
            "iteration 6419 : loss : 0.029131, loss_ce: 0.007292\n",
            "iteration 6420 : loss : 0.028538, loss_ce: 0.006087\n",
            "iteration 6421 : loss : 0.018618, loss_ce: 0.004054\n",
            "iteration 6422 : loss : 0.031412, loss_ce: 0.014394\n",
            "iteration 6423 : loss : 0.035667, loss_ce: 0.009083\n",
            "iteration 6424 : loss : 0.033037, loss_ce: 0.009891\n",
            "iteration 6425 : loss : 0.026679, loss_ce: 0.009838\n",
            "iteration 6426 : loss : 0.032674, loss_ce: 0.014208\n",
            "iteration 6427 : loss : 0.031379, loss_ce: 0.008698\n",
            "iteration 6428 : loss : 0.041702, loss_ce: 0.009335\n",
            "iteration 6429 : loss : 0.034932, loss_ce: 0.008798\n",
            "iteration 6430 : loss : 0.035242, loss_ce: 0.012708\n",
            "iteration 6431 : loss : 0.038721, loss_ce: 0.008714\n",
            "iteration 6432 : loss : 0.032301, loss_ce: 0.009814\n",
            "iteration 6433 : loss : 0.030296, loss_ce: 0.012387\n",
            "iteration 6434 : loss : 0.029861, loss_ce: 0.011170\n",
            "iteration 6435 : loss : 0.034988, loss_ce: 0.009333\n",
            "iteration 6436 : loss : 0.023311, loss_ce: 0.008790\n",
            "iteration 6437 : loss : 0.027038, loss_ce: 0.008858\n",
            "iteration 6438 : loss : 0.038466, loss_ce: 0.018089\n",
            " 58%|███████████████▋           | 87/150 [2:37:03<1:53:50, 108.43s/it]iteration 6439 : loss : 0.030419, loss_ce: 0.009408\n",
            "iteration 6440 : loss : 0.031286, loss_ce: 0.011884\n",
            "iteration 6441 : loss : 0.026601, loss_ce: 0.008265\n",
            "iteration 6442 : loss : 0.025172, loss_ce: 0.007965\n",
            "iteration 6443 : loss : 0.032937, loss_ce: 0.011047\n",
            "iteration 6444 : loss : 0.027430, loss_ce: 0.012220\n",
            "iteration 6445 : loss : 0.035627, loss_ce: 0.009276\n",
            "iteration 6446 : loss : 0.030964, loss_ce: 0.010175\n",
            "iteration 6447 : loss : 0.033263, loss_ce: 0.013185\n",
            "iteration 6448 : loss : 0.027431, loss_ce: 0.008487\n",
            "iteration 6449 : loss : 0.082952, loss_ce: 0.005913\n",
            "iteration 6450 : loss : 0.075185, loss_ce: 0.003284\n",
            "iteration 6451 : loss : 0.033658, loss_ce: 0.012879\n",
            "iteration 6452 : loss : 0.034011, loss_ce: 0.009666\n",
            "iteration 6453 : loss : 0.031662, loss_ce: 0.010129\n",
            "iteration 6454 : loss : 0.030373, loss_ce: 0.011344\n",
            "iteration 6455 : loss : 0.033950, loss_ce: 0.016341\n",
            "iteration 6456 : loss : 0.028268, loss_ce: 0.006677\n",
            "iteration 6457 : loss : 0.028434, loss_ce: 0.010533\n",
            "iteration 6458 : loss : 0.026010, loss_ce: 0.007023\n",
            "iteration 6459 : loss : 0.032796, loss_ce: 0.010938\n",
            "iteration 6460 : loss : 0.034610, loss_ce: 0.015306\n",
            "iteration 6461 : loss : 0.025685, loss_ce: 0.010621\n",
            "iteration 6462 : loss : 0.039252, loss_ce: 0.011000\n",
            "iteration 6463 : loss : 0.030345, loss_ce: 0.010068\n",
            "iteration 6464 : loss : 0.025792, loss_ce: 0.008976\n",
            "iteration 6465 : loss : 0.039379, loss_ce: 0.008166\n",
            "iteration 6466 : loss : 0.028640, loss_ce: 0.009881\n",
            "iteration 6467 : loss : 0.032613, loss_ce: 0.014519\n",
            "iteration 6468 : loss : 0.026621, loss_ce: 0.010893\n",
            "iteration 6469 : loss : 0.028809, loss_ce: 0.012207\n",
            "iteration 6470 : loss : 0.025785, loss_ce: 0.006692\n",
            "iteration 6471 : loss : 0.026236, loss_ce: 0.006778\n",
            "iteration 6472 : loss : 0.027708, loss_ce: 0.010140\n",
            "iteration 6473 : loss : 0.076141, loss_ce: 0.006186\n",
            "iteration 6474 : loss : 0.029043, loss_ce: 0.009283\n",
            "iteration 6475 : loss : 0.027050, loss_ce: 0.006915\n",
            "iteration 6476 : loss : 0.026571, loss_ce: 0.007903\n",
            "iteration 6477 : loss : 0.034863, loss_ce: 0.010152\n",
            "iteration 6478 : loss : 0.079508, loss_ce: 0.008644\n",
            "iteration 6479 : loss : 0.040468, loss_ce: 0.009003\n",
            "iteration 6480 : loss : 0.034564, loss_ce: 0.012236\n",
            "iteration 6481 : loss : 0.029052, loss_ce: 0.008502\n",
            "iteration 6482 : loss : 0.030077, loss_ce: 0.013040\n",
            "iteration 6483 : loss : 0.027340, loss_ce: 0.009639\n",
            "iteration 6484 : loss : 0.027707, loss_ce: 0.011121\n",
            "iteration 6485 : loss : 0.030886, loss_ce: 0.009283\n",
            "iteration 6486 : loss : 0.081714, loss_ce: 0.005297\n",
            "iteration 6487 : loss : 0.024224, loss_ce: 0.007153\n",
            "iteration 6488 : loss : 0.028002, loss_ce: 0.006775\n",
            "iteration 6489 : loss : 0.036071, loss_ce: 0.008471\n",
            "iteration 6490 : loss : 0.034057, loss_ce: 0.010563\n",
            "iteration 6491 : loss : 0.030667, loss_ce: 0.008757\n",
            "iteration 6492 : loss : 0.029445, loss_ce: 0.008623\n",
            "iteration 6493 : loss : 0.085951, loss_ce: 0.007303\n",
            "iteration 6494 : loss : 0.028461, loss_ce: 0.013160\n",
            "iteration 6495 : loss : 0.031967, loss_ce: 0.010185\n",
            "iteration 6496 : loss : 0.025324, loss_ce: 0.010334\n",
            "iteration 6497 : loss : 0.032682, loss_ce: 0.012203\n",
            "iteration 6498 : loss : 0.030236, loss_ce: 0.015391\n",
            "iteration 6499 : loss : 0.030873, loss_ce: 0.010779\n",
            "iteration 6500 : loss : 0.031790, loss_ce: 0.014957\n",
            "iteration 6501 : loss : 0.031694, loss_ce: 0.011860\n",
            "iteration 6502 : loss : 0.025761, loss_ce: 0.008541\n",
            "iteration 6503 : loss : 0.033367, loss_ce: 0.013354\n",
            "iteration 6504 : loss : 0.079880, loss_ce: 0.004024\n",
            "iteration 6505 : loss : 0.063629, loss_ce: 0.011593\n",
            "iteration 6506 : loss : 0.032204, loss_ce: 0.006953\n",
            "iteration 6507 : loss : 0.029258, loss_ce: 0.009279\n",
            "iteration 6508 : loss : 0.030996, loss_ce: 0.011387\n",
            "iteration 6509 : loss : 0.031957, loss_ce: 0.013258\n",
            "iteration 6510 : loss : 0.029672, loss_ce: 0.009698\n",
            "iteration 6511 : loss : 0.026575, loss_ce: 0.005708\n",
            "iteration 6512 : loss : 0.095177, loss_ce: 0.009856\n",
            " 59%|███████████████▊           | 88/150 [2:38:50<1:51:40, 108.08s/it]iteration 6513 : loss : 0.027431, loss_ce: 0.010960\n",
            "iteration 6514 : loss : 0.036410, loss_ce: 0.009194\n",
            "iteration 6515 : loss : 0.029957, loss_ce: 0.007644\n",
            "iteration 6516 : loss : 0.033042, loss_ce: 0.010578\n",
            "iteration 6517 : loss : 0.080929, loss_ce: 0.008213\n",
            "iteration 6518 : loss : 0.035244, loss_ce: 0.010092\n",
            "iteration 6519 : loss : 0.050685, loss_ce: 0.010724\n",
            "iteration 6520 : loss : 0.050120, loss_ce: 0.012362\n",
            "iteration 6521 : loss : 0.032082, loss_ce: 0.015150\n",
            "iteration 6522 : loss : 0.028031, loss_ce: 0.007351\n",
            "iteration 6523 : loss : 0.085207, loss_ce: 0.006152\n",
            "iteration 6524 : loss : 0.028453, loss_ce: 0.009659\n",
            "iteration 6525 : loss : 0.036586, loss_ce: 0.018809\n",
            "iteration 6526 : loss : 0.033389, loss_ce: 0.010153\n",
            "iteration 6527 : loss : 0.034991, loss_ce: 0.014419\n",
            "iteration 6528 : loss : 0.048439, loss_ce: 0.015757\n",
            "iteration 6529 : loss : 0.028770, loss_ce: 0.009047\n",
            "iteration 6530 : loss : 0.043193, loss_ce: 0.017280\n",
            "iteration 6531 : loss : 0.034846, loss_ce: 0.012623\n",
            "iteration 6532 : loss : 0.026953, loss_ce: 0.009506\n",
            "iteration 6533 : loss : 0.080150, loss_ce: 0.007735\n",
            "iteration 6534 : loss : 0.082373, loss_ce: 0.005055\n",
            "iteration 6535 : loss : 0.079134, loss_ce: 0.007827\n",
            "iteration 6536 : loss : 0.080160, loss_ce: 0.006225\n",
            "iteration 6537 : loss : 0.036706, loss_ce: 0.009670\n",
            "iteration 6538 : loss : 0.029995, loss_ce: 0.009517\n",
            "iteration 6539 : loss : 0.065889, loss_ce: 0.011671\n",
            "iteration 6540 : loss : 0.043435, loss_ce: 0.016874\n",
            "iteration 6541 : loss : 0.029171, loss_ce: 0.009079\n",
            "iteration 6542 : loss : 0.036678, loss_ce: 0.012749\n",
            "iteration 6543 : loss : 0.039326, loss_ce: 0.009652\n",
            "iteration 6544 : loss : 0.038523, loss_ce: 0.007474\n",
            "iteration 6545 : loss : 0.028047, loss_ce: 0.009613\n",
            "iteration 6546 : loss : 0.027525, loss_ce: 0.006908\n",
            "iteration 6547 : loss : 0.038830, loss_ce: 0.024220\n",
            "iteration 6548 : loss : 0.032109, loss_ce: 0.010899\n",
            "iteration 6549 : loss : 0.032071, loss_ce: 0.013316\n",
            "iteration 6550 : loss : 0.032785, loss_ce: 0.012220\n",
            "iteration 6551 : loss : 0.028927, loss_ce: 0.010484\n",
            "iteration 6552 : loss : 0.029641, loss_ce: 0.011097\n",
            "iteration 6553 : loss : 0.034748, loss_ce: 0.007513\n",
            "iteration 6554 : loss : 0.033931, loss_ce: 0.010277\n",
            "iteration 6555 : loss : 0.031983, loss_ce: 0.010564\n",
            "iteration 6556 : loss : 0.030370, loss_ce: 0.013023\n",
            "iteration 6557 : loss : 0.034429, loss_ce: 0.008763\n",
            "iteration 6558 : loss : 0.028438, loss_ce: 0.011706\n",
            "iteration 6559 : loss : 0.031921, loss_ce: 0.012501\n",
            "iteration 6560 : loss : 0.026923, loss_ce: 0.008369\n",
            "iteration 6561 : loss : 0.026610, loss_ce: 0.009354\n",
            "iteration 6562 : loss : 0.031485, loss_ce: 0.005400\n",
            "iteration 6563 : loss : 0.031207, loss_ce: 0.012838\n",
            "iteration 6564 : loss : 0.025453, loss_ce: 0.008846\n",
            "iteration 6565 : loss : 0.031630, loss_ce: 0.009688\n",
            "iteration 6566 : loss : 0.027281, loss_ce: 0.007122\n",
            "iteration 6567 : loss : 0.035771, loss_ce: 0.009982\n",
            "iteration 6568 : loss : 0.032578, loss_ce: 0.010710\n",
            "iteration 6569 : loss : 0.033324, loss_ce: 0.006932\n",
            "iteration 6570 : loss : 0.024651, loss_ce: 0.008296\n",
            "iteration 6571 : loss : 0.028495, loss_ce: 0.011311\n",
            "iteration 6572 : loss : 0.033494, loss_ce: 0.012288\n",
            "iteration 6573 : loss : 0.071167, loss_ce: 0.010310\n",
            "iteration 6574 : loss : 0.034323, loss_ce: 0.009017\n",
            "iteration 6575 : loss : 0.081308, loss_ce: 0.011336\n",
            "iteration 6576 : loss : 0.029948, loss_ce: 0.007259\n",
            "iteration 6577 : loss : 0.081609, loss_ce: 0.010675\n",
            "iteration 6578 : loss : 0.030437, loss_ce: 0.009833\n",
            "iteration 6579 : loss : 0.029711, loss_ce: 0.015506\n",
            "iteration 6580 : loss : 0.032612, loss_ce: 0.012094\n",
            "iteration 6581 : loss : 0.111847, loss_ce: 0.006825\n",
            "iteration 6582 : loss : 0.037112, loss_ce: 0.009116\n",
            "iteration 6583 : loss : 0.030531, loss_ce: 0.008913\n",
            "iteration 6584 : loss : 0.030574, loss_ce: 0.013445\n",
            "iteration 6585 : loss : 0.050402, loss_ce: 0.007976\n",
            "iteration 6586 : loss : 0.083519, loss_ce: 0.004966\n",
            " 59%|████████████████           | 89/150 [2:40:38<1:49:49, 108.02s/it]iteration 6587 : loss : 0.035847, loss_ce: 0.007247\n",
            "iteration 6588 : loss : 0.035129, loss_ce: 0.006870\n",
            "iteration 6589 : loss : 0.024581, loss_ce: 0.007751\n",
            "iteration 6590 : loss : 0.032352, loss_ce: 0.013563\n",
            "iteration 6591 : loss : 0.074522, loss_ce: 0.008333\n",
            "iteration 6592 : loss : 0.029668, loss_ce: 0.010516\n",
            "iteration 6593 : loss : 0.040213, loss_ce: 0.010117\n",
            "iteration 6594 : loss : 0.036690, loss_ce: 0.013942\n",
            "iteration 6595 : loss : 0.031516, loss_ce: 0.008581\n",
            "iteration 6596 : loss : 0.031702, loss_ce: 0.009805\n",
            "iteration 6597 : loss : 0.031306, loss_ce: 0.009428\n",
            "iteration 6598 : loss : 0.028862, loss_ce: 0.011768\n",
            "iteration 6599 : loss : 0.042782, loss_ce: 0.008546\n",
            "iteration 6600 : loss : 0.030335, loss_ce: 0.010300\n",
            "iteration 6601 : loss : 0.032437, loss_ce: 0.010493\n",
            "iteration 6602 : loss : 0.029409, loss_ce: 0.010177\n",
            "iteration 6603 : loss : 0.025338, loss_ce: 0.009236\n",
            "iteration 6604 : loss : 0.033925, loss_ce: 0.010132\n",
            "iteration 6605 : loss : 0.033594, loss_ce: 0.009107\n",
            "iteration 6606 : loss : 0.025984, loss_ce: 0.010455\n",
            "iteration 6607 : loss : 0.034475, loss_ce: 0.010817\n",
            "iteration 6608 : loss : 0.028231, loss_ce: 0.012116\n",
            "iteration 6609 : loss : 0.028330, loss_ce: 0.008643\n",
            "iteration 6610 : loss : 0.029923, loss_ce: 0.007602\n",
            "iteration 6611 : loss : 0.084490, loss_ce: 0.005429\n",
            "iteration 6612 : loss : 0.080401, loss_ce: 0.009465\n",
            "iteration 6613 : loss : 0.025197, loss_ce: 0.005947\n",
            "iteration 6614 : loss : 0.031545, loss_ce: 0.012548\n",
            "iteration 6615 : loss : 0.047483, loss_ce: 0.005102\n",
            "iteration 6616 : loss : 0.077910, loss_ce: 0.008742\n",
            "iteration 6617 : loss : 0.038764, loss_ce: 0.010248\n",
            "iteration 6618 : loss : 0.037195, loss_ce: 0.012888\n",
            "iteration 6619 : loss : 0.032013, loss_ce: 0.012513\n",
            "iteration 6620 : loss : 0.032951, loss_ce: 0.010681\n",
            "iteration 6621 : loss : 0.073568, loss_ce: 0.004975\n",
            "iteration 6622 : loss : 0.021932, loss_ce: 0.006593\n",
            "iteration 6623 : loss : 0.029970, loss_ce: 0.008224\n",
            "iteration 6624 : loss : 0.036040, loss_ce: 0.019762\n",
            "iteration 6625 : loss : 0.026682, loss_ce: 0.010380\n",
            "iteration 6626 : loss : 0.029504, loss_ce: 0.014408\n",
            "iteration 6627 : loss : 0.033672, loss_ce: 0.008316\n",
            "iteration 6628 : loss : 0.027830, loss_ce: 0.008403\n",
            "iteration 6629 : loss : 0.036879, loss_ce: 0.009211\n",
            "iteration 6630 : loss : 0.075714, loss_ce: 0.004953\n",
            "iteration 6631 : loss : 0.032457, loss_ce: 0.009012\n",
            "iteration 6632 : loss : 0.032498, loss_ce: 0.010163\n",
            "iteration 6633 : loss : 0.082776, loss_ce: 0.010969\n",
            "iteration 6634 : loss : 0.025277, loss_ce: 0.012562\n",
            "iteration 6635 : loss : 0.036028, loss_ce: 0.012178\n",
            "iteration 6636 : loss : 0.031230, loss_ce: 0.008653\n",
            "iteration 6637 : loss : 0.079829, loss_ce: 0.006233\n",
            "iteration 6638 : loss : 0.034437, loss_ce: 0.015371\n",
            "iteration 6639 : loss : 0.025882, loss_ce: 0.008881\n",
            "iteration 6640 : loss : 0.048335, loss_ce: 0.008133\n",
            "iteration 6641 : loss : 0.030301, loss_ce: 0.011976\n",
            "iteration 6642 : loss : 0.033355, loss_ce: 0.011771\n",
            "iteration 6643 : loss : 0.031491, loss_ce: 0.012128\n",
            "iteration 6644 : loss : 0.032858, loss_ce: 0.007167\n",
            "iteration 6645 : loss : 0.033845, loss_ce: 0.009406\n",
            "iteration 6646 : loss : 0.034780, loss_ce: 0.012806\n",
            "iteration 6647 : loss : 0.021447, loss_ce: 0.006971\n",
            "iteration 6648 : loss : 0.031790, loss_ce: 0.014103\n",
            "iteration 6649 : loss : 0.031586, loss_ce: 0.013044\n",
            "iteration 6650 : loss : 0.030030, loss_ce: 0.012188\n",
            "iteration 6651 : loss : 0.029679, loss_ce: 0.011728\n",
            "iteration 6652 : loss : 0.027166, loss_ce: 0.009807\n",
            "iteration 6653 : loss : 0.031823, loss_ce: 0.010770\n",
            "iteration 6654 : loss : 0.027880, loss_ce: 0.013671\n",
            "iteration 6655 : loss : 0.031270, loss_ce: 0.013190\n",
            "iteration 6656 : loss : 0.024391, loss_ce: 0.009555\n",
            "iteration 6657 : loss : 0.031876, loss_ce: 0.012474\n",
            "iteration 6658 : loss : 0.026525, loss_ce: 0.008109\n",
            "iteration 6659 : loss : 0.040127, loss_ce: 0.013296\n",
            "iteration 6660 : loss : 0.034205, loss_ce: 0.009782\n",
            " 60%|████████████████▏          | 90/150 [2:42:27<1:48:22, 108.37s/it]iteration 6661 : loss : 0.131251, loss_ce: 0.004621\n",
            "iteration 6662 : loss : 0.033176, loss_ce: 0.007197\n",
            "iteration 6663 : loss : 0.079963, loss_ce: 0.007543\n",
            "iteration 6664 : loss : 0.029522, loss_ce: 0.011603\n",
            "iteration 6665 : loss : 0.032803, loss_ce: 0.012108\n",
            "iteration 6666 : loss : 0.026052, loss_ce: 0.008445\n",
            "iteration 6667 : loss : 0.034482, loss_ce: 0.015053\n",
            "iteration 6668 : loss : 0.024122, loss_ce: 0.008665\n",
            "iteration 6669 : loss : 0.027647, loss_ce: 0.012231\n",
            "iteration 6670 : loss : 0.071152, loss_ce: 0.003932\n",
            "iteration 6671 : loss : 0.030550, loss_ce: 0.008924\n",
            "iteration 6672 : loss : 0.037417, loss_ce: 0.007944\n",
            "iteration 6673 : loss : 0.030850, loss_ce: 0.007210\n",
            "iteration 6674 : loss : 0.027492, loss_ce: 0.008262\n",
            "iteration 6675 : loss : 0.076628, loss_ce: 0.006224\n",
            "iteration 6676 : loss : 0.032022, loss_ce: 0.014894\n",
            "iteration 6677 : loss : 0.027505, loss_ce: 0.009726\n",
            "iteration 6678 : loss : 0.031108, loss_ce: 0.009615\n",
            "iteration 6679 : loss : 0.030349, loss_ce: 0.009814\n",
            "iteration 6680 : loss : 0.029758, loss_ce: 0.008054\n",
            "iteration 6681 : loss : 0.027996, loss_ce: 0.013367\n",
            "iteration 6682 : loss : 0.028387, loss_ce: 0.008856\n",
            "iteration 6683 : loss : 0.033560, loss_ce: 0.009759\n",
            "iteration 6684 : loss : 0.033758, loss_ce: 0.012255\n",
            "iteration 6685 : loss : 0.026226, loss_ce: 0.011048\n",
            "iteration 6686 : loss : 0.033227, loss_ce: 0.007771\n",
            "iteration 6687 : loss : 0.026425, loss_ce: 0.010718\n",
            "iteration 6688 : loss : 0.030975, loss_ce: 0.012890\n",
            "iteration 6689 : loss : 0.031363, loss_ce: 0.011609\n",
            "iteration 6690 : loss : 0.032801, loss_ce: 0.012245\n",
            "iteration 6691 : loss : 0.023825, loss_ce: 0.009748\n",
            "iteration 6692 : loss : 0.028417, loss_ce: 0.011451\n",
            "iteration 6693 : loss : 0.029935, loss_ce: 0.007663\n",
            "iteration 6694 : loss : 0.030463, loss_ce: 0.006530\n",
            "iteration 6695 : loss : 0.035889, loss_ce: 0.009107\n",
            "iteration 6696 : loss : 0.028900, loss_ce: 0.011017\n",
            "iteration 6697 : loss : 0.040022, loss_ce: 0.015684\n",
            "iteration 6698 : loss : 0.023621, loss_ce: 0.005507\n",
            "iteration 6699 : loss : 0.033567, loss_ce: 0.011669\n",
            "iteration 6700 : loss : 0.031347, loss_ce: 0.009329\n",
            "iteration 6701 : loss : 0.032158, loss_ce: 0.006249\n",
            "iteration 6702 : loss : 0.026294, loss_ce: 0.011442\n",
            "iteration 6703 : loss : 0.028614, loss_ce: 0.005528\n",
            "iteration 6704 : loss : 0.026963, loss_ce: 0.006947\n",
            "iteration 6705 : loss : 0.026670, loss_ce: 0.011080\n",
            "iteration 6706 : loss : 0.033958, loss_ce: 0.009653\n",
            "iteration 6707 : loss : 0.030486, loss_ce: 0.009621\n",
            "iteration 6708 : loss : 0.027248, loss_ce: 0.008252\n",
            "iteration 6709 : loss : 0.031711, loss_ce: 0.011752\n",
            "iteration 6710 : loss : 0.030156, loss_ce: 0.007647\n",
            "iteration 6711 : loss : 0.031885, loss_ce: 0.011014\n",
            "iteration 6712 : loss : 0.025310, loss_ce: 0.005944\n",
            "iteration 6713 : loss : 0.033909, loss_ce: 0.008761\n",
            "iteration 6714 : loss : 0.033471, loss_ce: 0.015166\n",
            "iteration 6715 : loss : 0.033717, loss_ce: 0.012871\n",
            "iteration 6716 : loss : 0.030742, loss_ce: 0.013188\n",
            "iteration 6717 : loss : 0.041351, loss_ce: 0.011351\n",
            "iteration 6718 : loss : 0.028136, loss_ce: 0.007678\n",
            "iteration 6719 : loss : 0.033606, loss_ce: 0.010190\n",
            "iteration 6720 : loss : 0.027133, loss_ce: 0.009212\n",
            "iteration 6721 : loss : 0.082415, loss_ce: 0.005023\n",
            "iteration 6722 : loss : 0.029733, loss_ce: 0.012628\n",
            "iteration 6723 : loss : 0.072759, loss_ce: 0.004198\n",
            "iteration 6724 : loss : 0.079843, loss_ce: 0.008938\n",
            "iteration 6725 : loss : 0.026712, loss_ce: 0.009883\n",
            "iteration 6726 : loss : 0.077344, loss_ce: 0.005626\n",
            "iteration 6727 : loss : 0.031651, loss_ce: 0.011282\n",
            "iteration 6728 : loss : 0.033334, loss_ce: 0.012280\n",
            "iteration 6729 : loss : 0.026397, loss_ce: 0.009619\n",
            "iteration 6730 : loss : 0.027132, loss_ce: 0.008165\n",
            "iteration 6731 : loss : 0.029006, loss_ce: 0.011530\n",
            "iteration 6732 : loss : 0.025611, loss_ce: 0.012189\n",
            "iteration 6733 : loss : 0.026256, loss_ce: 0.008358\n",
            "iteration 6734 : loss : 0.038293, loss_ce: 0.010048\n",
            " 61%|████████████████▍          | 91/150 [2:44:16<1:46:42, 108.52s/it]iteration 6735 : loss : 0.027479, loss_ce: 0.012186\n",
            "iteration 6736 : loss : 0.036022, loss_ce: 0.010288\n",
            "iteration 6737 : loss : 0.027228, loss_ce: 0.011840\n",
            "iteration 6738 : loss : 0.036302, loss_ce: 0.010873\n",
            "iteration 6739 : loss : 0.024511, loss_ce: 0.006747\n",
            "iteration 6740 : loss : 0.028451, loss_ce: 0.012532\n",
            "iteration 6741 : loss : 0.080368, loss_ce: 0.008354\n",
            "iteration 6742 : loss : 0.030611, loss_ce: 0.008169\n",
            "iteration 6743 : loss : 0.032409, loss_ce: 0.008204\n",
            "iteration 6744 : loss : 0.023769, loss_ce: 0.009172\n",
            "iteration 6745 : loss : 0.032537, loss_ce: 0.010783\n",
            "iteration 6746 : loss : 0.027598, loss_ce: 0.010881\n",
            "iteration 6747 : loss : 0.080724, loss_ce: 0.007075\n",
            "iteration 6748 : loss : 0.031674, loss_ce: 0.008726\n",
            "iteration 6749 : loss : 0.024438, loss_ce: 0.008093\n",
            "iteration 6750 : loss : 0.027885, loss_ce: 0.011415\n",
            "iteration 6751 : loss : 0.032090, loss_ce: 0.011768\n",
            "iteration 6752 : loss : 0.038948, loss_ce: 0.012888\n",
            "iteration 6753 : loss : 0.025229, loss_ce: 0.008105\n",
            "iteration 6754 : loss : 0.023076, loss_ce: 0.006819\n",
            "iteration 6755 : loss : 0.025787, loss_ce: 0.006724\n",
            "iteration 6756 : loss : 0.030630, loss_ce: 0.014870\n",
            "iteration 6757 : loss : 0.029760, loss_ce: 0.008542\n",
            "iteration 6758 : loss : 0.027350, loss_ce: 0.006520\n",
            "iteration 6759 : loss : 0.034467, loss_ce: 0.008774\n",
            "iteration 6760 : loss : 0.028309, loss_ce: 0.011984\n",
            "iteration 6761 : loss : 0.033817, loss_ce: 0.011796\n",
            "iteration 6762 : loss : 0.035858, loss_ce: 0.009555\n",
            "iteration 6763 : loss : 0.024414, loss_ce: 0.009541\n",
            "iteration 6764 : loss : 0.026099, loss_ce: 0.007509\n",
            "iteration 6765 : loss : 0.029562, loss_ce: 0.011086\n",
            "iteration 6766 : loss : 0.029194, loss_ce: 0.009961\n",
            "iteration 6767 : loss : 0.023126, loss_ce: 0.008739\n",
            "iteration 6768 : loss : 0.029210, loss_ce: 0.010110\n",
            "iteration 6769 : loss : 0.032053, loss_ce: 0.013132\n",
            "iteration 6770 : loss : 0.056393, loss_ce: 0.009197\n",
            "iteration 6771 : loss : 0.031133, loss_ce: 0.012885\n",
            "iteration 6772 : loss : 0.027741, loss_ce: 0.008979\n",
            "iteration 6773 : loss : 0.033260, loss_ce: 0.011869\n",
            "iteration 6774 : loss : 0.032493, loss_ce: 0.011935\n",
            "iteration 6775 : loss : 0.031769, loss_ce: 0.009660\n",
            "iteration 6776 : loss : 0.039406, loss_ce: 0.003379\n",
            "iteration 6777 : loss : 0.030187, loss_ce: 0.011880\n",
            "iteration 6778 : loss : 0.025685, loss_ce: 0.008113\n",
            "iteration 6779 : loss : 0.025214, loss_ce: 0.007641\n",
            "iteration 6780 : loss : 0.028697, loss_ce: 0.009453\n",
            "iteration 6781 : loss : 0.026157, loss_ce: 0.006355\n",
            "iteration 6782 : loss : 0.023343, loss_ce: 0.007467\n",
            "iteration 6783 : loss : 0.028159, loss_ce: 0.008090\n",
            "iteration 6784 : loss : 0.025533, loss_ce: 0.009015\n",
            "iteration 6785 : loss : 0.024898, loss_ce: 0.008018\n",
            "iteration 6786 : loss : 0.029839, loss_ce: 0.008205\n",
            "iteration 6787 : loss : 0.028284, loss_ce: 0.010800\n",
            "iteration 6788 : loss : 0.021180, loss_ce: 0.006052\n",
            "iteration 6789 : loss : 0.028493, loss_ce: 0.012060\n",
            "iteration 6790 : loss : 0.028112, loss_ce: 0.010769\n",
            "iteration 6791 : loss : 0.028327, loss_ce: 0.005516\n",
            "iteration 6792 : loss : 0.034357, loss_ce: 0.011407\n",
            "iteration 6793 : loss : 0.028930, loss_ce: 0.009296\n",
            "iteration 6794 : loss : 0.029183, loss_ce: 0.013645\n",
            "iteration 6795 : loss : 0.081147, loss_ce: 0.011500\n",
            "iteration 6796 : loss : 0.036780, loss_ce: 0.014416\n",
            "iteration 6797 : loss : 0.030996, loss_ce: 0.009310\n",
            "iteration 6798 : loss : 0.024548, loss_ce: 0.007948\n",
            "iteration 6799 : loss : 0.030341, loss_ce: 0.007030\n",
            "iteration 6800 : loss : 0.080305, loss_ce: 0.011678\n",
            "iteration 6801 : loss : 0.022254, loss_ce: 0.006589\n",
            "iteration 6802 : loss : 0.030078, loss_ce: 0.008623\n",
            "iteration 6803 : loss : 0.035210, loss_ce: 0.015020\n",
            "iteration 6804 : loss : 0.026270, loss_ce: 0.008496\n",
            "iteration 6805 : loss : 0.030517, loss_ce: 0.008881\n",
            "iteration 6806 : loss : 0.027270, loss_ce: 0.010442\n",
            "iteration 6807 : loss : 0.078421, loss_ce: 0.007542\n",
            "iteration 6808 : loss : 0.033633, loss_ce: 0.009382\n",
            " 61%|████████████████▌          | 92/150 [2:46:04<1:44:42, 108.33s/it]iteration 6809 : loss : 0.029069, loss_ce: 0.008734\n",
            "iteration 6810 : loss : 0.029842, loss_ce: 0.013936\n",
            "iteration 6811 : loss : 0.026924, loss_ce: 0.008265\n",
            "iteration 6812 : loss : 0.025283, loss_ce: 0.010116\n",
            "iteration 6813 : loss : 0.029960, loss_ce: 0.012995\n",
            "iteration 6814 : loss : 0.032695, loss_ce: 0.008054\n",
            "iteration 6815 : loss : 0.076449, loss_ce: 0.007207\n",
            "iteration 6816 : loss : 0.026841, loss_ce: 0.008501\n",
            "iteration 6817 : loss : 0.028367, loss_ce: 0.008485\n",
            "iteration 6818 : loss : 0.027853, loss_ce: 0.011245\n",
            "iteration 6819 : loss : 0.029804, loss_ce: 0.011616\n",
            "iteration 6820 : loss : 0.027433, loss_ce: 0.007324\n",
            "iteration 6821 : loss : 0.037460, loss_ce: 0.005925\n",
            "iteration 6822 : loss : 0.027011, loss_ce: 0.005196\n",
            "iteration 6823 : loss : 0.032997, loss_ce: 0.010947\n",
            "iteration 6824 : loss : 0.030038, loss_ce: 0.008035\n",
            "iteration 6825 : loss : 0.028384, loss_ce: 0.007193\n",
            "iteration 6826 : loss : 0.027937, loss_ce: 0.012038\n",
            "iteration 6827 : loss : 0.028243, loss_ce: 0.009947\n",
            "iteration 6828 : loss : 0.075433, loss_ce: 0.004901\n",
            "iteration 6829 : loss : 0.022552, loss_ce: 0.006838\n",
            "iteration 6830 : loss : 0.026732, loss_ce: 0.007628\n",
            "iteration 6831 : loss : 0.029548, loss_ce: 0.015266\n",
            "iteration 6832 : loss : 0.026172, loss_ce: 0.009920\n",
            "iteration 6833 : loss : 0.029913, loss_ce: 0.011714\n",
            "iteration 6834 : loss : 0.024218, loss_ce: 0.008566\n",
            "iteration 6835 : loss : 0.023673, loss_ce: 0.008136\n",
            "iteration 6836 : loss : 0.027549, loss_ce: 0.010509\n",
            "iteration 6837 : loss : 0.022671, loss_ce: 0.007772\n",
            "iteration 6838 : loss : 0.031331, loss_ce: 0.011095\n",
            "iteration 6839 : loss : 0.027533, loss_ce: 0.009531\n",
            "iteration 6840 : loss : 0.023916, loss_ce: 0.006488\n",
            "iteration 6841 : loss : 0.028567, loss_ce: 0.010208\n",
            "iteration 6842 : loss : 0.029884, loss_ce: 0.011608\n",
            "iteration 6843 : loss : 0.074101, loss_ce: 0.007099\n",
            "iteration 6844 : loss : 0.028987, loss_ce: 0.011516\n",
            "iteration 6845 : loss : 0.029175, loss_ce: 0.008171\n",
            "iteration 6846 : loss : 0.026186, loss_ce: 0.009565\n",
            "iteration 6847 : loss : 0.028554, loss_ce: 0.010820\n",
            "iteration 6848 : loss : 0.032298, loss_ce: 0.010858\n",
            "iteration 6849 : loss : 0.031878, loss_ce: 0.011492\n",
            "iteration 6850 : loss : 0.027120, loss_ce: 0.008337\n",
            "iteration 6851 : loss : 0.026958, loss_ce: 0.011885\n",
            "iteration 6852 : loss : 0.028701, loss_ce: 0.012313\n",
            "iteration 6853 : loss : 0.025869, loss_ce: 0.009285\n",
            "iteration 6854 : loss : 0.036711, loss_ce: 0.008418\n",
            "iteration 6855 : loss : 0.029127, loss_ce: 0.007559\n",
            "iteration 6856 : loss : 0.028050, loss_ce: 0.009170\n",
            "iteration 6857 : loss : 0.028852, loss_ce: 0.010176\n",
            "iteration 6858 : loss : 0.030168, loss_ce: 0.008969\n",
            "iteration 6859 : loss : 0.029697, loss_ce: 0.011122\n",
            "iteration 6860 : loss : 0.030142, loss_ce: 0.007492\n",
            "iteration 6861 : loss : 0.028795, loss_ce: 0.011228\n",
            "iteration 6862 : loss : 0.025665, loss_ce: 0.004229\n",
            "iteration 6863 : loss : 0.028872, loss_ce: 0.010418\n",
            "iteration 6864 : loss : 0.030594, loss_ce: 0.012571\n",
            "iteration 6865 : loss : 0.028646, loss_ce: 0.008919\n",
            "iteration 6866 : loss : 0.027793, loss_ce: 0.006046\n",
            "iteration 6867 : loss : 0.038454, loss_ce: 0.007498\n",
            "iteration 6868 : loss : 0.026668, loss_ce: 0.009680\n",
            "iteration 6869 : loss : 0.029310, loss_ce: 0.010213\n",
            "iteration 6870 : loss : 0.033008, loss_ce: 0.011004\n",
            "iteration 6871 : loss : 0.025496, loss_ce: 0.007977\n",
            "iteration 6872 : loss : 0.024065, loss_ce: 0.004497\n",
            "iteration 6873 : loss : 0.031545, loss_ce: 0.010592\n",
            "iteration 6874 : loss : 0.063487, loss_ce: 0.007163\n",
            "iteration 6875 : loss : 0.028904, loss_ce: 0.015118\n",
            "iteration 6876 : loss : 0.033843, loss_ce: 0.008839\n",
            "iteration 6877 : loss : 0.028549, loss_ce: 0.011321\n",
            "iteration 6878 : loss : 0.030277, loss_ce: 0.012048\n",
            "iteration 6879 : loss : 0.027918, loss_ce: 0.009170\n",
            "iteration 6880 : loss : 0.024489, loss_ce: 0.010192\n",
            "iteration 6881 : loss : 0.032942, loss_ce: 0.010180\n",
            "iteration 6882 : loss : 0.031656, loss_ce: 0.010331\n",
            " 62%|████████████████▋          | 93/150 [2:47:52<1:42:45, 108.17s/it]iteration 6883 : loss : 0.026059, loss_ce: 0.008451\n",
            "iteration 6884 : loss : 0.046291, loss_ce: 0.011623\n",
            "iteration 6885 : loss : 0.031792, loss_ce: 0.012386\n",
            "iteration 6886 : loss : 0.025484, loss_ce: 0.007600\n",
            "iteration 6887 : loss : 0.029677, loss_ce: 0.011091\n",
            "iteration 6888 : loss : 0.031100, loss_ce: 0.016189\n",
            "iteration 6889 : loss : 0.032448, loss_ce: 0.009919\n",
            "iteration 6890 : loss : 0.068238, loss_ce: 0.007532\n",
            "iteration 6891 : loss : 0.023155, loss_ce: 0.006575\n",
            "iteration 6892 : loss : 0.031177, loss_ce: 0.007630\n",
            "iteration 6893 : loss : 0.023860, loss_ce: 0.008636\n",
            "iteration 6894 : loss : 0.076011, loss_ce: 0.007759\n",
            "iteration 6895 : loss : 0.029461, loss_ce: 0.011085\n",
            "iteration 6896 : loss : 0.023507, loss_ce: 0.007628\n",
            "iteration 6897 : loss : 0.031206, loss_ce: 0.008967\n",
            "iteration 6898 : loss : 0.028378, loss_ce: 0.013048\n",
            "iteration 6899 : loss : 0.026579, loss_ce: 0.007579\n",
            "iteration 6900 : loss : 0.030160, loss_ce: 0.006253\n",
            "iteration 6901 : loss : 0.025318, loss_ce: 0.012583\n",
            "iteration 6902 : loss : 0.025480, loss_ce: 0.010200\n",
            "iteration 6903 : loss : 0.031280, loss_ce: 0.010490\n",
            "iteration 6904 : loss : 0.030094, loss_ce: 0.011198\n",
            "iteration 6905 : loss : 0.027742, loss_ce: 0.011571\n",
            "iteration 6906 : loss : 0.027156, loss_ce: 0.009124\n",
            "iteration 6907 : loss : 0.036533, loss_ce: 0.015955\n",
            "iteration 6908 : loss : 0.029094, loss_ce: 0.008292\n",
            "iteration 6909 : loss : 0.032675, loss_ce: 0.010523\n",
            "iteration 6910 : loss : 0.033103, loss_ce: 0.011043\n",
            "iteration 6911 : loss : 0.028327, loss_ce: 0.008070\n",
            "iteration 6912 : loss : 0.029694, loss_ce: 0.010304\n",
            "iteration 6913 : loss : 0.052496, loss_ce: 0.007156\n",
            "iteration 6914 : loss : 0.038436, loss_ce: 0.010689\n",
            "iteration 6915 : loss : 0.027231, loss_ce: 0.011619\n",
            "iteration 6916 : loss : 0.026872, loss_ce: 0.008423\n",
            "iteration 6917 : loss : 0.029310, loss_ce: 0.012381\n",
            "iteration 6918 : loss : 0.030581, loss_ce: 0.007850\n",
            "iteration 6919 : loss : 0.031027, loss_ce: 0.011469\n",
            "iteration 6920 : loss : 0.040913, loss_ce: 0.013048\n",
            "iteration 6921 : loss : 0.031461, loss_ce: 0.007219\n",
            "iteration 6922 : loss : 0.051045, loss_ce: 0.008112\n",
            "iteration 6923 : loss : 0.034570, loss_ce: 0.007198\n",
            "iteration 6924 : loss : 0.024762, loss_ce: 0.009076\n",
            "iteration 6925 : loss : 0.030003, loss_ce: 0.011578\n",
            "iteration 6926 : loss : 0.032055, loss_ce: 0.013708\n",
            "iteration 6927 : loss : 0.037161, loss_ce: 0.014706\n",
            "iteration 6928 : loss : 0.033740, loss_ce: 0.013931\n",
            "iteration 6929 : loss : 0.025903, loss_ce: 0.006802\n",
            "iteration 6930 : loss : 0.027178, loss_ce: 0.010195\n",
            "iteration 6931 : loss : 0.031637, loss_ce: 0.009054\n",
            "iteration 6932 : loss : 0.033288, loss_ce: 0.008619\n",
            "iteration 6933 : loss : 0.035253, loss_ce: 0.007882\n",
            "iteration 6934 : loss : 0.028563, loss_ce: 0.010586\n",
            "iteration 6935 : loss : 0.024409, loss_ce: 0.003900\n",
            "iteration 6936 : loss : 0.086269, loss_ce: 0.005763\n",
            "iteration 6937 : loss : 0.079908, loss_ce: 0.006859\n",
            "iteration 6938 : loss : 0.031740, loss_ce: 0.008309\n",
            "iteration 6939 : loss : 0.026690, loss_ce: 0.012256\n",
            "iteration 6940 : loss : 0.034713, loss_ce: 0.013611\n",
            "iteration 6941 : loss : 0.030641, loss_ce: 0.007074\n",
            "iteration 6942 : loss : 0.031011, loss_ce: 0.011496\n",
            "iteration 6943 : loss : 0.031264, loss_ce: 0.016049\n",
            "iteration 6944 : loss : 0.033050, loss_ce: 0.015246\n",
            "iteration 6945 : loss : 0.075951, loss_ce: 0.005564\n",
            "iteration 6946 : loss : 0.076146, loss_ce: 0.009434\n",
            "iteration 6947 : loss : 0.073071, loss_ce: 0.005430\n",
            "iteration 6948 : loss : 0.029058, loss_ce: 0.008188\n",
            "iteration 6949 : loss : 0.031413, loss_ce: 0.011460\n",
            "iteration 6950 : loss : 0.026628, loss_ce: 0.010235\n",
            "iteration 6951 : loss : 0.032869, loss_ce: 0.012829\n",
            "iteration 6952 : loss : 0.029013, loss_ce: 0.011017\n",
            "iteration 6953 : loss : 0.022155, loss_ce: 0.006112\n",
            "iteration 6954 : loss : 0.033306, loss_ce: 0.009457\n",
            "iteration 6955 : loss : 0.087178, loss_ce: 0.006733\n",
            "iteration 6956 : loss : 0.025950, loss_ce: 0.010088\n",
            " 63%|████████████████▉          | 94/150 [2:49:41<1:41:12, 108.43s/it]iteration 6957 : loss : 0.026232, loss_ce: 0.007113\n",
            "iteration 6958 : loss : 0.081801, loss_ce: 0.006600\n",
            "iteration 6959 : loss : 0.027539, loss_ce: 0.008777\n",
            "iteration 6960 : loss : 0.024423, loss_ce: 0.007281\n",
            "iteration 6961 : loss : 0.028733, loss_ce: 0.008993\n",
            "iteration 6962 : loss : 0.033881, loss_ce: 0.010482\n",
            "iteration 6963 : loss : 0.030309, loss_ce: 0.010371\n",
            "iteration 6964 : loss : 0.076534, loss_ce: 0.004133\n",
            "iteration 6965 : loss : 0.030730, loss_ce: 0.012623\n",
            "iteration 6966 : loss : 0.030672, loss_ce: 0.015863\n",
            "iteration 6967 : loss : 0.033532, loss_ce: 0.014814\n",
            "iteration 6968 : loss : 0.029809, loss_ce: 0.006844\n",
            "iteration 6969 : loss : 0.031083, loss_ce: 0.011767\n",
            "iteration 6970 : loss : 0.028996, loss_ce: 0.011457\n",
            "iteration 6971 : loss : 0.033546, loss_ce: 0.016319\n",
            "iteration 6972 : loss : 0.026448, loss_ce: 0.010832\n",
            "iteration 6973 : loss : 0.025169, loss_ce: 0.009115\n",
            "iteration 6974 : loss : 0.028260, loss_ce: 0.008936\n",
            "iteration 6975 : loss : 0.029107, loss_ce: 0.006582\n",
            "iteration 6976 : loss : 0.121177, loss_ce: 0.004712\n",
            "iteration 6977 : loss : 0.075262, loss_ce: 0.005564\n",
            "iteration 6978 : loss : 0.027713, loss_ce: 0.007862\n",
            "iteration 6979 : loss : 0.026261, loss_ce: 0.009837\n",
            "iteration 6980 : loss : 0.082076, loss_ce: 0.014551\n",
            "iteration 6981 : loss : 0.080293, loss_ce: 0.007176\n",
            "iteration 6982 : loss : 0.076157, loss_ce: 0.009465\n",
            "iteration 6983 : loss : 0.034328, loss_ce: 0.009395\n",
            "iteration 6984 : loss : 0.032080, loss_ce: 0.009382\n",
            "iteration 6985 : loss : 0.030583, loss_ce: 0.010965\n",
            "iteration 6986 : loss : 0.028864, loss_ce: 0.010318\n",
            "iteration 6987 : loss : 0.030150, loss_ce: 0.011936\n",
            "iteration 6988 : loss : 0.034737, loss_ce: 0.007630\n",
            "iteration 6989 : loss : 0.027137, loss_ce: 0.011885\n",
            "iteration 6990 : loss : 0.034302, loss_ce: 0.008294\n",
            "iteration 6991 : loss : 0.026405, loss_ce: 0.010920\n",
            "iteration 6992 : loss : 0.033686, loss_ce: 0.009604\n",
            "iteration 6993 : loss : 0.044097, loss_ce: 0.009321\n",
            "iteration 6994 : loss : 0.079353, loss_ce: 0.008825\n",
            "iteration 6995 : loss : 0.023976, loss_ce: 0.009831\n",
            "iteration 6996 : loss : 0.027834, loss_ce: 0.012510\n",
            "iteration 6997 : loss : 0.030170, loss_ce: 0.016460\n",
            "iteration 6998 : loss : 0.076270, loss_ce: 0.007439\n",
            "iteration 6999 : loss : 0.025356, loss_ce: 0.007450\n",
            "iteration 7000 : loss : 0.075105, loss_ce: 0.007878\n",
            "iteration 7001 : loss : 0.046851, loss_ce: 0.007277\n",
            "iteration 7002 : loss : 0.027936, loss_ce: 0.006496\n",
            "iteration 7003 : loss : 0.023601, loss_ce: 0.006341\n",
            "iteration 7004 : loss : 0.038716, loss_ce: 0.010111\n",
            "iteration 7005 : loss : 0.030978, loss_ce: 0.015444\n",
            "iteration 7006 : loss : 0.032414, loss_ce: 0.010486\n",
            "iteration 7007 : loss : 0.028664, loss_ce: 0.009768\n",
            "iteration 7008 : loss : 0.026267, loss_ce: 0.007228\n",
            "iteration 7009 : loss : 0.028892, loss_ce: 0.012413\n",
            "iteration 7010 : loss : 0.025200, loss_ce: 0.010865\n",
            "iteration 7011 : loss : 0.030008, loss_ce: 0.010070\n",
            "iteration 7012 : loss : 0.027436, loss_ce: 0.008236\n",
            "iteration 7013 : loss : 0.030459, loss_ce: 0.011478\n",
            "iteration 7014 : loss : 0.031118, loss_ce: 0.010777\n",
            "iteration 7015 : loss : 0.025882, loss_ce: 0.007388\n",
            "iteration 7016 : loss : 0.022962, loss_ce: 0.007217\n",
            "iteration 7017 : loss : 0.028041, loss_ce: 0.015155\n",
            "iteration 7018 : loss : 0.028307, loss_ce: 0.009726\n",
            "iteration 7019 : loss : 0.022681, loss_ce: 0.007443\n",
            "iteration 7020 : loss : 0.023712, loss_ce: 0.008608\n",
            "iteration 7021 : loss : 0.036128, loss_ce: 0.006604\n",
            "iteration 7022 : loss : 0.034844, loss_ce: 0.013019\n",
            "iteration 7023 : loss : 0.033457, loss_ce: 0.010716\n",
            "iteration 7024 : loss : 0.038697, loss_ce: 0.009825\n",
            "iteration 7025 : loss : 0.025137, loss_ce: 0.008783\n",
            "iteration 7026 : loss : 0.029781, loss_ce: 0.009972\n",
            "iteration 7027 : loss : 0.031730, loss_ce: 0.008897\n",
            "iteration 7028 : loss : 0.026480, loss_ce: 0.006952\n",
            "iteration 7029 : loss : 0.030332, loss_ce: 0.009412\n",
            "iteration 7030 : loss : 0.035407, loss_ce: 0.008802\n",
            " 63%|█████████████████          | 95/150 [2:51:30<1:39:35, 108.65s/it]iteration 7031 : loss : 0.029263, loss_ce: 0.007253\n",
            "iteration 7032 : loss : 0.025235, loss_ce: 0.009126\n",
            "iteration 7033 : loss : 0.028507, loss_ce: 0.008296\n",
            "iteration 7034 : loss : 0.025328, loss_ce: 0.007109\n",
            "iteration 7035 : loss : 0.035935, loss_ce: 0.010926\n",
            "iteration 7036 : loss : 0.030734, loss_ce: 0.006996\n",
            "iteration 7037 : loss : 0.026157, loss_ce: 0.010438\n",
            "iteration 7038 : loss : 0.027499, loss_ce: 0.008178\n",
            "iteration 7039 : loss : 0.075927, loss_ce: 0.006302\n",
            "iteration 7040 : loss : 0.026299, loss_ce: 0.010723\n",
            "iteration 7041 : loss : 0.026739, loss_ce: 0.009929\n",
            "iteration 7042 : loss : 0.033338, loss_ce: 0.011638\n",
            "iteration 7043 : loss : 0.028281, loss_ce: 0.011276\n",
            "iteration 7044 : loss : 0.031123, loss_ce: 0.008897\n",
            "iteration 7045 : loss : 0.031594, loss_ce: 0.010120\n",
            "iteration 7046 : loss : 0.026092, loss_ce: 0.014419\n",
            "iteration 7047 : loss : 0.026338, loss_ce: 0.011103\n",
            "iteration 7048 : loss : 0.030786, loss_ce: 0.009926\n",
            "iteration 7049 : loss : 0.024626, loss_ce: 0.007013\n",
            "iteration 7050 : loss : 0.024948, loss_ce: 0.009853\n",
            "iteration 7051 : loss : 0.032776, loss_ce: 0.014880\n",
            "iteration 7052 : loss : 0.028591, loss_ce: 0.007372\n",
            "iteration 7053 : loss : 0.035202, loss_ce: 0.007370\n",
            "iteration 7054 : loss : 0.039335, loss_ce: 0.011086\n",
            "iteration 7055 : loss : 0.027497, loss_ce: 0.010919\n",
            "iteration 7056 : loss : 0.025358, loss_ce: 0.011129\n",
            "iteration 7057 : loss : 0.029319, loss_ce: 0.007059\n",
            "iteration 7058 : loss : 0.028488, loss_ce: 0.009007\n",
            "iteration 7059 : loss : 0.031861, loss_ce: 0.014593\n",
            "iteration 7060 : loss : 0.025768, loss_ce: 0.011062\n",
            "iteration 7061 : loss : 0.027122, loss_ce: 0.013938\n",
            "iteration 7062 : loss : 0.077403, loss_ce: 0.006756\n",
            "iteration 7063 : loss : 0.023823, loss_ce: 0.008708\n",
            "iteration 7064 : loss : 0.024971, loss_ce: 0.010787\n",
            "iteration 7065 : loss : 0.029078, loss_ce: 0.010569\n",
            "iteration 7066 : loss : 0.029645, loss_ce: 0.009411\n",
            "iteration 7067 : loss : 0.027425, loss_ce: 0.008927\n",
            "iteration 7068 : loss : 0.036516, loss_ce: 0.009563\n",
            "iteration 7069 : loss : 0.030155, loss_ce: 0.005319\n",
            "iteration 7070 : loss : 0.030773, loss_ce: 0.009939\n",
            "iteration 7071 : loss : 0.030131, loss_ce: 0.007320\n",
            "iteration 7072 : loss : 0.026881, loss_ce: 0.010296\n",
            "iteration 7073 : loss : 0.025138, loss_ce: 0.006783\n",
            "iteration 7074 : loss : 0.029544, loss_ce: 0.007944\n",
            "iteration 7075 : loss : 0.023074, loss_ce: 0.009601\n",
            "iteration 7076 : loss : 0.031143, loss_ce: 0.013721\n",
            "iteration 7077 : loss : 0.027127, loss_ce: 0.009980\n",
            "iteration 7078 : loss : 0.028231, loss_ce: 0.010911\n",
            "iteration 7079 : loss : 0.029084, loss_ce: 0.007402\n",
            "iteration 7080 : loss : 0.028584, loss_ce: 0.008269\n",
            "iteration 7081 : loss : 0.026514, loss_ce: 0.013458\n",
            "iteration 7082 : loss : 0.028677, loss_ce: 0.011229\n",
            "iteration 7083 : loss : 0.040600, loss_ce: 0.010424\n",
            "iteration 7084 : loss : 0.025385, loss_ce: 0.007577\n",
            "iteration 7085 : loss : 0.022526, loss_ce: 0.006679\n",
            "iteration 7086 : loss : 0.034487, loss_ce: 0.006687\n",
            "iteration 7087 : loss : 0.035438, loss_ce: 0.017411\n",
            "iteration 7088 : loss : 0.024712, loss_ce: 0.006515\n",
            "iteration 7089 : loss : 0.030373, loss_ce: 0.010941\n",
            "iteration 7090 : loss : 0.075148, loss_ce: 0.004973\n",
            "iteration 7091 : loss : 0.033805, loss_ce: 0.013213\n",
            "iteration 7092 : loss : 0.024357, loss_ce: 0.007253\n",
            "iteration 7093 : loss : 0.031564, loss_ce: 0.012647\n",
            "iteration 7094 : loss : 0.029790, loss_ce: 0.013062\n",
            "iteration 7095 : loss : 0.027503, loss_ce: 0.008541\n",
            "iteration 7096 : loss : 0.029717, loss_ce: 0.007493\n",
            "iteration 7097 : loss : 0.028502, loss_ce: 0.009944\n",
            "iteration 7098 : loss : 0.022202, loss_ce: 0.006865\n",
            "iteration 7099 : loss : 0.032015, loss_ce: 0.009824\n",
            "iteration 7100 : loss : 0.028810, loss_ce: 0.007505\n",
            "iteration 7101 : loss : 0.027180, loss_ce: 0.007346\n",
            "iteration 7102 : loss : 0.029140, loss_ce: 0.007536\n",
            "iteration 7103 : loss : 0.026292, loss_ce: 0.004478\n",
            "iteration 7104 : loss : 0.030744, loss_ce: 0.011332\n",
            " 64%|█████████████████▎         | 96/150 [2:53:18<1:37:29, 108.32s/it]iteration 7105 : loss : 0.024651, loss_ce: 0.011372\n",
            "iteration 7106 : loss : 0.077072, loss_ce: 0.006501\n",
            "iteration 7107 : loss : 0.034227, loss_ce: 0.013693\n",
            "iteration 7108 : loss : 0.034407, loss_ce: 0.008487\n",
            "iteration 7109 : loss : 0.029257, loss_ce: 0.013189\n",
            "iteration 7110 : loss : 0.082501, loss_ce: 0.008529\n",
            "iteration 7111 : loss : 0.021371, loss_ce: 0.005529\n",
            "iteration 7112 : loss : 0.029537, loss_ce: 0.007853\n",
            "iteration 7113 : loss : 0.025529, loss_ce: 0.009113\n",
            "iteration 7114 : loss : 0.029092, loss_ce: 0.010730\n",
            "iteration 7115 : loss : 0.029846, loss_ce: 0.008415\n",
            "iteration 7116 : loss : 0.028060, loss_ce: 0.006107\n",
            "iteration 7117 : loss : 0.027761, loss_ce: 0.009519\n",
            "iteration 7118 : loss : 0.026959, loss_ce: 0.010300\n",
            "iteration 7119 : loss : 0.038304, loss_ce: 0.013825\n",
            "iteration 7120 : loss : 0.028121, loss_ce: 0.010497\n",
            "iteration 7121 : loss : 0.024165, loss_ce: 0.005383\n",
            "iteration 7122 : loss : 0.027296, loss_ce: 0.008611\n",
            "iteration 7123 : loss : 0.031010, loss_ce: 0.012717\n",
            "iteration 7124 : loss : 0.052141, loss_ce: 0.006992\n",
            "iteration 7125 : loss : 0.025246, loss_ce: 0.009770\n",
            "iteration 7126 : loss : 0.042589, loss_ce: 0.014879\n",
            "iteration 7127 : loss : 0.028635, loss_ce: 0.005980\n",
            "iteration 7128 : loss : 0.078736, loss_ce: 0.006229\n",
            "iteration 7129 : loss : 0.026561, loss_ce: 0.008896\n",
            "iteration 7130 : loss : 0.033608, loss_ce: 0.011223\n",
            "iteration 7131 : loss : 0.057382, loss_ce: 0.006031\n",
            "iteration 7132 : loss : 0.045114, loss_ce: 0.006779\n",
            "iteration 7133 : loss : 0.025678, loss_ce: 0.007157\n",
            "iteration 7134 : loss : 0.038575, loss_ce: 0.011858\n",
            "iteration 7135 : loss : 0.028313, loss_ce: 0.010963\n",
            "iteration 7136 : loss : 0.032376, loss_ce: 0.009397\n",
            "iteration 7137 : loss : 0.086864, loss_ce: 0.011630\n",
            "iteration 7138 : loss : 0.027134, loss_ce: 0.006229\n",
            "iteration 7139 : loss : 0.082492, loss_ce: 0.008657\n",
            "iteration 7140 : loss : 0.034688, loss_ce: 0.015813\n",
            "iteration 7141 : loss : 0.040634, loss_ce: 0.012088\n",
            "iteration 7142 : loss : 0.034317, loss_ce: 0.013776\n",
            "iteration 7143 : loss : 0.081822, loss_ce: 0.008130\n",
            "iteration 7144 : loss : 0.032978, loss_ce: 0.010389\n",
            "iteration 7145 : loss : 0.029513, loss_ce: 0.013501\n",
            "iteration 7146 : loss : 0.028519, loss_ce: 0.010206\n",
            "iteration 7147 : loss : 0.029767, loss_ce: 0.007772\n",
            "iteration 7148 : loss : 0.029176, loss_ce: 0.010592\n",
            "iteration 7149 : loss : 0.027846, loss_ce: 0.007670\n",
            "iteration 7150 : loss : 0.032806, loss_ce: 0.010207\n",
            "iteration 7151 : loss : 0.037853, loss_ce: 0.010774\n",
            "iteration 7152 : loss : 0.024311, loss_ce: 0.004794\n",
            "iteration 7153 : loss : 0.030785, loss_ce: 0.008055\n",
            "iteration 7154 : loss : 0.062896, loss_ce: 0.009823\n",
            "iteration 7155 : loss : 0.028503, loss_ce: 0.011084\n",
            "iteration 7156 : loss : 0.028915, loss_ce: 0.009454\n",
            "iteration 7157 : loss : 0.028294, loss_ce: 0.011349\n",
            "iteration 7158 : loss : 0.031899, loss_ce: 0.007706\n",
            "iteration 7159 : loss : 0.029712, loss_ce: 0.013191\n",
            "iteration 7160 : loss : 0.030605, loss_ce: 0.012664\n",
            "iteration 7161 : loss : 0.032117, loss_ce: 0.010813\n",
            "iteration 7162 : loss : 0.030585, loss_ce: 0.010510\n",
            "iteration 7163 : loss : 0.031542, loss_ce: 0.012519\n",
            "iteration 7164 : loss : 0.029697, loss_ce: 0.010008\n",
            "iteration 7165 : loss : 0.028342, loss_ce: 0.011326\n",
            "iteration 7166 : loss : 0.081310, loss_ce: 0.011166\n",
            "iteration 7167 : loss : 0.026477, loss_ce: 0.011014\n",
            "iteration 7168 : loss : 0.029747, loss_ce: 0.010428\n",
            "iteration 7169 : loss : 0.030821, loss_ce: 0.011487\n",
            "iteration 7170 : loss : 0.030623, loss_ce: 0.008432\n",
            "iteration 7171 : loss : 0.067862, loss_ce: 0.013804\n",
            "iteration 7172 : loss : 0.026548, loss_ce: 0.008626\n",
            "iteration 7173 : loss : 0.033642, loss_ce: 0.015486\n",
            "iteration 7174 : loss : 0.025264, loss_ce: 0.008259\n",
            "iteration 7175 : loss : 0.028595, loss_ce: 0.007229\n",
            "iteration 7176 : loss : 0.027773, loss_ce: 0.009091\n",
            "iteration 7177 : loss : 0.078531, loss_ce: 0.007068\n",
            "iteration 7178 : loss : 0.026787, loss_ce: 0.010254\n",
            " 65%|█████████████████▍         | 97/150 [2:55:05<1:35:33, 108.18s/it]iteration 7179 : loss : 0.027519, loss_ce: 0.012461\n",
            "iteration 7180 : loss : 0.031900, loss_ce: 0.010124\n",
            "iteration 7181 : loss : 0.043506, loss_ce: 0.016203\n",
            "iteration 7182 : loss : 0.037907, loss_ce: 0.009843\n",
            "iteration 7183 : loss : 0.029615, loss_ce: 0.007123\n",
            "iteration 7184 : loss : 0.024002, loss_ce: 0.005171\n",
            "iteration 7185 : loss : 0.030472, loss_ce: 0.014568\n",
            "iteration 7186 : loss : 0.029870, loss_ce: 0.009589\n",
            "iteration 7187 : loss : 0.076867, loss_ce: 0.006806\n",
            "iteration 7188 : loss : 0.025404, loss_ce: 0.007897\n",
            "iteration 7189 : loss : 0.076568, loss_ce: 0.007950\n",
            "iteration 7190 : loss : 0.028461, loss_ce: 0.012864\n",
            "iteration 7191 : loss : 0.032732, loss_ce: 0.007469\n",
            "iteration 7192 : loss : 0.025739, loss_ce: 0.008993\n",
            "iteration 7193 : loss : 0.057020, loss_ce: 0.007326\n",
            "iteration 7194 : loss : 0.026562, loss_ce: 0.010690\n",
            "iteration 7195 : loss : 0.033551, loss_ce: 0.008043\n",
            "iteration 7196 : loss : 0.034795, loss_ce: 0.008805\n",
            "iteration 7197 : loss : 0.027466, loss_ce: 0.010200\n",
            "iteration 7198 : loss : 0.027189, loss_ce: 0.005756\n",
            "iteration 7199 : loss : 0.025457, loss_ce: 0.011419\n",
            "iteration 7200 : loss : 0.030556, loss_ce: 0.009645\n",
            "iteration 7201 : loss : 0.084359, loss_ce: 0.007217\n",
            "iteration 7202 : loss : 0.076482, loss_ce: 0.007976\n",
            "iteration 7203 : loss : 0.025495, loss_ce: 0.009130\n",
            "iteration 7204 : loss : 0.040271, loss_ce: 0.016222\n",
            "iteration 7205 : loss : 0.027942, loss_ce: 0.011796\n",
            "iteration 7206 : loss : 0.027414, loss_ce: 0.008515\n",
            "iteration 7207 : loss : 0.079925, loss_ce: 0.010741\n",
            "iteration 7208 : loss : 0.021566, loss_ce: 0.006365\n",
            "iteration 7209 : loss : 0.029828, loss_ce: 0.010242\n",
            "iteration 7210 : loss : 0.034546, loss_ce: 0.008815\n",
            "iteration 7211 : loss : 0.030673, loss_ce: 0.009430\n",
            "iteration 7212 : loss : 0.025036, loss_ce: 0.009941\n",
            "iteration 7213 : loss : 0.029780, loss_ce: 0.006833\n",
            "iteration 7214 : loss : 0.027709, loss_ce: 0.008621\n",
            "iteration 7215 : loss : 0.030012, loss_ce: 0.007774\n",
            "iteration 7216 : loss : 0.029399, loss_ce: 0.015000\n",
            "iteration 7217 : loss : 0.026727, loss_ce: 0.007280\n",
            "iteration 7218 : loss : 0.026822, loss_ce: 0.010261\n",
            "iteration 7219 : loss : 0.031452, loss_ce: 0.014878\n",
            "iteration 7220 : loss : 0.075016, loss_ce: 0.005521\n",
            "iteration 7221 : loss : 0.024002, loss_ce: 0.005277\n",
            "iteration 7222 : loss : 0.029568, loss_ce: 0.013423\n",
            "iteration 7223 : loss : 0.025987, loss_ce: 0.009868\n",
            "iteration 7224 : loss : 0.080211, loss_ce: 0.011058\n",
            "iteration 7225 : loss : 0.075396, loss_ce: 0.007010\n",
            "iteration 7226 : loss : 0.024955, loss_ce: 0.008380\n",
            "iteration 7227 : loss : 0.148376, loss_ce: 0.002875\n",
            "iteration 7228 : loss : 0.025879, loss_ce: 0.012157\n",
            "iteration 7229 : loss : 0.030966, loss_ce: 0.009306\n",
            "iteration 7230 : loss : 0.033741, loss_ce: 0.011151\n",
            "iteration 7231 : loss : 0.033769, loss_ce: 0.013726\n",
            "iteration 7232 : loss : 0.027674, loss_ce: 0.009131\n",
            "iteration 7233 : loss : 0.027082, loss_ce: 0.007612\n",
            "iteration 7234 : loss : 0.030546, loss_ce: 0.013227\n",
            "iteration 7235 : loss : 0.027109, loss_ce: 0.008105\n",
            "iteration 7236 : loss : 0.028854, loss_ce: 0.008038\n",
            "iteration 7237 : loss : 0.031866, loss_ce: 0.010325\n",
            "iteration 7238 : loss : 0.034127, loss_ce: 0.010895\n",
            "iteration 7239 : loss : 0.037909, loss_ce: 0.014054\n",
            "iteration 7240 : loss : 0.032422, loss_ce: 0.008998\n",
            "iteration 7241 : loss : 0.030085, loss_ce: 0.012862\n",
            "iteration 7242 : loss : 0.030606, loss_ce: 0.011831\n",
            "iteration 7243 : loss : 0.031882, loss_ce: 0.011089\n",
            "iteration 7244 : loss : 0.026160, loss_ce: 0.006141\n",
            "iteration 7245 : loss : 0.030263, loss_ce: 0.008609\n",
            "iteration 7246 : loss : 0.030168, loss_ce: 0.009640\n",
            "iteration 7247 : loss : 0.029887, loss_ce: 0.012291\n",
            "iteration 7248 : loss : 0.025682, loss_ce: 0.006764\n",
            "iteration 7249 : loss : 0.048574, loss_ce: 0.006283\n",
            "iteration 7250 : loss : 0.027471, loss_ce: 0.011716\n",
            "iteration 7251 : loss : 0.028042, loss_ce: 0.009461\n",
            "iteration 7252 : loss : 0.073002, loss_ce: 0.007408\n",
            " 65%|█████████████████▋         | 98/150 [2:56:54<1:33:53, 108.34s/it]iteration 7253 : loss : 0.030868, loss_ce: 0.013149\n",
            "iteration 7254 : loss : 0.031095, loss_ce: 0.009187\n",
            "iteration 7255 : loss : 0.030609, loss_ce: 0.010017\n",
            "iteration 7256 : loss : 0.027890, loss_ce: 0.010000\n",
            "iteration 7257 : loss : 0.031921, loss_ce: 0.009690\n",
            "iteration 7258 : loss : 0.078558, loss_ce: 0.008540\n",
            "iteration 7259 : loss : 0.023337, loss_ce: 0.007104\n",
            "iteration 7260 : loss : 0.034303, loss_ce: 0.011339\n",
            "iteration 7261 : loss : 0.026334, loss_ce: 0.011489\n",
            "iteration 7262 : loss : 0.025142, loss_ce: 0.009277\n",
            "iteration 7263 : loss : 0.029755, loss_ce: 0.007853\n",
            "iteration 7264 : loss : 0.027426, loss_ce: 0.008515\n",
            "iteration 7265 : loss : 0.032520, loss_ce: 0.010787\n",
            "iteration 7266 : loss : 0.027002, loss_ce: 0.010296\n",
            "iteration 7267 : loss : 0.027119, loss_ce: 0.010216\n",
            "iteration 7268 : loss : 0.026138, loss_ce: 0.012276\n",
            "iteration 7269 : loss : 0.030569, loss_ce: 0.007852\n",
            "iteration 7270 : loss : 0.028096, loss_ce: 0.007423\n",
            "iteration 7271 : loss : 0.026359, loss_ce: 0.009761\n",
            "iteration 7272 : loss : 0.028371, loss_ce: 0.005543\n",
            "iteration 7273 : loss : 0.079330, loss_ce: 0.010527\n",
            "iteration 7274 : loss : 0.022863, loss_ce: 0.006342\n",
            "iteration 7275 : loss : 0.029083, loss_ce: 0.009939\n",
            "iteration 7276 : loss : 0.032860, loss_ce: 0.010756\n",
            "iteration 7277 : loss : 0.031761, loss_ce: 0.010250\n",
            "iteration 7278 : loss : 0.023789, loss_ce: 0.006470\n",
            "iteration 7279 : loss : 0.077726, loss_ce: 0.009658\n",
            "iteration 7280 : loss : 0.027249, loss_ce: 0.008116\n",
            "iteration 7281 : loss : 0.028441, loss_ce: 0.008211\n",
            "iteration 7282 : loss : 0.031933, loss_ce: 0.014488\n",
            "iteration 7283 : loss : 0.037183, loss_ce: 0.005102\n",
            "iteration 7284 : loss : 0.027268, loss_ce: 0.010780\n",
            "iteration 7285 : loss : 0.022504, loss_ce: 0.009104\n",
            "iteration 7286 : loss : 0.024745, loss_ce: 0.008230\n",
            "iteration 7287 : loss : 0.043725, loss_ce: 0.007314\n",
            "iteration 7288 : loss : 0.031964, loss_ce: 0.014787\n",
            "iteration 7289 : loss : 0.027548, loss_ce: 0.008223\n",
            "iteration 7290 : loss : 0.028963, loss_ce: 0.010468\n",
            "iteration 7291 : loss : 0.028218, loss_ce: 0.010867\n",
            "iteration 7292 : loss : 0.075758, loss_ce: 0.006329\n",
            "iteration 7293 : loss : 0.030018, loss_ce: 0.009495\n",
            "iteration 7294 : loss : 0.027678, loss_ce: 0.008198\n",
            "iteration 7295 : loss : 0.024951, loss_ce: 0.006628\n",
            "iteration 7296 : loss : 0.031635, loss_ce: 0.010979\n",
            "iteration 7297 : loss : 0.046120, loss_ce: 0.007044\n",
            "iteration 7298 : loss : 0.028656, loss_ce: 0.006600\n",
            "iteration 7299 : loss : 0.024946, loss_ce: 0.009568\n",
            "iteration 7300 : loss : 0.025598, loss_ce: 0.010561\n",
            "iteration 7301 : loss : 0.037716, loss_ce: 0.003708\n",
            "iteration 7302 : loss : 0.030277, loss_ce: 0.013302\n",
            "iteration 7303 : loss : 0.026789, loss_ce: 0.010576\n",
            "iteration 7304 : loss : 0.023046, loss_ce: 0.004188\n",
            "iteration 7305 : loss : 0.027256, loss_ce: 0.009462\n",
            "iteration 7306 : loss : 0.030117, loss_ce: 0.007058\n",
            "iteration 7307 : loss : 0.030452, loss_ce: 0.008598\n",
            "iteration 7308 : loss : 0.025401, loss_ce: 0.009632\n",
            "iteration 7309 : loss : 0.080696, loss_ce: 0.010331\n",
            "iteration 7310 : loss : 0.032034, loss_ce: 0.012344\n",
            "iteration 7311 : loss : 0.077827, loss_ce: 0.005710\n",
            "iteration 7312 : loss : 0.027221, loss_ce: 0.009447\n",
            "iteration 7313 : loss : 0.026257, loss_ce: 0.012255\n",
            "iteration 7314 : loss : 0.032172, loss_ce: 0.008582\n",
            "iteration 7315 : loss : 0.028480, loss_ce: 0.008982\n",
            "iteration 7316 : loss : 0.032097, loss_ce: 0.008357\n",
            "iteration 7317 : loss : 0.076689, loss_ce: 0.008201\n",
            "iteration 7318 : loss : 0.028660, loss_ce: 0.011168\n",
            "iteration 7319 : loss : 0.028960, loss_ce: 0.009931\n",
            "iteration 7320 : loss : 0.029661, loss_ce: 0.015713\n",
            "iteration 7321 : loss : 0.032567, loss_ce: 0.010939\n",
            "iteration 7322 : loss : 0.028960, loss_ce: 0.013219\n",
            "iteration 7323 : loss : 0.029142, loss_ce: 0.011456\n",
            "iteration 7324 : loss : 0.027941, loss_ce: 0.007958\n",
            "iteration 7325 : loss : 0.081399, loss_ce: 0.005557\n",
            "iteration 7326 : loss : 0.031141, loss_ce: 0.017048\n",
            " 66%|█████████████████▊         | 99/150 [2:58:44<1:32:22, 108.67s/it]iteration 7327 : loss : 0.029863, loss_ce: 0.013326\n",
            "iteration 7328 : loss : 0.029365, loss_ce: 0.010400\n",
            "iteration 7329 : loss : 0.028066, loss_ce: 0.006488\n",
            "iteration 7330 : loss : 0.081998, loss_ce: 0.012817\n",
            "iteration 7331 : loss : 0.028264, loss_ce: 0.008737\n",
            "iteration 7332 : loss : 0.033957, loss_ce: 0.008717\n",
            "iteration 7333 : loss : 0.023689, loss_ce: 0.006269\n",
            "iteration 7334 : loss : 0.030210, loss_ce: 0.010804\n",
            "iteration 7335 : loss : 0.026455, loss_ce: 0.008781\n",
            "iteration 7336 : loss : 0.022584, loss_ce: 0.009158\n",
            "iteration 7337 : loss : 0.027547, loss_ce: 0.007757\n",
            "iteration 7338 : loss : 0.028616, loss_ce: 0.012400\n",
            "iteration 7339 : loss : 0.029465, loss_ce: 0.006143\n",
            "iteration 7340 : loss : 0.022796, loss_ce: 0.006703\n",
            "iteration 7341 : loss : 0.027545, loss_ce: 0.008809\n",
            "iteration 7342 : loss : 0.024606, loss_ce: 0.006899\n",
            "iteration 7343 : loss : 0.021607, loss_ce: 0.005266\n",
            "iteration 7344 : loss : 0.028872, loss_ce: 0.009094\n",
            "iteration 7345 : loss : 0.028402, loss_ce: 0.008656\n",
            "iteration 7346 : loss : 0.027209, loss_ce: 0.012730\n",
            "iteration 7347 : loss : 0.026167, loss_ce: 0.008180\n",
            "iteration 7348 : loss : 0.076001, loss_ce: 0.007381\n",
            "iteration 7349 : loss : 0.047717, loss_ce: 0.016035\n",
            "iteration 7350 : loss : 0.026905, loss_ce: 0.006037\n",
            "iteration 7351 : loss : 0.049646, loss_ce: 0.010805\n",
            "iteration 7352 : loss : 0.027105, loss_ce: 0.007559\n",
            "iteration 7353 : loss : 0.101175, loss_ce: 0.004397\n",
            "iteration 7354 : loss : 0.031911, loss_ce: 0.008236\n",
            "iteration 7355 : loss : 0.023979, loss_ce: 0.008698\n",
            "iteration 7356 : loss : 0.029263, loss_ce: 0.010494\n",
            "iteration 7357 : loss : 0.033984, loss_ce: 0.010080\n",
            "iteration 7358 : loss : 0.028348, loss_ce: 0.010357\n",
            "iteration 7359 : loss : 0.031093, loss_ce: 0.012118\n",
            "iteration 7360 : loss : 0.033312, loss_ce: 0.014309\n",
            "iteration 7361 : loss : 0.038438, loss_ce: 0.010288\n",
            "iteration 7362 : loss : 0.031404, loss_ce: 0.010636\n",
            "iteration 7363 : loss : 0.033035, loss_ce: 0.010838\n",
            "iteration 7364 : loss : 0.029321, loss_ce: 0.009926\n",
            "iteration 7365 : loss : 0.030726, loss_ce: 0.010002\n",
            "iteration 7366 : loss : 0.032737, loss_ce: 0.008470\n",
            "iteration 7367 : loss : 0.028463, loss_ce: 0.007573\n",
            "iteration 7368 : loss : 0.026162, loss_ce: 0.008060\n",
            "iteration 7369 : loss : 0.068002, loss_ce: 0.009405\n",
            "iteration 7370 : loss : 0.034027, loss_ce: 0.009321\n",
            "iteration 7371 : loss : 0.027068, loss_ce: 0.009893\n",
            "iteration 7372 : loss : 0.031246, loss_ce: 0.006447\n",
            "iteration 7373 : loss : 0.028316, loss_ce: 0.012036\n",
            "iteration 7374 : loss : 0.042647, loss_ce: 0.005058\n",
            "iteration 7375 : loss : 0.033967, loss_ce: 0.013370\n",
            "iteration 7376 : loss : 0.031486, loss_ce: 0.012614\n",
            "iteration 7377 : loss : 0.029052, loss_ce: 0.007647\n",
            "iteration 7378 : loss : 0.026402, loss_ce: 0.008216\n",
            "iteration 7379 : loss : 0.034154, loss_ce: 0.014891\n",
            "iteration 7380 : loss : 0.037100, loss_ce: 0.012329\n",
            "iteration 7381 : loss : 0.082396, loss_ce: 0.009010\n",
            "iteration 7382 : loss : 0.027116, loss_ce: 0.012115\n",
            "iteration 7383 : loss : 0.027672, loss_ce: 0.011351\n",
            "iteration 7384 : loss : 0.077392, loss_ce: 0.008612\n",
            "iteration 7385 : loss : 0.028046, loss_ce: 0.012173\n",
            "iteration 7386 : loss : 0.031868, loss_ce: 0.008199\n",
            "iteration 7387 : loss : 0.026685, loss_ce: 0.010809\n",
            "iteration 7388 : loss : 0.034993, loss_ce: 0.012226\n",
            "iteration 7389 : loss : 0.035215, loss_ce: 0.010314\n",
            "iteration 7390 : loss : 0.027630, loss_ce: 0.009779\n",
            "iteration 7391 : loss : 0.028994, loss_ce: 0.010927\n",
            "iteration 7392 : loss : 0.029843, loss_ce: 0.008250\n",
            "iteration 7393 : loss : 0.030166, loss_ce: 0.010649\n",
            "iteration 7394 : loss : 0.026409, loss_ce: 0.010356\n",
            "iteration 7395 : loss : 0.026375, loss_ce: 0.009498\n",
            "iteration 7396 : loss : 0.059581, loss_ce: 0.008426\n",
            "iteration 7397 : loss : 0.026338, loss_ce: 0.007413\n",
            "iteration 7398 : loss : 0.025187, loss_ce: 0.009220\n",
            "iteration 7399 : loss : 0.029856, loss_ce: 0.010746\n",
            "iteration 7400 : loss : 0.030545, loss_ce: 0.013739\n",
            "save model to /content/project_TransUNet/project_TransUNet/model/TU_Synapse224/TU_pretrain_R50-ViT-B_16_skip3_epo150_bs24_224/epoch_99.pth\n",
            " 67%|█████████████████▎        | 100/150 [3:00:33<1:30:41, 108.83s/it]iteration 7401 : loss : 0.028219, loss_ce: 0.011961\n",
            "iteration 7402 : loss : 0.067188, loss_ce: 0.005932\n",
            "iteration 7403 : loss : 0.028790, loss_ce: 0.010946\n",
            "iteration 7404 : loss : 0.079209, loss_ce: 0.008857\n",
            "iteration 7405 : loss : 0.030008, loss_ce: 0.011601\n",
            "iteration 7406 : loss : 0.029817, loss_ce: 0.011495\n",
            "iteration 7407 : loss : 0.030834, loss_ce: 0.009473\n",
            "iteration 7408 : loss : 0.024533, loss_ce: 0.007417\n",
            "iteration 7409 : loss : 0.034296, loss_ce: 0.010845\n",
            "iteration 7410 : loss : 0.029955, loss_ce: 0.010306\n",
            "iteration 7411 : loss : 0.024041, loss_ce: 0.007154\n",
            "iteration 7412 : loss : 0.033998, loss_ce: 0.005788\n",
            "iteration 7413 : loss : 0.038586, loss_ce: 0.012041\n",
            "iteration 7414 : loss : 0.030179, loss_ce: 0.010409\n",
            "iteration 7415 : loss : 0.027573, loss_ce: 0.011764\n",
            "iteration 7416 : loss : 0.036576, loss_ce: 0.011332\n",
            "iteration 7417 : loss : 0.075085, loss_ce: 0.008188\n",
            "iteration 7418 : loss : 0.081407, loss_ce: 0.010089\n",
            "iteration 7419 : loss : 0.024983, loss_ce: 0.010413\n",
            "iteration 7420 : loss : 0.073735, loss_ce: 0.006600\n",
            "iteration 7421 : loss : 0.026491, loss_ce: 0.009178\n",
            "iteration 7422 : loss : 0.028835, loss_ce: 0.013215\n",
            "iteration 7423 : loss : 0.038565, loss_ce: 0.009082\n",
            "iteration 7424 : loss : 0.033043, loss_ce: 0.007431\n",
            "iteration 7425 : loss : 0.029334, loss_ce: 0.008273\n",
            "iteration 7426 : loss : 0.029448, loss_ce: 0.007205\n",
            "iteration 7427 : loss : 0.035283, loss_ce: 0.010811\n",
            "iteration 7428 : loss : 0.030735, loss_ce: 0.011802\n",
            "iteration 7429 : loss : 0.028862, loss_ce: 0.007640\n",
            "iteration 7430 : loss : 0.026890, loss_ce: 0.010500\n",
            "iteration 7431 : loss : 0.027300, loss_ce: 0.009509\n",
            "iteration 7432 : loss : 0.027287, loss_ce: 0.009382\n",
            "iteration 7433 : loss : 0.026444, loss_ce: 0.006264\n",
            "iteration 7434 : loss : 0.029395, loss_ce: 0.009417\n",
            "iteration 7435 : loss : 0.023595, loss_ce: 0.006117\n",
            "iteration 7436 : loss : 0.026759, loss_ce: 0.007865\n",
            "iteration 7437 : loss : 0.023783, loss_ce: 0.007396\n",
            "iteration 7438 : loss : 0.025924, loss_ce: 0.007382\n",
            "iteration 7439 : loss : 0.030363, loss_ce: 0.009261\n",
            "iteration 7440 : loss : 0.029526, loss_ce: 0.010535\n",
            "iteration 7441 : loss : 0.024440, loss_ce: 0.009435\n",
            "iteration 7442 : loss : 0.027682, loss_ce: 0.007313\n",
            "iteration 7443 : loss : 0.035342, loss_ce: 0.007780\n",
            "iteration 7444 : loss : 0.030380, loss_ce: 0.008991\n",
            "iteration 7445 : loss : 0.073366, loss_ce: 0.008220\n",
            "iteration 7446 : loss : 0.028964, loss_ce: 0.008812\n",
            "iteration 7447 : loss : 0.026824, loss_ce: 0.006416\n",
            "iteration 7448 : loss : 0.027709, loss_ce: 0.006721\n",
            "iteration 7449 : loss : 0.080359, loss_ce: 0.008347\n",
            "iteration 7450 : loss : 0.028118, loss_ce: 0.007729\n",
            "iteration 7451 : loss : 0.080693, loss_ce: 0.008337\n",
            "iteration 7452 : loss : 0.027794, loss_ce: 0.007771\n",
            "iteration 7453 : loss : 0.024453, loss_ce: 0.009382\n",
            "iteration 7454 : loss : 0.024872, loss_ce: 0.005867\n",
            "iteration 7455 : loss : 0.028987, loss_ce: 0.013181\n",
            "iteration 7456 : loss : 0.024865, loss_ce: 0.010307\n",
            "iteration 7457 : loss : 0.028356, loss_ce: 0.011285\n",
            "iteration 7458 : loss : 0.026681, loss_ce: 0.007019\n",
            "iteration 7459 : loss : 0.034931, loss_ce: 0.022831\n",
            "iteration 7460 : loss : 0.030697, loss_ce: 0.010999\n",
            "iteration 7461 : loss : 0.080211, loss_ce: 0.009137\n",
            "iteration 7462 : loss : 0.036482, loss_ce: 0.005559\n",
            "iteration 7463 : loss : 0.037512, loss_ce: 0.005455\n",
            "iteration 7464 : loss : 0.034083, loss_ce: 0.015413\n",
            "iteration 7465 : loss : 0.028377, loss_ce: 0.012748\n",
            "iteration 7466 : loss : 0.027741, loss_ce: 0.012613\n",
            "iteration 7467 : loss : 0.032484, loss_ce: 0.014859\n",
            "iteration 7468 : loss : 0.026048, loss_ce: 0.006646\n",
            "iteration 7469 : loss : 0.024699, loss_ce: 0.009042\n",
            "iteration 7470 : loss : 0.067030, loss_ce: 0.009908\n",
            "iteration 7471 : loss : 0.029580, loss_ce: 0.009789\n",
            "iteration 7472 : loss : 0.028632, loss_ce: 0.009345\n",
            "iteration 7473 : loss : 0.022701, loss_ce: 0.006140\n",
            "iteration 7474 : loss : 0.029902, loss_ce: 0.015246\n",
            " 67%|█████████████████▌        | 101/150 [3:02:21<1:28:46, 108.70s/it]iteration 7475 : loss : 0.020702, loss_ce: 0.005486\n",
            "iteration 7476 : loss : 0.034328, loss_ce: 0.016652\n",
            "iteration 7477 : loss : 0.031155, loss_ce: 0.009514\n",
            "iteration 7478 : loss : 0.030307, loss_ce: 0.010107\n",
            "iteration 7479 : loss : 0.030195, loss_ce: 0.009737\n",
            "iteration 7480 : loss : 0.035203, loss_ce: 0.008292\n",
            "iteration 7481 : loss : 0.026441, loss_ce: 0.009441\n",
            "iteration 7482 : loss : 0.033797, loss_ce: 0.010447\n",
            "iteration 7483 : loss : 0.029715, loss_ce: 0.011893\n",
            "iteration 7484 : loss : 0.029247, loss_ce: 0.011349\n",
            "iteration 7485 : loss : 0.029870, loss_ce: 0.008696\n",
            "iteration 7486 : loss : 0.034862, loss_ce: 0.011344\n",
            "iteration 7487 : loss : 0.030793, loss_ce: 0.010604\n",
            "iteration 7488 : loss : 0.029954, loss_ce: 0.012743\n",
            "iteration 7489 : loss : 0.028110, loss_ce: 0.012532\n",
            "iteration 7490 : loss : 0.037891, loss_ce: 0.013578\n",
            "iteration 7491 : loss : 0.029182, loss_ce: 0.009189\n",
            "iteration 7492 : loss : 0.024940, loss_ce: 0.009094\n",
            "iteration 7493 : loss : 0.042466, loss_ce: 0.007539\n",
            "iteration 7494 : loss : 0.029917, loss_ce: 0.012553\n",
            "iteration 7495 : loss : 0.037454, loss_ce: 0.008688\n",
            "iteration 7496 : loss : 0.031081, loss_ce: 0.009962\n",
            "iteration 7497 : loss : 0.030325, loss_ce: 0.011234\n",
            "iteration 7498 : loss : 0.024903, loss_ce: 0.008101\n",
            "iteration 7499 : loss : 0.027474, loss_ce: 0.012266\n",
            "iteration 7500 : loss : 0.024056, loss_ce: 0.009877\n",
            "iteration 7501 : loss : 0.024244, loss_ce: 0.010188\n",
            "iteration 7502 : loss : 0.032769, loss_ce: 0.009969\n",
            "iteration 7503 : loss : 0.031082, loss_ce: 0.008618\n",
            "iteration 7504 : loss : 0.030507, loss_ce: 0.010063\n",
            "iteration 7505 : loss : 0.034110, loss_ce: 0.013803\n",
            "iteration 7506 : loss : 0.030114, loss_ce: 0.009060\n",
            "iteration 7507 : loss : 0.029419, loss_ce: 0.009371\n",
            "iteration 7508 : loss : 0.022460, loss_ce: 0.004828\n",
            "iteration 7509 : loss : 0.037279, loss_ce: 0.011152\n",
            "iteration 7510 : loss : 0.084989, loss_ce: 0.008686\n",
            "iteration 7511 : loss : 0.026849, loss_ce: 0.009377\n",
            "iteration 7512 : loss : 0.023957, loss_ce: 0.010911\n",
            "iteration 7513 : loss : 0.029113, loss_ce: 0.011095\n",
            "iteration 7514 : loss : 0.026594, loss_ce: 0.010240\n",
            "iteration 7515 : loss : 0.025701, loss_ce: 0.010200\n",
            "iteration 7516 : loss : 0.027552, loss_ce: 0.008077\n",
            "iteration 7517 : loss : 0.033027, loss_ce: 0.008156\n",
            "iteration 7518 : loss : 0.032420, loss_ce: 0.008698\n",
            "iteration 7519 : loss : 0.031120, loss_ce: 0.011141\n",
            "iteration 7520 : loss : 0.022016, loss_ce: 0.006483\n",
            "iteration 7521 : loss : 0.024638, loss_ce: 0.005109\n",
            "iteration 7522 : loss : 0.032261, loss_ce: 0.014021\n",
            "iteration 7523 : loss : 0.031206, loss_ce: 0.008529\n",
            "iteration 7524 : loss : 0.023338, loss_ce: 0.007681\n",
            "iteration 7525 : loss : 0.030023, loss_ce: 0.012172\n",
            "iteration 7526 : loss : 0.079444, loss_ce: 0.011949\n",
            "iteration 7527 : loss : 0.027573, loss_ce: 0.005796\n",
            "iteration 7528 : loss : 0.028824, loss_ce: 0.008461\n",
            "iteration 7529 : loss : 0.073975, loss_ce: 0.006167\n",
            "iteration 7530 : loss : 0.079365, loss_ce: 0.004553\n",
            "iteration 7531 : loss : 0.079289, loss_ce: 0.004290\n",
            "iteration 7532 : loss : 0.027323, loss_ce: 0.007879\n",
            "iteration 7533 : loss : 0.022705, loss_ce: 0.009176\n",
            "iteration 7534 : loss : 0.078756, loss_ce: 0.010949\n",
            "iteration 7535 : loss : 0.024427, loss_ce: 0.004769\n",
            "iteration 7536 : loss : 0.029001, loss_ce: 0.010946\n",
            "iteration 7537 : loss : 0.031512, loss_ce: 0.013666\n",
            "iteration 7538 : loss : 0.031052, loss_ce: 0.010181\n",
            "iteration 7539 : loss : 0.042361, loss_ce: 0.009835\n",
            "iteration 7540 : loss : 0.032055, loss_ce: 0.011562\n",
            "iteration 7541 : loss : 0.031471, loss_ce: 0.009042\n",
            "iteration 7542 : loss : 0.026062, loss_ce: 0.010232\n",
            "iteration 7543 : loss : 0.081452, loss_ce: 0.007224\n",
            "iteration 7544 : loss : 0.076518, loss_ce: 0.006107\n",
            "iteration 7545 : loss : 0.024383, loss_ce: 0.006385\n",
            "iteration 7546 : loss : 0.029217, loss_ce: 0.011508\n",
            "iteration 7547 : loss : 0.082535, loss_ce: 0.005142\n",
            "iteration 7548 : loss : 0.078215, loss_ce: 0.009415\n",
            " 68%|█████████████████▋        | 102/150 [3:04:09<1:26:41, 108.37s/it]iteration 7549 : loss : 0.026448, loss_ce: 0.008462\n",
            "iteration 7550 : loss : 0.030865, loss_ce: 0.009848\n",
            "iteration 7551 : loss : 0.032713, loss_ce: 0.010199\n",
            "iteration 7552 : loss : 0.034650, loss_ce: 0.014130\n",
            "iteration 7553 : loss : 0.024182, loss_ce: 0.006433\n",
            "iteration 7554 : loss : 0.028943, loss_ce: 0.011943\n",
            "iteration 7555 : loss : 0.030103, loss_ce: 0.006397\n",
            "iteration 7556 : loss : 0.033856, loss_ce: 0.008820\n",
            "iteration 7557 : loss : 0.024319, loss_ce: 0.007841\n",
            "iteration 7558 : loss : 0.028660, loss_ce: 0.011323\n",
            "iteration 7559 : loss : 0.029035, loss_ce: 0.007651\n",
            "iteration 7560 : loss : 0.076628, loss_ce: 0.005138\n",
            "iteration 7561 : loss : 0.027275, loss_ce: 0.009255\n",
            "iteration 7562 : loss : 0.032655, loss_ce: 0.008110\n",
            "iteration 7563 : loss : 0.030621, loss_ce: 0.011399\n",
            "iteration 7564 : loss : 0.026825, loss_ce: 0.007950\n",
            "iteration 7565 : loss : 0.030041, loss_ce: 0.009431\n",
            "iteration 7566 : loss : 0.027694, loss_ce: 0.011851\n",
            "iteration 7567 : loss : 0.022854, loss_ce: 0.007649\n",
            "iteration 7568 : loss : 0.028176, loss_ce: 0.010855\n",
            "iteration 7569 : loss : 0.026662, loss_ce: 0.011105\n",
            "iteration 7570 : loss : 0.033532, loss_ce: 0.009150\n",
            "iteration 7571 : loss : 0.028259, loss_ce: 0.005290\n",
            "iteration 7572 : loss : 0.025450, loss_ce: 0.008225\n",
            "iteration 7573 : loss : 0.026023, loss_ce: 0.010132\n",
            "iteration 7574 : loss : 0.023518, loss_ce: 0.006977\n",
            "iteration 7575 : loss : 0.030513, loss_ce: 0.011050\n",
            "iteration 7576 : loss : 0.039027, loss_ce: 0.007540\n",
            "iteration 7577 : loss : 0.077664, loss_ce: 0.009599\n",
            "iteration 7578 : loss : 0.026972, loss_ce: 0.006363\n",
            "iteration 7579 : loss : 0.022013, loss_ce: 0.008389\n",
            "iteration 7580 : loss : 0.034558, loss_ce: 0.007803\n",
            "iteration 7581 : loss : 0.028036, loss_ce: 0.006291\n",
            "iteration 7582 : loss : 0.027641, loss_ce: 0.009897\n",
            "iteration 7583 : loss : 0.027376, loss_ce: 0.010143\n",
            "iteration 7584 : loss : 0.037544, loss_ce: 0.009637\n",
            "iteration 7585 : loss : 0.027862, loss_ce: 0.011007\n",
            "iteration 7586 : loss : 0.030310, loss_ce: 0.012358\n",
            "iteration 7587 : loss : 0.028951, loss_ce: 0.011718\n",
            "iteration 7588 : loss : 0.028005, loss_ce: 0.010221\n",
            "iteration 7589 : loss : 0.026067, loss_ce: 0.005421\n",
            "iteration 7590 : loss : 0.031226, loss_ce: 0.008979\n",
            "iteration 7591 : loss : 0.028191, loss_ce: 0.009704\n",
            "iteration 7592 : loss : 0.029411, loss_ce: 0.012181\n",
            "iteration 7593 : loss : 0.024149, loss_ce: 0.011084\n",
            "iteration 7594 : loss : 0.025409, loss_ce: 0.010272\n",
            "iteration 7595 : loss : 0.026912, loss_ce: 0.008033\n",
            "iteration 7596 : loss : 0.039539, loss_ce: 0.007281\n",
            "iteration 7597 : loss : 0.029854, loss_ce: 0.010285\n",
            "iteration 7598 : loss : 0.025237, loss_ce: 0.009905\n",
            "iteration 7599 : loss : 0.025282, loss_ce: 0.012159\n",
            "iteration 7600 : loss : 0.022719, loss_ce: 0.006425\n",
            "iteration 7601 : loss : 0.028075, loss_ce: 0.010315\n",
            "iteration 7602 : loss : 0.026305, loss_ce: 0.006873\n",
            "iteration 7603 : loss : 0.029911, loss_ce: 0.009861\n",
            "iteration 7604 : loss : 0.026172, loss_ce: 0.008904\n",
            "iteration 7605 : loss : 0.030071, loss_ce: 0.010067\n",
            "iteration 7606 : loss : 0.023464, loss_ce: 0.009136\n",
            "iteration 7607 : loss : 0.028437, loss_ce: 0.012990\n",
            "iteration 7608 : loss : 0.027616, loss_ce: 0.006572\n",
            "iteration 7609 : loss : 0.027779, loss_ce: 0.011325\n",
            "iteration 7610 : loss : 0.028105, loss_ce: 0.012412\n",
            "iteration 7611 : loss : 0.029103, loss_ce: 0.011635\n",
            "iteration 7612 : loss : 0.023250, loss_ce: 0.007619\n",
            "iteration 7613 : loss : 0.023629, loss_ce: 0.005590\n",
            "iteration 7614 : loss : 0.029249, loss_ce: 0.010830\n",
            "iteration 7615 : loss : 0.024710, loss_ce: 0.009176\n",
            "iteration 7616 : loss : 0.025381, loss_ce: 0.007755\n",
            "iteration 7617 : loss : 0.078903, loss_ce: 0.005077\n",
            "iteration 7618 : loss : 0.028966, loss_ce: 0.005343\n",
            "iteration 7619 : loss : 0.023380, loss_ce: 0.007025\n",
            "iteration 7620 : loss : 0.077744, loss_ce: 0.008194\n",
            "iteration 7621 : loss : 0.038732, loss_ce: 0.009817\n",
            "iteration 7622 : loss : 0.030704, loss_ce: 0.011720\n",
            " 69%|█████████████████▊        | 103/150 [3:05:59<1:25:15, 108.85s/it]iteration 7623 : loss : 0.028703, loss_ce: 0.010141\n",
            "iteration 7624 : loss : 0.021318, loss_ce: 0.005515\n",
            "iteration 7625 : loss : 0.037639, loss_ce: 0.011056\n",
            "iteration 7626 : loss : 0.029567, loss_ce: 0.011728\n",
            "iteration 7627 : loss : 0.024552, loss_ce: 0.008349\n",
            "iteration 7628 : loss : 0.023549, loss_ce: 0.008919\n",
            "iteration 7629 : loss : 0.026861, loss_ce: 0.009340\n",
            "iteration 7630 : loss : 0.027773, loss_ce: 0.010760\n",
            "iteration 7631 : loss : 0.033291, loss_ce: 0.005117\n",
            "iteration 7632 : loss : 0.028211, loss_ce: 0.013047\n",
            "iteration 7633 : loss : 0.025076, loss_ce: 0.011688\n",
            "iteration 7634 : loss : 0.022812, loss_ce: 0.006512\n",
            "iteration 7635 : loss : 0.040064, loss_ce: 0.010780\n",
            "iteration 7636 : loss : 0.037310, loss_ce: 0.008244\n",
            "iteration 7637 : loss : 0.051199, loss_ce: 0.006621\n",
            "iteration 7638 : loss : 0.024046, loss_ce: 0.010972\n",
            "iteration 7639 : loss : 0.026785, loss_ce: 0.005478\n",
            "iteration 7640 : loss : 0.024407, loss_ce: 0.006967\n",
            "iteration 7641 : loss : 0.022489, loss_ce: 0.010115\n",
            "iteration 7642 : loss : 0.029580, loss_ce: 0.005062\n",
            "iteration 7643 : loss : 0.026412, loss_ce: 0.006021\n",
            "iteration 7644 : loss : 0.027445, loss_ce: 0.006695\n",
            "iteration 7645 : loss : 0.028724, loss_ce: 0.008854\n",
            "iteration 7646 : loss : 0.027749, loss_ce: 0.009257\n",
            "iteration 7647 : loss : 0.027783, loss_ce: 0.008360\n",
            "iteration 7648 : loss : 0.028370, loss_ce: 0.008820\n",
            "iteration 7649 : loss : 0.025577, loss_ce: 0.008240\n",
            "iteration 7650 : loss : 0.029030, loss_ce: 0.008698\n",
            "iteration 7651 : loss : 0.023179, loss_ce: 0.004576\n",
            "iteration 7652 : loss : 0.027417, loss_ce: 0.010278\n",
            "iteration 7653 : loss : 0.026581, loss_ce: 0.006941\n",
            "iteration 7654 : loss : 0.023785, loss_ce: 0.009065\n",
            "iteration 7655 : loss : 0.032323, loss_ce: 0.008155\n",
            "iteration 7656 : loss : 0.027312, loss_ce: 0.010021\n",
            "iteration 7657 : loss : 0.028153, loss_ce: 0.010172\n",
            "iteration 7658 : loss : 0.034494, loss_ce: 0.008488\n",
            "iteration 7659 : loss : 0.077287, loss_ce: 0.010458\n",
            "iteration 7660 : loss : 0.030199, loss_ce: 0.006791\n",
            "iteration 7661 : loss : 0.028336, loss_ce: 0.012615\n",
            "iteration 7662 : loss : 0.079366, loss_ce: 0.009189\n",
            "iteration 7663 : loss : 0.026383, loss_ce: 0.011105\n",
            "iteration 7664 : loss : 0.022957, loss_ce: 0.008391\n",
            "iteration 7665 : loss : 0.027706, loss_ce: 0.011211\n",
            "iteration 7666 : loss : 0.031572, loss_ce: 0.014094\n",
            "iteration 7667 : loss : 0.024381, loss_ce: 0.008269\n",
            "iteration 7668 : loss : 0.031967, loss_ce: 0.013897\n",
            "iteration 7669 : loss : 0.027368, loss_ce: 0.010542\n",
            "iteration 7670 : loss : 0.024349, loss_ce: 0.009208\n",
            "iteration 7671 : loss : 0.029796, loss_ce: 0.010614\n",
            "iteration 7672 : loss : 0.025908, loss_ce: 0.009717\n",
            "iteration 7673 : loss : 0.030153, loss_ce: 0.011997\n",
            "iteration 7674 : loss : 0.027024, loss_ce: 0.009784\n",
            "iteration 7675 : loss : 0.030581, loss_ce: 0.007972\n",
            "iteration 7676 : loss : 0.022102, loss_ce: 0.007504\n",
            "iteration 7677 : loss : 0.029661, loss_ce: 0.006854\n",
            "iteration 7678 : loss : 0.029955, loss_ce: 0.010038\n",
            "iteration 7679 : loss : 0.034374, loss_ce: 0.008894\n",
            "iteration 7680 : loss : 0.023550, loss_ce: 0.008901\n",
            "iteration 7681 : loss : 0.036761, loss_ce: 0.004894\n",
            "iteration 7682 : loss : 0.075384, loss_ce: 0.007855\n",
            "iteration 7683 : loss : 0.030495, loss_ce: 0.010643\n",
            "iteration 7684 : loss : 0.034561, loss_ce: 0.007793\n",
            "iteration 7685 : loss : 0.023539, loss_ce: 0.009107\n",
            "iteration 7686 : loss : 0.025854, loss_ce: 0.010685\n",
            "iteration 7687 : loss : 0.024500, loss_ce: 0.008387\n",
            "iteration 7688 : loss : 0.027338, loss_ce: 0.010716\n",
            "iteration 7689 : loss : 0.028740, loss_ce: 0.012474\n",
            "iteration 7690 : loss : 0.031955, loss_ce: 0.011973\n",
            "iteration 7691 : loss : 0.030295, loss_ce: 0.011144\n",
            "iteration 7692 : loss : 0.025354, loss_ce: 0.008362\n",
            "iteration 7693 : loss : 0.032377, loss_ce: 0.007885\n",
            "iteration 7694 : loss : 0.023920, loss_ce: 0.008002\n",
            "iteration 7695 : loss : 0.078701, loss_ce: 0.009502\n",
            "iteration 7696 : loss : 0.030844, loss_ce: 0.011899\n",
            " 69%|██████████████████        | 104/150 [3:07:48<1:23:37, 109.08s/it]iteration 7697 : loss : 0.028975, loss_ce: 0.009229\n",
            "iteration 7698 : loss : 0.028522, loss_ce: 0.010890\n",
            "iteration 7699 : loss : 0.073290, loss_ce: 0.005929\n",
            "iteration 7700 : loss : 0.029232, loss_ce: 0.012521\n",
            "iteration 7701 : loss : 0.037990, loss_ce: 0.011468\n",
            "iteration 7702 : loss : 0.032276, loss_ce: 0.009530\n",
            "iteration 7703 : loss : 0.029270, loss_ce: 0.008986\n",
            "iteration 7704 : loss : 0.023274, loss_ce: 0.009579\n",
            "iteration 7705 : loss : 0.026538, loss_ce: 0.006828\n",
            "iteration 7706 : loss : 0.027858, loss_ce: 0.010173\n",
            "iteration 7707 : loss : 0.025406, loss_ce: 0.007337\n",
            "iteration 7708 : loss : 0.031577, loss_ce: 0.011770\n",
            "iteration 7709 : loss : 0.026090, loss_ce: 0.010902\n",
            "iteration 7710 : loss : 0.028330, loss_ce: 0.011481\n",
            "iteration 7711 : loss : 0.029782, loss_ce: 0.008828\n",
            "iteration 7712 : loss : 0.031933, loss_ce: 0.009470\n",
            "iteration 7713 : loss : 0.029621, loss_ce: 0.009889\n",
            "iteration 7714 : loss : 0.083298, loss_ce: 0.005713\n",
            "iteration 7715 : loss : 0.077239, loss_ce: 0.008505\n",
            "iteration 7716 : loss : 0.025210, loss_ce: 0.007812\n",
            "iteration 7717 : loss : 0.075209, loss_ce: 0.005313\n",
            "iteration 7718 : loss : 0.026014, loss_ce: 0.008321\n",
            "iteration 7719 : loss : 0.022517, loss_ce: 0.006642\n",
            "iteration 7720 : loss : 0.025711, loss_ce: 0.009226\n",
            "iteration 7721 : loss : 0.027418, loss_ce: 0.009429\n",
            "iteration 7722 : loss : 0.041439, loss_ce: 0.004978\n",
            "iteration 7723 : loss : 0.042278, loss_ce: 0.006558\n",
            "iteration 7724 : loss : 0.034045, loss_ce: 0.011314\n",
            "iteration 7725 : loss : 0.026681, loss_ce: 0.013821\n",
            "iteration 7726 : loss : 0.030586, loss_ce: 0.011117\n",
            "iteration 7727 : loss : 0.023921, loss_ce: 0.006170\n",
            "iteration 7728 : loss : 0.035316, loss_ce: 0.008318\n",
            "iteration 7729 : loss : 0.027257, loss_ce: 0.010547\n",
            "iteration 7730 : loss : 0.030661, loss_ce: 0.012818\n",
            "iteration 7731 : loss : 0.028701, loss_ce: 0.009701\n",
            "iteration 7732 : loss : 0.039425, loss_ce: 0.007475\n",
            "iteration 7733 : loss : 0.031052, loss_ce: 0.008236\n",
            "iteration 7734 : loss : 0.031848, loss_ce: 0.013133\n",
            "iteration 7735 : loss : 0.029326, loss_ce: 0.011871\n",
            "iteration 7736 : loss : 0.031836, loss_ce: 0.005383\n",
            "iteration 7737 : loss : 0.031299, loss_ce: 0.010132\n",
            "iteration 7738 : loss : 0.031040, loss_ce: 0.011525\n",
            "iteration 7739 : loss : 0.032496, loss_ce: 0.010119\n",
            "iteration 7740 : loss : 0.027579, loss_ce: 0.009601\n",
            "iteration 7741 : loss : 0.025492, loss_ce: 0.008286\n",
            "iteration 7742 : loss : 0.032434, loss_ce: 0.007892\n",
            "iteration 7743 : loss : 0.077554, loss_ce: 0.010072\n",
            "iteration 7744 : loss : 0.020378, loss_ce: 0.004994\n",
            "iteration 7745 : loss : 0.025906, loss_ce: 0.009967\n",
            "iteration 7746 : loss : 0.041753, loss_ce: 0.008449\n",
            "iteration 7747 : loss : 0.023242, loss_ce: 0.006492\n",
            "iteration 7748 : loss : 0.025832, loss_ce: 0.010031\n",
            "iteration 7749 : loss : 0.028159, loss_ce: 0.010020\n",
            "iteration 7750 : loss : 0.029091, loss_ce: 0.011066\n",
            "iteration 7751 : loss : 0.030160, loss_ce: 0.013114\n",
            "iteration 7752 : loss : 0.031740, loss_ce: 0.009014\n",
            "iteration 7753 : loss : 0.027187, loss_ce: 0.013140\n",
            "iteration 7754 : loss : 0.046381, loss_ce: 0.006839\n",
            "iteration 7755 : loss : 0.030661, loss_ce: 0.013336\n",
            "iteration 7756 : loss : 0.071729, loss_ce: 0.003085\n",
            "iteration 7757 : loss : 0.026345, loss_ce: 0.008058\n",
            "iteration 7758 : loss : 0.028011, loss_ce: 0.008008\n",
            "iteration 7759 : loss : 0.024139, loss_ce: 0.007417\n",
            "iteration 7760 : loss : 0.025044, loss_ce: 0.007037\n",
            "iteration 7761 : loss : 0.030339, loss_ce: 0.010412\n",
            "iteration 7762 : loss : 0.031317, loss_ce: 0.011912\n",
            "iteration 7763 : loss : 0.030896, loss_ce: 0.011859\n",
            "iteration 7764 : loss : 0.028898, loss_ce: 0.008116\n",
            "iteration 7765 : loss : 0.026623, loss_ce: 0.012689\n",
            "iteration 7766 : loss : 0.026419, loss_ce: 0.008525\n",
            "iteration 7767 : loss : 0.023643, loss_ce: 0.010764\n",
            "iteration 7768 : loss : 0.026131, loss_ce: 0.009412\n",
            "iteration 7769 : loss : 0.028244, loss_ce: 0.007806\n",
            "iteration 7770 : loss : 0.023822, loss_ce: 0.010398\n",
            " 70%|██████████████████▏       | 105/150 [3:09:37<1:21:47, 109.05s/it]iteration 7771 : loss : 0.025397, loss_ce: 0.012676\n",
            "iteration 7772 : loss : 0.029098, loss_ce: 0.011990\n",
            "iteration 7773 : loss : 0.046919, loss_ce: 0.007758\n",
            "iteration 7774 : loss : 0.080820, loss_ce: 0.004530\n",
            "iteration 7775 : loss : 0.027526, loss_ce: 0.012595\n",
            "iteration 7776 : loss : 0.078654, loss_ce: 0.011094\n",
            "iteration 7777 : loss : 0.027990, loss_ce: 0.011791\n",
            "iteration 7778 : loss : 0.025098, loss_ce: 0.009495\n",
            "iteration 7779 : loss : 0.032821, loss_ce: 0.010607\n",
            "iteration 7780 : loss : 0.031574, loss_ce: 0.015314\n",
            "iteration 7781 : loss : 0.025100, loss_ce: 0.010751\n",
            "iteration 7782 : loss : 0.027918, loss_ce: 0.012103\n",
            "iteration 7783 : loss : 0.026049, loss_ce: 0.011457\n",
            "iteration 7784 : loss : 0.025093, loss_ce: 0.006889\n",
            "iteration 7785 : loss : 0.027753, loss_ce: 0.007209\n",
            "iteration 7786 : loss : 0.023575, loss_ce: 0.003720\n",
            "iteration 7787 : loss : 0.027383, loss_ce: 0.006401\n",
            "iteration 7788 : loss : 0.024677, loss_ce: 0.009356\n",
            "iteration 7789 : loss : 0.023798, loss_ce: 0.010133\n",
            "iteration 7790 : loss : 0.026839, loss_ce: 0.006136\n",
            "iteration 7791 : loss : 0.022738, loss_ce: 0.010639\n",
            "iteration 7792 : loss : 0.028658, loss_ce: 0.005170\n",
            "iteration 7793 : loss : 0.032115, loss_ce: 0.007387\n",
            "iteration 7794 : loss : 0.026333, loss_ce: 0.008064\n",
            "iteration 7795 : loss : 0.022218, loss_ce: 0.006725\n",
            "iteration 7796 : loss : 0.022536, loss_ce: 0.006109\n",
            "iteration 7797 : loss : 0.031597, loss_ce: 0.010111\n",
            "iteration 7798 : loss : 0.042894, loss_ce: 0.010994\n",
            "iteration 7799 : loss : 0.054008, loss_ce: 0.010870\n",
            "iteration 7800 : loss : 0.077148, loss_ce: 0.004223\n",
            "iteration 7801 : loss : 0.044400, loss_ce: 0.006088\n",
            "iteration 7802 : loss : 0.078593, loss_ce: 0.006462\n",
            "iteration 7803 : loss : 0.028118, loss_ce: 0.009117\n",
            "iteration 7804 : loss : 0.030875, loss_ce: 0.015657\n",
            "iteration 7805 : loss : 0.030222, loss_ce: 0.005688\n",
            "iteration 7806 : loss : 0.029270, loss_ce: 0.012272\n",
            "iteration 7807 : loss : 0.027742, loss_ce: 0.007146\n",
            "iteration 7808 : loss : 0.029762, loss_ce: 0.007480\n",
            "iteration 7809 : loss : 0.027790, loss_ce: 0.008045\n",
            "iteration 7810 : loss : 0.028953, loss_ce: 0.011910\n",
            "iteration 7811 : loss : 0.026354, loss_ce: 0.010590\n",
            "iteration 7812 : loss : 0.029208, loss_ce: 0.009811\n",
            "iteration 7813 : loss : 0.032896, loss_ce: 0.008154\n",
            "iteration 7814 : loss : 0.026245, loss_ce: 0.006400\n",
            "iteration 7815 : loss : 0.026865, loss_ce: 0.012466\n",
            "iteration 7816 : loss : 0.027239, loss_ce: 0.006565\n",
            "iteration 7817 : loss : 0.031417, loss_ce: 0.006226\n",
            "iteration 7818 : loss : 0.028714, loss_ce: 0.012596\n",
            "iteration 7819 : loss : 0.028987, loss_ce: 0.010586\n",
            "iteration 7820 : loss : 0.033988, loss_ce: 0.011242\n",
            "iteration 7821 : loss : 0.028156, loss_ce: 0.007443\n",
            "iteration 7822 : loss : 0.028817, loss_ce: 0.007687\n",
            "iteration 7823 : loss : 0.031527, loss_ce: 0.010827\n",
            "iteration 7824 : loss : 0.025285, loss_ce: 0.010944\n",
            "iteration 7825 : loss : 0.077944, loss_ce: 0.007683\n",
            "iteration 7826 : loss : 0.028527, loss_ce: 0.013934\n",
            "iteration 7827 : loss : 0.027286, loss_ce: 0.007768\n",
            "iteration 7828 : loss : 0.026867, loss_ce: 0.004571\n",
            "iteration 7829 : loss : 0.034636, loss_ce: 0.008550\n",
            "iteration 7830 : loss : 0.025866, loss_ce: 0.007625\n",
            "iteration 7831 : loss : 0.027304, loss_ce: 0.008304\n",
            "iteration 7832 : loss : 0.025822, loss_ce: 0.008154\n",
            "iteration 7833 : loss : 0.029624, loss_ce: 0.010363\n",
            "iteration 7834 : loss : 0.026101, loss_ce: 0.006624\n",
            "iteration 7835 : loss : 0.023874, loss_ce: 0.006386\n",
            "iteration 7836 : loss : 0.036532, loss_ce: 0.012899\n",
            "iteration 7837 : loss : 0.027113, loss_ce: 0.010047\n",
            "iteration 7838 : loss : 0.026410, loss_ce: 0.010127\n",
            "iteration 7839 : loss : 0.029357, loss_ce: 0.011118\n",
            "iteration 7840 : loss : 0.030095, loss_ce: 0.006279\n",
            "iteration 7841 : loss : 0.031230, loss_ce: 0.017244\n",
            "iteration 7842 : loss : 0.028648, loss_ce: 0.008969\n",
            "iteration 7843 : loss : 0.028655, loss_ce: 0.011814\n",
            "iteration 7844 : loss : 0.026361, loss_ce: 0.011321\n",
            " 71%|██████████████████▎       | 106/150 [3:11:25<1:19:44, 108.75s/it]iteration 7845 : loss : 0.025117, loss_ce: 0.007749\n",
            "iteration 7846 : loss : 0.025553, loss_ce: 0.007706\n",
            "iteration 7847 : loss : 0.028184, loss_ce: 0.010748\n",
            "iteration 7848 : loss : 0.030035, loss_ce: 0.011388\n",
            "iteration 7849 : loss : 0.030106, loss_ce: 0.013065\n",
            "iteration 7850 : loss : 0.025293, loss_ce: 0.008803\n",
            "iteration 7851 : loss : 0.031615, loss_ce: 0.009932\n",
            "iteration 7852 : loss : 0.030581, loss_ce: 0.010032\n",
            "iteration 7853 : loss : 0.022495, loss_ce: 0.007115\n",
            "iteration 7854 : loss : 0.033666, loss_ce: 0.011568\n",
            "iteration 7855 : loss : 0.028446, loss_ce: 0.012225\n",
            "iteration 7856 : loss : 0.027598, loss_ce: 0.011408\n",
            "iteration 7857 : loss : 0.023944, loss_ce: 0.007473\n",
            "iteration 7858 : loss : 0.026758, loss_ce: 0.008741\n",
            "iteration 7859 : loss : 0.031678, loss_ce: 0.008611\n",
            "iteration 7860 : loss : 0.027708, loss_ce: 0.007875\n",
            "iteration 7861 : loss : 0.027623, loss_ce: 0.010497\n",
            "iteration 7862 : loss : 0.026104, loss_ce: 0.009458\n",
            "iteration 7863 : loss : 0.022931, loss_ce: 0.007879\n",
            "iteration 7864 : loss : 0.024325, loss_ce: 0.011293\n",
            "iteration 7865 : loss : 0.031399, loss_ce: 0.009437\n",
            "iteration 7866 : loss : 0.023383, loss_ce: 0.005706\n",
            "iteration 7867 : loss : 0.024922, loss_ce: 0.006459\n",
            "iteration 7868 : loss : 0.024917, loss_ce: 0.009618\n",
            "iteration 7869 : loss : 0.023023, loss_ce: 0.008552\n",
            "iteration 7870 : loss : 0.020593, loss_ce: 0.007333\n",
            "iteration 7871 : loss : 0.078580, loss_ce: 0.007618\n",
            "iteration 7872 : loss : 0.032864, loss_ce: 0.009546\n",
            "iteration 7873 : loss : 0.024841, loss_ce: 0.007717\n",
            "iteration 7874 : loss : 0.024788, loss_ce: 0.007169\n",
            "iteration 7875 : loss : 0.125903, loss_ce: 0.004482\n",
            "iteration 7876 : loss : 0.028492, loss_ce: 0.011221\n",
            "iteration 7877 : loss : 0.030898, loss_ce: 0.008109\n",
            "iteration 7878 : loss : 0.074933, loss_ce: 0.003965\n",
            "iteration 7879 : loss : 0.033528, loss_ce: 0.005530\n",
            "iteration 7880 : loss : 0.024078, loss_ce: 0.007312\n",
            "iteration 7881 : loss : 0.024877, loss_ce: 0.007641\n",
            "iteration 7882 : loss : 0.024498, loss_ce: 0.010219\n",
            "iteration 7883 : loss : 0.030278, loss_ce: 0.010683\n",
            "iteration 7884 : loss : 0.026554, loss_ce: 0.010674\n",
            "iteration 7885 : loss : 0.028887, loss_ce: 0.009441\n",
            "iteration 7886 : loss : 0.027022, loss_ce: 0.009493\n",
            "iteration 7887 : loss : 0.023132, loss_ce: 0.008710\n",
            "iteration 7888 : loss : 0.031633, loss_ce: 0.012890\n",
            "iteration 7889 : loss : 0.026733, loss_ce: 0.009902\n",
            "iteration 7890 : loss : 0.029075, loss_ce: 0.012806\n",
            "iteration 7891 : loss : 0.024185, loss_ce: 0.008573\n",
            "iteration 7892 : loss : 0.074643, loss_ce: 0.006448\n",
            "iteration 7893 : loss : 0.028072, loss_ce: 0.007817\n",
            "iteration 7894 : loss : 0.025606, loss_ce: 0.009926\n",
            "iteration 7895 : loss : 0.029426, loss_ce: 0.013198\n",
            "iteration 7896 : loss : 0.028887, loss_ce: 0.011325\n",
            "iteration 7897 : loss : 0.074398, loss_ce: 0.007382\n",
            "iteration 7898 : loss : 0.026026, loss_ce: 0.012804\n",
            "iteration 7899 : loss : 0.032264, loss_ce: 0.008419\n",
            "iteration 7900 : loss : 0.026968, loss_ce: 0.011794\n",
            "iteration 7901 : loss : 0.030067, loss_ce: 0.009285\n",
            "iteration 7902 : loss : 0.024399, loss_ce: 0.005989\n",
            "iteration 7903 : loss : 0.027809, loss_ce: 0.009562\n",
            "iteration 7904 : loss : 0.065849, loss_ce: 0.005885\n",
            "iteration 7905 : loss : 0.023384, loss_ce: 0.009671\n",
            "iteration 7906 : loss : 0.030000, loss_ce: 0.006823\n",
            "iteration 7907 : loss : 0.031158, loss_ce: 0.011083\n",
            "iteration 7908 : loss : 0.040153, loss_ce: 0.009214\n",
            "iteration 7909 : loss : 0.028925, loss_ce: 0.008394\n",
            "iteration 7910 : loss : 0.028702, loss_ce: 0.007813\n",
            "iteration 7911 : loss : 0.028702, loss_ce: 0.010005\n",
            "iteration 7912 : loss : 0.036575, loss_ce: 0.011505\n",
            "iteration 7913 : loss : 0.030034, loss_ce: 0.012453\n",
            "iteration 7914 : loss : 0.022684, loss_ce: 0.007285\n",
            "iteration 7915 : loss : 0.024288, loss_ce: 0.009622\n",
            "iteration 7916 : loss : 0.028748, loss_ce: 0.009660\n",
            "iteration 7917 : loss : 0.026790, loss_ce: 0.010254\n",
            "iteration 7918 : loss : 0.078453, loss_ce: 0.004977\n",
            " 71%|██████████████████▌       | 107/150 [3:13:13<1:17:40, 108.39s/it]iteration 7919 : loss : 0.023655, loss_ce: 0.008376\n",
            "iteration 7920 : loss : 0.035692, loss_ce: 0.010568\n",
            "iteration 7921 : loss : 0.082100, loss_ce: 0.009538\n",
            "iteration 7922 : loss : 0.032254, loss_ce: 0.011433\n",
            "iteration 7923 : loss : 0.030834, loss_ce: 0.007172\n",
            "iteration 7924 : loss : 0.028028, loss_ce: 0.008233\n",
            "iteration 7925 : loss : 0.024799, loss_ce: 0.008528\n",
            "iteration 7926 : loss : 0.028659, loss_ce: 0.008183\n",
            "iteration 7927 : loss : 0.027300, loss_ce: 0.007927\n",
            "iteration 7928 : loss : 0.076082, loss_ce: 0.005865\n",
            "iteration 7929 : loss : 0.027266, loss_ce: 0.008702\n",
            "iteration 7930 : loss : 0.036278, loss_ce: 0.009343\n",
            "iteration 7931 : loss : 0.025902, loss_ce: 0.008931\n",
            "iteration 7932 : loss : 0.078514, loss_ce: 0.007644\n",
            "iteration 7933 : loss : 0.036182, loss_ce: 0.015645\n",
            "iteration 7934 : loss : 0.029681, loss_ce: 0.005005\n",
            "iteration 7935 : loss : 0.029504, loss_ce: 0.009063\n",
            "iteration 7936 : loss : 0.029862, loss_ce: 0.011619\n",
            "iteration 7937 : loss : 0.026822, loss_ce: 0.011584\n",
            "iteration 7938 : loss : 0.032770, loss_ce: 0.013640\n",
            "iteration 7939 : loss : 0.027132, loss_ce: 0.011226\n",
            "iteration 7940 : loss : 0.029908, loss_ce: 0.007107\n",
            "iteration 7941 : loss : 0.067499, loss_ce: 0.013562\n",
            "iteration 7942 : loss : 0.031947, loss_ce: 0.013008\n",
            "iteration 7943 : loss : 0.018945, loss_ce: 0.004861\n",
            "iteration 7944 : loss : 0.024627, loss_ce: 0.008564\n",
            "iteration 7945 : loss : 0.021464, loss_ce: 0.007569\n",
            "iteration 7946 : loss : 0.085241, loss_ce: 0.006027\n",
            "iteration 7947 : loss : 0.032562, loss_ce: 0.005899\n",
            "iteration 7948 : loss : 0.027925, loss_ce: 0.009453\n",
            "iteration 7949 : loss : 0.025817, loss_ce: 0.011207\n",
            "iteration 7950 : loss : 0.027844, loss_ce: 0.011812\n",
            "iteration 7951 : loss : 0.024971, loss_ce: 0.010237\n",
            "iteration 7952 : loss : 0.027452, loss_ce: 0.009241\n",
            "iteration 7953 : loss : 0.026185, loss_ce: 0.012052\n",
            "iteration 7954 : loss : 0.025464, loss_ce: 0.010503\n",
            "iteration 7955 : loss : 0.026630, loss_ce: 0.010487\n",
            "iteration 7956 : loss : 0.029253, loss_ce: 0.010374\n",
            "iteration 7957 : loss : 0.027342, loss_ce: 0.007910\n",
            "iteration 7958 : loss : 0.081635, loss_ce: 0.010109\n",
            "iteration 7959 : loss : 0.026789, loss_ce: 0.006718\n",
            "iteration 7960 : loss : 0.027919, loss_ce: 0.010005\n",
            "iteration 7961 : loss : 0.029225, loss_ce: 0.008678\n",
            "iteration 7962 : loss : 0.025502, loss_ce: 0.009781\n",
            "iteration 7963 : loss : 0.029942, loss_ce: 0.013116\n",
            "iteration 7964 : loss : 0.025762, loss_ce: 0.008856\n",
            "iteration 7965 : loss : 0.025156, loss_ce: 0.007499\n",
            "iteration 7966 : loss : 0.026657, loss_ce: 0.007225\n",
            "iteration 7967 : loss : 0.026651, loss_ce: 0.010295\n",
            "iteration 7968 : loss : 0.029138, loss_ce: 0.010113\n",
            "iteration 7969 : loss : 0.033154, loss_ce: 0.011128\n",
            "iteration 7970 : loss : 0.028483, loss_ce: 0.010261\n",
            "iteration 7971 : loss : 0.031908, loss_ce: 0.010121\n",
            "iteration 7972 : loss : 0.031535, loss_ce: 0.008055\n",
            "iteration 7973 : loss : 0.029507, loss_ce: 0.011040\n",
            "iteration 7974 : loss : 0.030450, loss_ce: 0.010339\n",
            "iteration 7975 : loss : 0.028391, loss_ce: 0.007204\n",
            "iteration 7976 : loss : 0.023860, loss_ce: 0.006038\n",
            "iteration 7977 : loss : 0.028332, loss_ce: 0.009835\n",
            "iteration 7978 : loss : 0.028695, loss_ce: 0.008909\n",
            "iteration 7979 : loss : 0.028525, loss_ce: 0.010524\n",
            "iteration 7980 : loss : 0.024347, loss_ce: 0.011075\n",
            "iteration 7981 : loss : 0.025725, loss_ce: 0.011446\n",
            "iteration 7982 : loss : 0.031263, loss_ce: 0.008962\n",
            "iteration 7983 : loss : 0.032559, loss_ce: 0.014180\n",
            "iteration 7984 : loss : 0.026119, loss_ce: 0.014200\n",
            "iteration 7985 : loss : 0.027854, loss_ce: 0.007005\n",
            "iteration 7986 : loss : 0.027398, loss_ce: 0.010740\n",
            "iteration 7987 : loss : 0.025106, loss_ce: 0.007052\n",
            "iteration 7988 : loss : 0.031626, loss_ce: 0.009350\n",
            "iteration 7989 : loss : 0.027324, loss_ce: 0.009496\n",
            "iteration 7990 : loss : 0.019551, loss_ce: 0.005822\n",
            "iteration 7991 : loss : 0.027102, loss_ce: 0.007822\n",
            "iteration 7992 : loss : 0.031811, loss_ce: 0.010486\n",
            " 72%|██████████████████▋       | 108/150 [3:15:02<1:16:02, 108.62s/it]iteration 7993 : loss : 0.022076, loss_ce: 0.007501\n",
            "iteration 7994 : loss : 0.026934, loss_ce: 0.010486\n",
            "iteration 7995 : loss : 0.030318, loss_ce: 0.011805\n",
            "iteration 7996 : loss : 0.033484, loss_ce: 0.005588\n",
            "iteration 7997 : loss : 0.031648, loss_ce: 0.011947\n",
            "iteration 7998 : loss : 0.026591, loss_ce: 0.008599\n",
            "iteration 7999 : loss : 0.023275, loss_ce: 0.005801\n",
            "iteration 8000 : loss : 0.020008, loss_ce: 0.005169\n",
            "iteration 8001 : loss : 0.032129, loss_ce: 0.009077\n",
            "iteration 8002 : loss : 0.027975, loss_ce: 0.011503\n",
            "iteration 8003 : loss : 0.027962, loss_ce: 0.008908\n",
            "iteration 8004 : loss : 0.078722, loss_ce: 0.010057\n",
            "iteration 8005 : loss : 0.023050, loss_ce: 0.008033\n",
            "iteration 8006 : loss : 0.032210, loss_ce: 0.011390\n",
            "iteration 8007 : loss : 0.030617, loss_ce: 0.010971\n",
            "iteration 8008 : loss : 0.026344, loss_ce: 0.007084\n",
            "iteration 8009 : loss : 0.023939, loss_ce: 0.009046\n",
            "iteration 8010 : loss : 0.026840, loss_ce: 0.005867\n",
            "iteration 8011 : loss : 0.039518, loss_ce: 0.008487\n",
            "iteration 8012 : loss : 0.027669, loss_ce: 0.008910\n",
            "iteration 8013 : loss : 0.033318, loss_ce: 0.010202\n",
            "iteration 8014 : loss : 0.032699, loss_ce: 0.010599\n",
            "iteration 8015 : loss : 0.031197, loss_ce: 0.006773\n",
            "iteration 8016 : loss : 0.034390, loss_ce: 0.007771\n",
            "iteration 8017 : loss : 0.030153, loss_ce: 0.008568\n",
            "iteration 8018 : loss : 0.029695, loss_ce: 0.005826\n",
            "iteration 8019 : loss : 0.073686, loss_ce: 0.007025\n",
            "iteration 8020 : loss : 0.029246, loss_ce: 0.005264\n",
            "iteration 8021 : loss : 0.026172, loss_ce: 0.009410\n",
            "iteration 8022 : loss : 0.029697, loss_ce: 0.011315\n",
            "iteration 8023 : loss : 0.025360, loss_ce: 0.008722\n",
            "iteration 8024 : loss : 0.023997, loss_ce: 0.006365\n",
            "iteration 8025 : loss : 0.026907, loss_ce: 0.010398\n",
            "iteration 8026 : loss : 0.025636, loss_ce: 0.006437\n",
            "iteration 8027 : loss : 0.026173, loss_ce: 0.008643\n",
            "iteration 8028 : loss : 0.029915, loss_ce: 0.009688\n",
            "iteration 8029 : loss : 0.025453, loss_ce: 0.006966\n",
            "iteration 8030 : loss : 0.027178, loss_ce: 0.008789\n",
            "iteration 8031 : loss : 0.031942, loss_ce: 0.012967\n",
            "iteration 8032 : loss : 0.026910, loss_ce: 0.011533\n",
            "iteration 8033 : loss : 0.028677, loss_ce: 0.009912\n",
            "iteration 8034 : loss : 0.023865, loss_ce: 0.007701\n",
            "iteration 8035 : loss : 0.026096, loss_ce: 0.013040\n",
            "iteration 8036 : loss : 0.026423, loss_ce: 0.008737\n",
            "iteration 8037 : loss : 0.027766, loss_ce: 0.006864\n",
            "iteration 8038 : loss : 0.033225, loss_ce: 0.009593\n",
            "iteration 8039 : loss : 0.026012, loss_ce: 0.012292\n",
            "iteration 8040 : loss : 0.038029, loss_ce: 0.008923\n",
            "iteration 8041 : loss : 0.026059, loss_ce: 0.009861\n",
            "iteration 8042 : loss : 0.027210, loss_ce: 0.011088\n",
            "iteration 8043 : loss : 0.023004, loss_ce: 0.006058\n",
            "iteration 8044 : loss : 0.026253, loss_ce: 0.008686\n",
            "iteration 8045 : loss : 0.027630, loss_ce: 0.009096\n",
            "iteration 8046 : loss : 0.024855, loss_ce: 0.010530\n",
            "iteration 8047 : loss : 0.025173, loss_ce: 0.006747\n",
            "iteration 8048 : loss : 0.023377, loss_ce: 0.011912\n",
            "iteration 8049 : loss : 0.029895, loss_ce: 0.013106\n",
            "iteration 8050 : loss : 0.027469, loss_ce: 0.008631\n",
            "iteration 8051 : loss : 0.025288, loss_ce: 0.006201\n",
            "iteration 8052 : loss : 0.024013, loss_ce: 0.010274\n",
            "iteration 8053 : loss : 0.025555, loss_ce: 0.008525\n",
            "iteration 8054 : loss : 0.028987, loss_ce: 0.012220\n",
            "iteration 8055 : loss : 0.030945, loss_ce: 0.007290\n",
            "iteration 8056 : loss : 0.028607, loss_ce: 0.015179\n",
            "iteration 8057 : loss : 0.028379, loss_ce: 0.006009\n",
            "iteration 8058 : loss : 0.030729, loss_ce: 0.010464\n",
            "iteration 8059 : loss : 0.023457, loss_ce: 0.009101\n",
            "iteration 8060 : loss : 0.029616, loss_ce: 0.007502\n",
            "iteration 8061 : loss : 0.028952, loss_ce: 0.007650\n",
            "iteration 8062 : loss : 0.024157, loss_ce: 0.010907\n",
            "iteration 8063 : loss : 0.022161, loss_ce: 0.005239\n",
            "iteration 8064 : loss : 0.025642, loss_ce: 0.008689\n",
            "iteration 8065 : loss : 0.024436, loss_ce: 0.009265\n",
            "iteration 8066 : loss : 0.027672, loss_ce: 0.008564\n",
            " 73%|██████████████████▉       | 109/150 [3:16:52<1:14:25, 108.91s/it]iteration 8067 : loss : 0.025880, loss_ce: 0.010717\n",
            "iteration 8068 : loss : 0.025095, loss_ce: 0.007261\n",
            "iteration 8069 : loss : 0.078935, loss_ce: 0.006722\n",
            "iteration 8070 : loss : 0.077842, loss_ce: 0.008026\n",
            "iteration 8071 : loss : 0.025568, loss_ce: 0.009365\n",
            "iteration 8072 : loss : 0.026212, loss_ce: 0.006276\n",
            "iteration 8073 : loss : 0.027279, loss_ce: 0.010491\n",
            "iteration 8074 : loss : 0.028174, loss_ce: 0.006343\n",
            "iteration 8075 : loss : 0.024479, loss_ce: 0.008789\n",
            "iteration 8076 : loss : 0.019769, loss_ce: 0.005784\n",
            "iteration 8077 : loss : 0.039881, loss_ce: 0.007914\n",
            "iteration 8078 : loss : 0.023129, loss_ce: 0.009181\n",
            "iteration 8079 : loss : 0.035385, loss_ce: 0.007451\n",
            "iteration 8080 : loss : 0.030564, loss_ce: 0.004458\n",
            "iteration 8081 : loss : 0.028401, loss_ce: 0.008478\n",
            "iteration 8082 : loss : 0.032821, loss_ce: 0.009809\n",
            "iteration 8083 : loss : 0.027123, loss_ce: 0.011866\n",
            "iteration 8084 : loss : 0.029343, loss_ce: 0.012853\n",
            "iteration 8085 : loss : 0.022307, loss_ce: 0.007148\n",
            "iteration 8086 : loss : 0.025066, loss_ce: 0.008518\n",
            "iteration 8087 : loss : 0.025038, loss_ce: 0.009811\n",
            "iteration 8088 : loss : 0.076848, loss_ce: 0.009730\n",
            "iteration 8089 : loss : 0.022995, loss_ce: 0.008336\n",
            "iteration 8090 : loss : 0.027514, loss_ce: 0.005711\n",
            "iteration 8091 : loss : 0.030176, loss_ce: 0.006017\n",
            "iteration 8092 : loss : 0.026362, loss_ce: 0.006750\n",
            "iteration 8093 : loss : 0.076911, loss_ce: 0.007691\n",
            "iteration 8094 : loss : 0.027692, loss_ce: 0.010250\n",
            "iteration 8095 : loss : 0.022966, loss_ce: 0.004907\n",
            "iteration 8096 : loss : 0.020950, loss_ce: 0.007288\n",
            "iteration 8097 : loss : 0.026198, loss_ce: 0.008758\n",
            "iteration 8098 : loss : 0.027612, loss_ce: 0.007662\n",
            "iteration 8099 : loss : 0.025160, loss_ce: 0.009434\n",
            "iteration 8100 : loss : 0.022141, loss_ce: 0.006432\n",
            "iteration 8101 : loss : 0.031585, loss_ce: 0.013209\n",
            "iteration 8102 : loss : 0.027307, loss_ce: 0.009286\n",
            "iteration 8103 : loss : 0.026338, loss_ce: 0.009892\n",
            "iteration 8104 : loss : 0.073756, loss_ce: 0.006246\n",
            "iteration 8105 : loss : 0.027163, loss_ce: 0.004624\n",
            "iteration 8106 : loss : 0.024059, loss_ce: 0.008076\n",
            "iteration 8107 : loss : 0.025386, loss_ce: 0.008657\n",
            "iteration 8108 : loss : 0.025607, loss_ce: 0.010130\n",
            "iteration 8109 : loss : 0.030475, loss_ce: 0.010338\n",
            "iteration 8110 : loss : 0.019656, loss_ce: 0.006356\n",
            "iteration 8111 : loss : 0.021000, loss_ce: 0.009036\n",
            "iteration 8112 : loss : 0.024718, loss_ce: 0.010173\n",
            "iteration 8113 : loss : 0.024505, loss_ce: 0.009617\n",
            "iteration 8114 : loss : 0.027976, loss_ce: 0.011166\n",
            "iteration 8115 : loss : 0.079288, loss_ce: 0.010491\n",
            "iteration 8116 : loss : 0.075387, loss_ce: 0.006407\n",
            "iteration 8117 : loss : 0.028941, loss_ce: 0.011440\n",
            "iteration 8118 : loss : 0.026205, loss_ce: 0.006238\n",
            "iteration 8119 : loss : 0.028279, loss_ce: 0.013122\n",
            "iteration 8120 : loss : 0.028951, loss_ce: 0.011715\n",
            "iteration 8121 : loss : 0.028791, loss_ce: 0.006374\n",
            "iteration 8122 : loss : 0.023811, loss_ce: 0.008992\n",
            "iteration 8123 : loss : 0.022320, loss_ce: 0.007837\n",
            "iteration 8124 : loss : 0.026796, loss_ce: 0.006302\n",
            "iteration 8125 : loss : 0.023388, loss_ce: 0.010514\n",
            "iteration 8126 : loss : 0.023842, loss_ce: 0.006530\n",
            "iteration 8127 : loss : 0.029295, loss_ce: 0.011340\n",
            "iteration 8128 : loss : 0.027360, loss_ce: 0.009107\n",
            "iteration 8129 : loss : 0.026606, loss_ce: 0.010540\n",
            "iteration 8130 : loss : 0.028898, loss_ce: 0.010991\n",
            "iteration 8131 : loss : 0.030964, loss_ce: 0.012146\n",
            "iteration 8132 : loss : 0.027912, loss_ce: 0.009915\n",
            "iteration 8133 : loss : 0.031232, loss_ce: 0.010077\n",
            "iteration 8134 : loss : 0.027734, loss_ce: 0.011551\n",
            "iteration 8135 : loss : 0.024848, loss_ce: 0.008733\n",
            "iteration 8136 : loss : 0.026395, loss_ce: 0.006165\n",
            "iteration 8137 : loss : 0.024647, loss_ce: 0.008165\n",
            "iteration 8138 : loss : 0.025720, loss_ce: 0.010959\n",
            "iteration 8139 : loss : 0.029401, loss_ce: 0.012584\n",
            "iteration 8140 : loss : 0.026338, loss_ce: 0.010288\n",
            " 73%|███████████████████       | 110/150 [3:18:39<1:12:22, 108.57s/it]iteration 8141 : loss : 0.024507, loss_ce: 0.007819\n",
            "iteration 8142 : loss : 0.021799, loss_ce: 0.008784\n",
            "iteration 8143 : loss : 0.126159, loss_ce: 0.006680\n",
            "iteration 8144 : loss : 0.025077, loss_ce: 0.009272\n",
            "iteration 8145 : loss : 0.022775, loss_ce: 0.006264\n",
            "iteration 8146 : loss : 0.026583, loss_ce: 0.009333\n",
            "iteration 8147 : loss : 0.025384, loss_ce: 0.005014\n",
            "iteration 8148 : loss : 0.028170, loss_ce: 0.010340\n",
            "iteration 8149 : loss : 0.024010, loss_ce: 0.009562\n",
            "iteration 8150 : loss : 0.025402, loss_ce: 0.009961\n",
            "iteration 8151 : loss : 0.029730, loss_ce: 0.011335\n",
            "iteration 8152 : loss : 0.024545, loss_ce: 0.007117\n",
            "iteration 8153 : loss : 0.027771, loss_ce: 0.008434\n",
            "iteration 8154 : loss : 0.024785, loss_ce: 0.007314\n",
            "iteration 8155 : loss : 0.027702, loss_ce: 0.007360\n",
            "iteration 8156 : loss : 0.025367, loss_ce: 0.009275\n",
            "iteration 8157 : loss : 0.024063, loss_ce: 0.007697\n",
            "iteration 8158 : loss : 0.026573, loss_ce: 0.009226\n",
            "iteration 8159 : loss : 0.027419, loss_ce: 0.009961\n",
            "iteration 8160 : loss : 0.023197, loss_ce: 0.009513\n",
            "iteration 8161 : loss : 0.021738, loss_ce: 0.007782\n",
            "iteration 8162 : loss : 0.027852, loss_ce: 0.011581\n",
            "iteration 8163 : loss : 0.073839, loss_ce: 0.006080\n",
            "iteration 8164 : loss : 0.025019, loss_ce: 0.008245\n",
            "iteration 8165 : loss : 0.024795, loss_ce: 0.010566\n",
            "iteration 8166 : loss : 0.024359, loss_ce: 0.008707\n",
            "iteration 8167 : loss : 0.033048, loss_ce: 0.008715\n",
            "iteration 8168 : loss : 0.024673, loss_ce: 0.007694\n",
            "iteration 8169 : loss : 0.032244, loss_ce: 0.011506\n",
            "iteration 8170 : loss : 0.025063, loss_ce: 0.010843\n",
            "iteration 8171 : loss : 0.032578, loss_ce: 0.011545\n",
            "iteration 8172 : loss : 0.023270, loss_ce: 0.006246\n",
            "iteration 8173 : loss : 0.023758, loss_ce: 0.010396\n",
            "iteration 8174 : loss : 0.077012, loss_ce: 0.005886\n",
            "iteration 8175 : loss : 0.031610, loss_ce: 0.008067\n",
            "iteration 8176 : loss : 0.023931, loss_ce: 0.004774\n",
            "iteration 8177 : loss : 0.025471, loss_ce: 0.008941\n",
            "iteration 8178 : loss : 0.074251, loss_ce: 0.005468\n",
            "iteration 8179 : loss : 0.028277, loss_ce: 0.012000\n",
            "iteration 8180 : loss : 0.024261, loss_ce: 0.008884\n",
            "iteration 8181 : loss : 0.025053, loss_ce: 0.007645\n",
            "iteration 8182 : loss : 0.025538, loss_ce: 0.012700\n",
            "iteration 8183 : loss : 0.028100, loss_ce: 0.010823\n",
            "iteration 8184 : loss : 0.022576, loss_ce: 0.006634\n",
            "iteration 8185 : loss : 0.029656, loss_ce: 0.012952\n",
            "iteration 8186 : loss : 0.076770, loss_ce: 0.009608\n",
            "iteration 8187 : loss : 0.025824, loss_ce: 0.008593\n",
            "iteration 8188 : loss : 0.027523, loss_ce: 0.010451\n",
            "iteration 8189 : loss : 0.030275, loss_ce: 0.012900\n",
            "iteration 8190 : loss : 0.029216, loss_ce: 0.013289\n",
            "iteration 8191 : loss : 0.071272, loss_ce: 0.006302\n",
            "iteration 8192 : loss : 0.025688, loss_ce: 0.007908\n",
            "iteration 8193 : loss : 0.030319, loss_ce: 0.014973\n",
            "iteration 8194 : loss : 0.022989, loss_ce: 0.006981\n",
            "iteration 8195 : loss : 0.028798, loss_ce: 0.009076\n",
            "iteration 8196 : loss : 0.025659, loss_ce: 0.007787\n",
            "iteration 8197 : loss : 0.025004, loss_ce: 0.010197\n",
            "iteration 8198 : loss : 0.026418, loss_ce: 0.006389\n",
            "iteration 8199 : loss : 0.035167, loss_ce: 0.008609\n",
            "iteration 8200 : loss : 0.023766, loss_ce: 0.009091\n",
            "iteration 8201 : loss : 0.028916, loss_ce: 0.006329\n",
            "iteration 8202 : loss : 0.024150, loss_ce: 0.008052\n",
            "iteration 8203 : loss : 0.024295, loss_ce: 0.007399\n",
            "iteration 8204 : loss : 0.027305, loss_ce: 0.007845\n",
            "iteration 8205 : loss : 0.022983, loss_ce: 0.008686\n",
            "iteration 8206 : loss : 0.029371, loss_ce: 0.004337\n",
            "iteration 8207 : loss : 0.028031, loss_ce: 0.008729\n",
            "iteration 8208 : loss : 0.027163, loss_ce: 0.008317\n",
            "iteration 8209 : loss : 0.026897, loss_ce: 0.014759\n",
            "iteration 8210 : loss : 0.026712, loss_ce: 0.009397\n",
            "iteration 8211 : loss : 0.025104, loss_ce: 0.011101\n",
            "iteration 8212 : loss : 0.077923, loss_ce: 0.004559\n",
            "iteration 8213 : loss : 0.026310, loss_ce: 0.008187\n",
            "iteration 8214 : loss : 0.044935, loss_ce: 0.006672\n",
            " 74%|███████████████████▏      | 111/150 [3:20:27<1:10:24, 108.33s/it]iteration 8215 : loss : 0.070983, loss_ce: 0.003416\n",
            "iteration 8216 : loss : 0.024802, loss_ce: 0.006103\n",
            "iteration 8217 : loss : 0.030831, loss_ce: 0.009365\n",
            "iteration 8218 : loss : 0.025776, loss_ce: 0.010968\n",
            "iteration 8219 : loss : 0.024559, loss_ce: 0.009167\n",
            "iteration 8220 : loss : 0.026327, loss_ce: 0.011299\n",
            "iteration 8221 : loss : 0.025439, loss_ce: 0.013742\n",
            "iteration 8222 : loss : 0.025180, loss_ce: 0.006736\n",
            "iteration 8223 : loss : 0.027889, loss_ce: 0.009010\n",
            "iteration 8224 : loss : 0.025582, loss_ce: 0.010054\n",
            "iteration 8225 : loss : 0.025327, loss_ce: 0.007650\n",
            "iteration 8226 : loss : 0.024284, loss_ce: 0.009913\n",
            "iteration 8227 : loss : 0.026918, loss_ce: 0.006019\n",
            "iteration 8228 : loss : 0.023401, loss_ce: 0.009311\n",
            "iteration 8229 : loss : 0.030752, loss_ce: 0.010749\n",
            "iteration 8230 : loss : 0.027625, loss_ce: 0.013051\n",
            "iteration 8231 : loss : 0.078055, loss_ce: 0.004835\n",
            "iteration 8232 : loss : 0.027664, loss_ce: 0.007389\n",
            "iteration 8233 : loss : 0.032686, loss_ce: 0.006104\n",
            "iteration 8234 : loss : 0.022849, loss_ce: 0.007048\n",
            "iteration 8235 : loss : 0.025800, loss_ce: 0.013711\n",
            "iteration 8236 : loss : 0.022828, loss_ce: 0.006866\n",
            "iteration 8237 : loss : 0.029859, loss_ce: 0.009084\n",
            "iteration 8238 : loss : 0.027036, loss_ce: 0.010656\n",
            "iteration 8239 : loss : 0.027898, loss_ce: 0.007968\n",
            "iteration 8240 : loss : 0.028757, loss_ce: 0.012617\n",
            "iteration 8241 : loss : 0.028923, loss_ce: 0.008289\n",
            "iteration 8242 : loss : 0.030424, loss_ce: 0.011710\n",
            "iteration 8243 : loss : 0.022764, loss_ce: 0.009068\n",
            "iteration 8244 : loss : 0.024783, loss_ce: 0.008911\n",
            "iteration 8245 : loss : 0.028884, loss_ce: 0.008346\n",
            "iteration 8246 : loss : 0.021719, loss_ce: 0.006937\n",
            "iteration 8247 : loss : 0.029586, loss_ce: 0.007187\n",
            "iteration 8248 : loss : 0.023345, loss_ce: 0.008528\n",
            "iteration 8249 : loss : 0.026148, loss_ce: 0.007439\n",
            "iteration 8250 : loss : 0.027488, loss_ce: 0.010922\n",
            "iteration 8251 : loss : 0.025171, loss_ce: 0.010767\n",
            "iteration 8252 : loss : 0.025576, loss_ce: 0.005104\n",
            "iteration 8253 : loss : 0.028215, loss_ce: 0.009322\n",
            "iteration 8254 : loss : 0.076665, loss_ce: 0.007442\n",
            "iteration 8255 : loss : 0.027673, loss_ce: 0.007678\n",
            "iteration 8256 : loss : 0.023816, loss_ce: 0.007009\n",
            "iteration 8257 : loss : 0.024848, loss_ce: 0.006003\n",
            "iteration 8258 : loss : 0.028247, loss_ce: 0.013233\n",
            "iteration 8259 : loss : 0.027112, loss_ce: 0.013658\n",
            "iteration 8260 : loss : 0.027700, loss_ce: 0.010044\n",
            "iteration 8261 : loss : 0.028574, loss_ce: 0.008684\n",
            "iteration 8262 : loss : 0.021771, loss_ce: 0.007965\n",
            "iteration 8263 : loss : 0.075192, loss_ce: 0.005623\n",
            "iteration 8264 : loss : 0.030905, loss_ce: 0.012195\n",
            "iteration 8265 : loss : 0.047923, loss_ce: 0.005689\n",
            "iteration 8266 : loss : 0.026923, loss_ce: 0.008554\n",
            "iteration 8267 : loss : 0.087382, loss_ce: 0.006634\n",
            "iteration 8268 : loss : 0.024398, loss_ce: 0.009081\n",
            "iteration 8269 : loss : 0.030621, loss_ce: 0.011110\n",
            "iteration 8270 : loss : 0.029314, loss_ce: 0.011221\n",
            "iteration 8271 : loss : 0.125185, loss_ce: 0.005171\n",
            "iteration 8272 : loss : 0.030270, loss_ce: 0.010009\n",
            "iteration 8273 : loss : 0.028700, loss_ce: 0.012412\n",
            "iteration 8274 : loss : 0.026405, loss_ce: 0.010113\n",
            "iteration 8275 : loss : 0.029372, loss_ce: 0.009862\n",
            "iteration 8276 : loss : 0.024333, loss_ce: 0.004494\n",
            "iteration 8277 : loss : 0.024533, loss_ce: 0.012354\n",
            "iteration 8278 : loss : 0.030349, loss_ce: 0.009561\n",
            "iteration 8279 : loss : 0.027404, loss_ce: 0.013053\n",
            "iteration 8280 : loss : 0.031124, loss_ce: 0.008814\n",
            "iteration 8281 : loss : 0.026688, loss_ce: 0.006913\n",
            "iteration 8282 : loss : 0.028361, loss_ce: 0.012849\n",
            "iteration 8283 : loss : 0.027413, loss_ce: 0.007493\n",
            "iteration 8284 : loss : 0.023025, loss_ce: 0.006846\n",
            "iteration 8285 : loss : 0.030961, loss_ce: 0.013503\n",
            "iteration 8286 : loss : 0.026039, loss_ce: 0.009501\n",
            "iteration 8287 : loss : 0.028512, loss_ce: 0.006885\n",
            "iteration 8288 : loss : 0.026691, loss_ce: 0.007420\n",
            " 75%|███████████████████▍      | 112/150 [3:22:15<1:08:33, 108.25s/it]iteration 8289 : loss : 0.030049, loss_ce: 0.009608\n",
            "iteration 8290 : loss : 0.023437, loss_ce: 0.008526\n",
            "iteration 8291 : loss : 0.080211, loss_ce: 0.007357\n",
            "iteration 8292 : loss : 0.025664, loss_ce: 0.005638\n",
            "iteration 8293 : loss : 0.027718, loss_ce: 0.010454\n",
            "iteration 8294 : loss : 0.023897, loss_ce: 0.008352\n",
            "iteration 8295 : loss : 0.027265, loss_ce: 0.009907\n",
            "iteration 8296 : loss : 0.030322, loss_ce: 0.003733\n",
            "iteration 8297 : loss : 0.024751, loss_ce: 0.011880\n",
            "iteration 8298 : loss : 0.027719, loss_ce: 0.006757\n",
            "iteration 8299 : loss : 0.029638, loss_ce: 0.006543\n",
            "iteration 8300 : loss : 0.028859, loss_ce: 0.011514\n",
            "iteration 8301 : loss : 0.027191, loss_ce: 0.008230\n",
            "iteration 8302 : loss : 0.023712, loss_ce: 0.009154\n",
            "iteration 8303 : loss : 0.027390, loss_ce: 0.009986\n",
            "iteration 8304 : loss : 0.028555, loss_ce: 0.012654\n",
            "iteration 8305 : loss : 0.030650, loss_ce: 0.007676\n",
            "iteration 8306 : loss : 0.028255, loss_ce: 0.007362\n",
            "iteration 8307 : loss : 0.026573, loss_ce: 0.009148\n",
            "iteration 8308 : loss : 0.026681, loss_ce: 0.009461\n",
            "iteration 8309 : loss : 0.026081, loss_ce: 0.009212\n",
            "iteration 8310 : loss : 0.024761, loss_ce: 0.011092\n",
            "iteration 8311 : loss : 0.026052, loss_ce: 0.009339\n",
            "iteration 8312 : loss : 0.026393, loss_ce: 0.009274\n",
            "iteration 8313 : loss : 0.030562, loss_ce: 0.011480\n",
            "iteration 8314 : loss : 0.025208, loss_ce: 0.009475\n",
            "iteration 8315 : loss : 0.025967, loss_ce: 0.006599\n",
            "iteration 8316 : loss : 0.029778, loss_ce: 0.010884\n",
            "iteration 8317 : loss : 0.022726, loss_ce: 0.008002\n",
            "iteration 8318 : loss : 0.026077, loss_ce: 0.008345\n",
            "iteration 8319 : loss : 0.072664, loss_ce: 0.005261\n",
            "iteration 8320 : loss : 0.044958, loss_ce: 0.008655\n",
            "iteration 8321 : loss : 0.028030, loss_ce: 0.010643\n",
            "iteration 8322 : loss : 0.030907, loss_ce: 0.007304\n",
            "iteration 8323 : loss : 0.034134, loss_ce: 0.010710\n",
            "iteration 8324 : loss : 0.028356, loss_ce: 0.009431\n",
            "iteration 8325 : loss : 0.076805, loss_ce: 0.006467\n",
            "iteration 8326 : loss : 0.030045, loss_ce: 0.010910\n",
            "iteration 8327 : loss : 0.027468, loss_ce: 0.012009\n",
            "iteration 8328 : loss : 0.030302, loss_ce: 0.012127\n",
            "iteration 8329 : loss : 0.027731, loss_ce: 0.010991\n",
            "iteration 8330 : loss : 0.029508, loss_ce: 0.007010\n",
            "iteration 8331 : loss : 0.032686, loss_ce: 0.007347\n",
            "iteration 8332 : loss : 0.022955, loss_ce: 0.009953\n",
            "iteration 8333 : loss : 0.072112, loss_ce: 0.005008\n",
            "iteration 8334 : loss : 0.024934, loss_ce: 0.009339\n",
            "iteration 8335 : loss : 0.024951, loss_ce: 0.007858\n",
            "iteration 8336 : loss : 0.023297, loss_ce: 0.006860\n",
            "iteration 8337 : loss : 0.041846, loss_ce: 0.008785\n",
            "iteration 8338 : loss : 0.027652, loss_ce: 0.014594\n",
            "iteration 8339 : loss : 0.033456, loss_ce: 0.008194\n",
            "iteration 8340 : loss : 0.025337, loss_ce: 0.007829\n",
            "iteration 8341 : loss : 0.025315, loss_ce: 0.006845\n",
            "iteration 8342 : loss : 0.021509, loss_ce: 0.008247\n",
            "iteration 8343 : loss : 0.025880, loss_ce: 0.012642\n",
            "iteration 8344 : loss : 0.028900, loss_ce: 0.010012\n",
            "iteration 8345 : loss : 0.024385, loss_ce: 0.007532\n",
            "iteration 8346 : loss : 0.028391, loss_ce: 0.005423\n",
            "iteration 8347 : loss : 0.024769, loss_ce: 0.008226\n",
            "iteration 8348 : loss : 0.029366, loss_ce: 0.010555\n",
            "iteration 8349 : loss : 0.025926, loss_ce: 0.011364\n",
            "iteration 8350 : loss : 0.034332, loss_ce: 0.008775\n",
            "iteration 8351 : loss : 0.032009, loss_ce: 0.018055\n",
            "iteration 8352 : loss : 0.024503, loss_ce: 0.007551\n",
            "iteration 8353 : loss : 0.025028, loss_ce: 0.009435\n",
            "iteration 8354 : loss : 0.024512, loss_ce: 0.006392\n",
            "iteration 8355 : loss : 0.038148, loss_ce: 0.010737\n",
            "iteration 8356 : loss : 0.022484, loss_ce: 0.008286\n",
            "iteration 8357 : loss : 0.028291, loss_ce: 0.010775\n",
            "iteration 8358 : loss : 0.032150, loss_ce: 0.008971\n",
            "iteration 8359 : loss : 0.020561, loss_ce: 0.006687\n",
            "iteration 8360 : loss : 0.024764, loss_ce: 0.004195\n",
            "iteration 8361 : loss : 0.026337, loss_ce: 0.010477\n",
            "iteration 8362 : loss : 0.024401, loss_ce: 0.007789\n",
            " 75%|███████████████████▌      | 113/150 [3:24:05<1:06:57, 108.58s/it]iteration 8363 : loss : 0.178873, loss_ce: 0.005841\n",
            "iteration 8364 : loss : 0.028764, loss_ce: 0.008144\n",
            "iteration 8365 : loss : 0.031967, loss_ce: 0.015894\n",
            "iteration 8366 : loss : 0.026232, loss_ce: 0.009808\n",
            "iteration 8367 : loss : 0.032206, loss_ce: 0.010957\n",
            "iteration 8368 : loss : 0.025413, loss_ce: 0.008288\n",
            "iteration 8369 : loss : 0.077184, loss_ce: 0.007874\n",
            "iteration 8370 : loss : 0.033195, loss_ce: 0.006128\n",
            "iteration 8371 : loss : 0.027037, loss_ce: 0.011264\n",
            "iteration 8372 : loss : 0.025304, loss_ce: 0.011100\n",
            "iteration 8373 : loss : 0.025829, loss_ce: 0.004351\n",
            "iteration 8374 : loss : 0.023752, loss_ce: 0.007474\n",
            "iteration 8375 : loss : 0.026386, loss_ce: 0.010320\n",
            "iteration 8376 : loss : 0.023822, loss_ce: 0.007971\n",
            "iteration 8377 : loss : 0.026598, loss_ce: 0.008189\n",
            "iteration 8378 : loss : 0.026001, loss_ce: 0.009367\n",
            "iteration 8379 : loss : 0.027750, loss_ce: 0.005943\n",
            "iteration 8380 : loss : 0.025612, loss_ce: 0.007924\n",
            "iteration 8381 : loss : 0.023356, loss_ce: 0.009116\n",
            "iteration 8382 : loss : 0.026411, loss_ce: 0.005995\n",
            "iteration 8383 : loss : 0.095328, loss_ce: 0.005815\n",
            "iteration 8384 : loss : 0.020247, loss_ce: 0.005516\n",
            "iteration 8385 : loss : 0.026881, loss_ce: 0.011617\n",
            "iteration 8386 : loss : 0.071922, loss_ce: 0.005157\n",
            "iteration 8387 : loss : 0.076974, loss_ce: 0.008220\n",
            "iteration 8388 : loss : 0.024309, loss_ce: 0.009962\n",
            "iteration 8389 : loss : 0.023063, loss_ce: 0.009640\n",
            "iteration 8390 : loss : 0.030135, loss_ce: 0.007852\n",
            "iteration 8391 : loss : 0.034014, loss_ce: 0.007540\n",
            "iteration 8392 : loss : 0.021289, loss_ce: 0.005167\n",
            "iteration 8393 : loss : 0.022817, loss_ce: 0.007361\n",
            "iteration 8394 : loss : 0.024203, loss_ce: 0.009154\n",
            "iteration 8395 : loss : 0.022666, loss_ce: 0.008611\n",
            "iteration 8396 : loss : 0.022650, loss_ce: 0.008179\n",
            "iteration 8397 : loss : 0.026613, loss_ce: 0.009295\n",
            "iteration 8398 : loss : 0.023090, loss_ce: 0.008903\n",
            "iteration 8399 : loss : 0.036946, loss_ce: 0.007420\n",
            "iteration 8400 : loss : 0.025179, loss_ce: 0.010407\n",
            "iteration 8401 : loss : 0.033480, loss_ce: 0.007786\n",
            "iteration 8402 : loss : 0.030541, loss_ce: 0.008620\n",
            "iteration 8403 : loss : 0.022636, loss_ce: 0.006101\n",
            "iteration 8404 : loss : 0.027446, loss_ce: 0.009505\n",
            "iteration 8405 : loss : 0.025677, loss_ce: 0.008306\n",
            "iteration 8406 : loss : 0.030972, loss_ce: 0.006840\n",
            "iteration 8407 : loss : 0.028458, loss_ce: 0.011873\n",
            "iteration 8408 : loss : 0.075561, loss_ce: 0.006484\n",
            "iteration 8409 : loss : 0.029838, loss_ce: 0.012640\n",
            "iteration 8410 : loss : 0.026002, loss_ce: 0.007699\n",
            "iteration 8411 : loss : 0.026898, loss_ce: 0.005166\n",
            "iteration 8412 : loss : 0.024996, loss_ce: 0.008475\n",
            "iteration 8413 : loss : 0.023670, loss_ce: 0.011615\n",
            "iteration 8414 : loss : 0.032061, loss_ce: 0.008754\n",
            "iteration 8415 : loss : 0.025602, loss_ce: 0.007708\n",
            "iteration 8416 : loss : 0.023108, loss_ce: 0.008444\n",
            "iteration 8417 : loss : 0.032897, loss_ce: 0.007862\n",
            "iteration 8418 : loss : 0.027812, loss_ce: 0.011161\n",
            "iteration 8419 : loss : 0.037350, loss_ce: 0.011636\n",
            "iteration 8420 : loss : 0.026343, loss_ce: 0.012664\n",
            "iteration 8421 : loss : 0.027706, loss_ce: 0.008287\n",
            "iteration 8422 : loss : 0.066858, loss_ce: 0.010560\n",
            "iteration 8423 : loss : 0.026458, loss_ce: 0.010334\n",
            "iteration 8424 : loss : 0.026856, loss_ce: 0.012055\n",
            "iteration 8425 : loss : 0.026301, loss_ce: 0.007214\n",
            "iteration 8426 : loss : 0.026478, loss_ce: 0.010974\n",
            "iteration 8427 : loss : 0.098336, loss_ce: 0.002775\n",
            "iteration 8428 : loss : 0.024396, loss_ce: 0.009981\n",
            "iteration 8429 : loss : 0.030360, loss_ce: 0.010768\n",
            "iteration 8430 : loss : 0.027022, loss_ce: 0.012625\n",
            "iteration 8431 : loss : 0.023076, loss_ce: 0.009813\n",
            "iteration 8432 : loss : 0.029774, loss_ce: 0.012040\n",
            "iteration 8433 : loss : 0.028488, loss_ce: 0.011520\n",
            "iteration 8434 : loss : 0.026103, loss_ce: 0.014695\n",
            "iteration 8435 : loss : 0.029151, loss_ce: 0.007249\n",
            "iteration 8436 : loss : 0.025087, loss_ce: 0.012349\n",
            " 76%|███████████████████▊      | 114/150 [3:25:53<1:05:10, 108.62s/it]iteration 8437 : loss : 0.025593, loss_ce: 0.008723\n",
            "iteration 8438 : loss : 0.025279, loss_ce: 0.006063\n",
            "iteration 8439 : loss : 0.027726, loss_ce: 0.010871\n",
            "iteration 8440 : loss : 0.076721, loss_ce: 0.006934\n",
            "iteration 8441 : loss : 0.077380, loss_ce: 0.005709\n",
            "iteration 8442 : loss : 0.029171, loss_ce: 0.008560\n",
            "iteration 8443 : loss : 0.024916, loss_ce: 0.007035\n",
            "iteration 8444 : loss : 0.023870, loss_ce: 0.009727\n",
            "iteration 8445 : loss : 0.027119, loss_ce: 0.012933\n",
            "iteration 8446 : loss : 0.027017, loss_ce: 0.013844\n",
            "iteration 8447 : loss : 0.027003, loss_ce: 0.009269\n",
            "iteration 8448 : loss : 0.035897, loss_ce: 0.006644\n",
            "iteration 8449 : loss : 0.026323, loss_ce: 0.010526\n",
            "iteration 8450 : loss : 0.026902, loss_ce: 0.007290\n",
            "iteration 8451 : loss : 0.027988, loss_ce: 0.007524\n",
            "iteration 8452 : loss : 0.041788, loss_ce: 0.009999\n",
            "iteration 8453 : loss : 0.027386, loss_ce: 0.010443\n",
            "iteration 8454 : loss : 0.079119, loss_ce: 0.008133\n",
            "iteration 8455 : loss : 0.024335, loss_ce: 0.009358\n",
            "iteration 8456 : loss : 0.026850, loss_ce: 0.008370\n",
            "iteration 8457 : loss : 0.026892, loss_ce: 0.010653\n",
            "iteration 8458 : loss : 0.024095, loss_ce: 0.010524\n",
            "iteration 8459 : loss : 0.025872, loss_ce: 0.011830\n",
            "iteration 8460 : loss : 0.028047, loss_ce: 0.009449\n",
            "iteration 8461 : loss : 0.076779, loss_ce: 0.007262\n",
            "iteration 8462 : loss : 0.027853, loss_ce: 0.007627\n",
            "iteration 8463 : loss : 0.023219, loss_ce: 0.009348\n",
            "iteration 8464 : loss : 0.023130, loss_ce: 0.007684\n",
            "iteration 8465 : loss : 0.026713, loss_ce: 0.010308\n",
            "iteration 8466 : loss : 0.020913, loss_ce: 0.006391\n",
            "iteration 8467 : loss : 0.023149, loss_ce: 0.007778\n",
            "iteration 8468 : loss : 0.030125, loss_ce: 0.005802\n",
            "iteration 8469 : loss : 0.028814, loss_ce: 0.012074\n",
            "iteration 8470 : loss : 0.027996, loss_ce: 0.008041\n",
            "iteration 8471 : loss : 0.024184, loss_ce: 0.008868\n",
            "iteration 8472 : loss : 0.081009, loss_ce: 0.006309\n",
            "iteration 8473 : loss : 0.023291, loss_ce: 0.007488\n",
            "iteration 8474 : loss : 0.026022, loss_ce: 0.009565\n",
            "iteration 8475 : loss : 0.025318, loss_ce: 0.007989\n",
            "iteration 8476 : loss : 0.026724, loss_ce: 0.010090\n",
            "iteration 8477 : loss : 0.022168, loss_ce: 0.005410\n",
            "iteration 8478 : loss : 0.026200, loss_ce: 0.007766\n",
            "iteration 8479 : loss : 0.036670, loss_ce: 0.012629\n",
            "iteration 8480 : loss : 0.023393, loss_ce: 0.008982\n",
            "iteration 8481 : loss : 0.025495, loss_ce: 0.011179\n",
            "iteration 8482 : loss : 0.027320, loss_ce: 0.005214\n",
            "iteration 8483 : loss : 0.022696, loss_ce: 0.008905\n",
            "iteration 8484 : loss : 0.031587, loss_ce: 0.007169\n",
            "iteration 8485 : loss : 0.024109, loss_ce: 0.006219\n",
            "iteration 8486 : loss : 0.025306, loss_ce: 0.010914\n",
            "iteration 8487 : loss : 0.030291, loss_ce: 0.008388\n",
            "iteration 8488 : loss : 0.024956, loss_ce: 0.007967\n",
            "iteration 8489 : loss : 0.027295, loss_ce: 0.011882\n",
            "iteration 8490 : loss : 0.033093, loss_ce: 0.005602\n",
            "iteration 8491 : loss : 0.025476, loss_ce: 0.011381\n",
            "iteration 8492 : loss : 0.072791, loss_ce: 0.002394\n",
            "iteration 8493 : loss : 0.030211, loss_ce: 0.012474\n",
            "iteration 8494 : loss : 0.027412, loss_ce: 0.007757\n",
            "iteration 8495 : loss : 0.030544, loss_ce: 0.009635\n",
            "iteration 8496 : loss : 0.020922, loss_ce: 0.006494\n",
            "iteration 8497 : loss : 0.029060, loss_ce: 0.012530\n",
            "iteration 8498 : loss : 0.030240, loss_ce: 0.010316\n",
            "iteration 8499 : loss : 0.026878, loss_ce: 0.010609\n",
            "iteration 8500 : loss : 0.021554, loss_ce: 0.007495\n",
            "iteration 8501 : loss : 0.025143, loss_ce: 0.008121\n",
            "iteration 8502 : loss : 0.029615, loss_ce: 0.013562\n",
            "iteration 8503 : loss : 0.023026, loss_ce: 0.006403\n",
            "iteration 8504 : loss : 0.028124, loss_ce: 0.006904\n",
            "iteration 8505 : loss : 0.028266, loss_ce: 0.012796\n",
            "iteration 8506 : loss : 0.038160, loss_ce: 0.008837\n",
            "iteration 8507 : loss : 0.025819, loss_ce: 0.008894\n",
            "iteration 8508 : loss : 0.023741, loss_ce: 0.012092\n",
            "iteration 8509 : loss : 0.027232, loss_ce: 0.010700\n",
            "iteration 8510 : loss : 0.025721, loss_ce: 0.009003\n",
            " 77%|███████████████████▉      | 115/150 [3:27:42<1:03:18, 108.52s/it]iteration 8511 : loss : 0.025634, loss_ce: 0.009984\n",
            "iteration 8512 : loss : 0.021128, loss_ce: 0.004633\n",
            "iteration 8513 : loss : 0.027119, loss_ce: 0.010544\n",
            "iteration 8514 : loss : 0.024674, loss_ce: 0.007125\n",
            "iteration 8515 : loss : 0.024620, loss_ce: 0.010608\n",
            "iteration 8516 : loss : 0.026905, loss_ce: 0.007011\n",
            "iteration 8517 : loss : 0.026347, loss_ce: 0.012416\n",
            "iteration 8518 : loss : 0.034908, loss_ce: 0.007178\n",
            "iteration 8519 : loss : 0.031510, loss_ce: 0.007872\n",
            "iteration 8520 : loss : 0.059524, loss_ce: 0.006891\n",
            "iteration 8521 : loss : 0.026100, loss_ce: 0.005922\n",
            "iteration 8522 : loss : 0.027118, loss_ce: 0.007311\n",
            "iteration 8523 : loss : 0.026831, loss_ce: 0.012445\n",
            "iteration 8524 : loss : 0.027571, loss_ce: 0.011408\n",
            "iteration 8525 : loss : 0.024889, loss_ce: 0.009137\n",
            "iteration 8526 : loss : 0.026425, loss_ce: 0.010587\n",
            "iteration 8527 : loss : 0.025805, loss_ce: 0.007333\n",
            "iteration 8528 : loss : 0.029493, loss_ce: 0.007801\n",
            "iteration 8529 : loss : 0.025736, loss_ce: 0.008335\n",
            "iteration 8530 : loss : 0.022008, loss_ce: 0.008807\n",
            "iteration 8531 : loss : 0.026230, loss_ce: 0.006970\n",
            "iteration 8532 : loss : 0.024330, loss_ce: 0.010983\n",
            "iteration 8533 : loss : 0.029357, loss_ce: 0.007925\n",
            "iteration 8534 : loss : 0.036579, loss_ce: 0.008965\n",
            "iteration 8535 : loss : 0.041980, loss_ce: 0.008661\n",
            "iteration 8536 : loss : 0.025957, loss_ce: 0.008132\n",
            "iteration 8537 : loss : 0.027021, loss_ce: 0.008609\n",
            "iteration 8538 : loss : 0.030349, loss_ce: 0.010039\n",
            "iteration 8539 : loss : 0.022494, loss_ce: 0.007732\n",
            "iteration 8540 : loss : 0.078717, loss_ce: 0.004268\n",
            "iteration 8541 : loss : 0.023195, loss_ce: 0.007108\n",
            "iteration 8542 : loss : 0.027187, loss_ce: 0.010041\n",
            "iteration 8543 : loss : 0.078502, loss_ce: 0.012325\n",
            "iteration 8544 : loss : 0.022739, loss_ce: 0.006901\n",
            "iteration 8545 : loss : 0.027230, loss_ce: 0.010611\n",
            "iteration 8546 : loss : 0.024525, loss_ce: 0.005287\n",
            "iteration 8547 : loss : 0.027073, loss_ce: 0.012265\n",
            "iteration 8548 : loss : 0.030823, loss_ce: 0.009103\n",
            "iteration 8549 : loss : 0.022500, loss_ce: 0.007431\n",
            "iteration 8550 : loss : 0.028231, loss_ce: 0.011511\n",
            "iteration 8551 : loss : 0.025839, loss_ce: 0.007621\n",
            "iteration 8552 : loss : 0.025554, loss_ce: 0.008918\n",
            "iteration 8553 : loss : 0.032253, loss_ce: 0.011022\n",
            "iteration 8554 : loss : 0.027986, loss_ce: 0.011643\n",
            "iteration 8555 : loss : 0.024225, loss_ce: 0.006491\n",
            "iteration 8556 : loss : 0.024090, loss_ce: 0.008893\n",
            "iteration 8557 : loss : 0.026808, loss_ce: 0.008544\n",
            "iteration 8558 : loss : 0.029442, loss_ce: 0.008444\n",
            "iteration 8559 : loss : 0.031825, loss_ce: 0.007271\n",
            "iteration 8560 : loss : 0.027151, loss_ce: 0.009703\n",
            "iteration 8561 : loss : 0.026943, loss_ce: 0.011453\n",
            "iteration 8562 : loss : 0.025452, loss_ce: 0.009369\n",
            "iteration 8563 : loss : 0.021384, loss_ce: 0.008990\n",
            "iteration 8564 : loss : 0.024509, loss_ce: 0.008732\n",
            "iteration 8565 : loss : 0.023963, loss_ce: 0.009682\n",
            "iteration 8566 : loss : 0.027007, loss_ce: 0.009181\n",
            "iteration 8567 : loss : 0.026825, loss_ce: 0.013120\n",
            "iteration 8568 : loss : 0.023603, loss_ce: 0.010854\n",
            "iteration 8569 : loss : 0.028158, loss_ce: 0.006870\n",
            "iteration 8570 : loss : 0.026498, loss_ce: 0.008147\n",
            "iteration 8571 : loss : 0.027473, loss_ce: 0.010140\n",
            "iteration 8572 : loss : 0.025495, loss_ce: 0.005768\n",
            "iteration 8573 : loss : 0.026935, loss_ce: 0.008582\n",
            "iteration 8574 : loss : 0.031301, loss_ce: 0.008768\n",
            "iteration 8575 : loss : 0.076983, loss_ce: 0.004586\n",
            "iteration 8576 : loss : 0.031558, loss_ce: 0.009000\n",
            "iteration 8577 : loss : 0.028170, loss_ce: 0.009796\n",
            "iteration 8578 : loss : 0.044890, loss_ce: 0.006239\n",
            "iteration 8579 : loss : 0.025417, loss_ce: 0.007614\n",
            "iteration 8580 : loss : 0.030035, loss_ce: 0.008886\n",
            "iteration 8581 : loss : 0.022877, loss_ce: 0.005510\n",
            "iteration 8582 : loss : 0.022569, loss_ce: 0.007367\n",
            "iteration 8583 : loss : 0.032662, loss_ce: 0.010761\n",
            "iteration 8584 : loss : 0.025425, loss_ce: 0.008766\n",
            " 77%|████████████████████      | 116/150 [3:29:29<1:01:21, 108.27s/it]iteration 8585 : loss : 0.022883, loss_ce: 0.006137\n",
            "iteration 8586 : loss : 0.025828, loss_ce: 0.007121\n",
            "iteration 8587 : loss : 0.028063, loss_ce: 0.011592\n",
            "iteration 8588 : loss : 0.026692, loss_ce: 0.009432\n",
            "iteration 8589 : loss : 0.027099, loss_ce: 0.010673\n",
            "iteration 8590 : loss : 0.028714, loss_ce: 0.009246\n",
            "iteration 8591 : loss : 0.024116, loss_ce: 0.010305\n",
            "iteration 8592 : loss : 0.025621, loss_ce: 0.008555\n",
            "iteration 8593 : loss : 0.125794, loss_ce: 0.005980\n",
            "iteration 8594 : loss : 0.022300, loss_ce: 0.006100\n",
            "iteration 8595 : loss : 0.035051, loss_ce: 0.005006\n",
            "iteration 8596 : loss : 0.022044, loss_ce: 0.006010\n",
            "iteration 8597 : loss : 0.028116, loss_ce: 0.013168\n",
            "iteration 8598 : loss : 0.023799, loss_ce: 0.006629\n",
            "iteration 8599 : loss : 0.024416, loss_ce: 0.009950\n",
            "iteration 8600 : loss : 0.027560, loss_ce: 0.009919\n",
            "iteration 8601 : loss : 0.027178, loss_ce: 0.009914\n",
            "iteration 8602 : loss : 0.023860, loss_ce: 0.009373\n",
            "iteration 8603 : loss : 0.021814, loss_ce: 0.006270\n",
            "iteration 8604 : loss : 0.024563, loss_ce: 0.010330\n",
            "iteration 8605 : loss : 0.026343, loss_ce: 0.008953\n",
            "iteration 8606 : loss : 0.021060, loss_ce: 0.006436\n",
            "iteration 8607 : loss : 0.029331, loss_ce: 0.014070\n",
            "iteration 8608 : loss : 0.029896, loss_ce: 0.010603\n",
            "iteration 8609 : loss : 0.023850, loss_ce: 0.005942\n",
            "iteration 8610 : loss : 0.033834, loss_ce: 0.006066\n",
            "iteration 8611 : loss : 0.025505, loss_ce: 0.009045\n",
            "iteration 8612 : loss : 0.023594, loss_ce: 0.008044\n",
            "iteration 8613 : loss : 0.026293, loss_ce: 0.012531\n",
            "iteration 8614 : loss : 0.030133, loss_ce: 0.014366\n",
            "iteration 8615 : loss : 0.029413, loss_ce: 0.007639\n",
            "iteration 8616 : loss : 0.028246, loss_ce: 0.007953\n",
            "iteration 8617 : loss : 0.025951, loss_ce: 0.008492\n",
            "iteration 8618 : loss : 0.019096, loss_ce: 0.005341\n",
            "iteration 8619 : loss : 0.024300, loss_ce: 0.009561\n",
            "iteration 8620 : loss : 0.028514, loss_ce: 0.008589\n",
            "iteration 8621 : loss : 0.025994, loss_ce: 0.007809\n",
            "iteration 8622 : loss : 0.025914, loss_ce: 0.007366\n",
            "iteration 8623 : loss : 0.024450, loss_ce: 0.010791\n",
            "iteration 8624 : loss : 0.073688, loss_ce: 0.005330\n",
            "iteration 8625 : loss : 0.028376, loss_ce: 0.010930\n",
            "iteration 8626 : loss : 0.019564, loss_ce: 0.005646\n",
            "iteration 8627 : loss : 0.025501, loss_ce: 0.007147\n",
            "iteration 8628 : loss : 0.027096, loss_ce: 0.009727\n",
            "iteration 8629 : loss : 0.024262, loss_ce: 0.005533\n",
            "iteration 8630 : loss : 0.026099, loss_ce: 0.008213\n",
            "iteration 8631 : loss : 0.027430, loss_ce: 0.011621\n",
            "iteration 8632 : loss : 0.024265, loss_ce: 0.011173\n",
            "iteration 8633 : loss : 0.027918, loss_ce: 0.010996\n",
            "iteration 8634 : loss : 0.026509, loss_ce: 0.010896\n",
            "iteration 8635 : loss : 0.030729, loss_ce: 0.014695\n",
            "iteration 8636 : loss : 0.027063, loss_ce: 0.007325\n",
            "iteration 8637 : loss : 0.021846, loss_ce: 0.005757\n",
            "iteration 8638 : loss : 0.030847, loss_ce: 0.012122\n",
            "iteration 8639 : loss : 0.026525, loss_ce: 0.008138\n",
            "iteration 8640 : loss : 0.019300, loss_ce: 0.006152\n",
            "iteration 8641 : loss : 0.025980, loss_ce: 0.012370\n",
            "iteration 8642 : loss : 0.027332, loss_ce: 0.013174\n",
            "iteration 8643 : loss : 0.026738, loss_ce: 0.006408\n",
            "iteration 8644 : loss : 0.025193, loss_ce: 0.010839\n",
            "iteration 8645 : loss : 0.029456, loss_ce: 0.008298\n",
            "iteration 8646 : loss : 0.023455, loss_ce: 0.007192\n",
            "iteration 8647 : loss : 0.025704, loss_ce: 0.009274\n",
            "iteration 8648 : loss : 0.028370, loss_ce: 0.009512\n",
            "iteration 8649 : loss : 0.077996, loss_ce: 0.004271\n",
            "iteration 8650 : loss : 0.028208, loss_ce: 0.007808\n",
            "iteration 8651 : loss : 0.035145, loss_ce: 0.012821\n",
            "iteration 8652 : loss : 0.034899, loss_ce: 0.007698\n",
            "iteration 8653 : loss : 0.022902, loss_ce: 0.007823\n",
            "iteration 8654 : loss : 0.028941, loss_ce: 0.008252\n",
            "iteration 8655 : loss : 0.074962, loss_ce: 0.006955\n",
            "iteration 8656 : loss : 0.026675, loss_ce: 0.010327\n",
            "iteration 8657 : loss : 0.028991, loss_ce: 0.008284\n",
            "iteration 8658 : loss : 0.020370, loss_ce: 0.008181\n",
            " 78%|█████████████████████▊      | 117/150 [3:31:18<59:38, 108.45s/it]iteration 8659 : loss : 0.024214, loss_ce: 0.008294\n",
            "iteration 8660 : loss : 0.021577, loss_ce: 0.007759\n",
            "iteration 8661 : loss : 0.043776, loss_ce: 0.004424\n",
            "iteration 8662 : loss : 0.024444, loss_ce: 0.008673\n",
            "iteration 8663 : loss : 0.027503, loss_ce: 0.010429\n",
            "iteration 8664 : loss : 0.027932, loss_ce: 0.010914\n",
            "iteration 8665 : loss : 0.027056, loss_ce: 0.010404\n",
            "iteration 8666 : loss : 0.022577, loss_ce: 0.009109\n",
            "iteration 8667 : loss : 0.029884, loss_ce: 0.005836\n",
            "iteration 8668 : loss : 0.023266, loss_ce: 0.007203\n",
            "iteration 8669 : loss : 0.027255, loss_ce: 0.010684\n",
            "iteration 8670 : loss : 0.031192, loss_ce: 0.005393\n",
            "iteration 8671 : loss : 0.023973, loss_ce: 0.010465\n",
            "iteration 8672 : loss : 0.026928, loss_ce: 0.009084\n",
            "iteration 8673 : loss : 0.030812, loss_ce: 0.008099\n",
            "iteration 8674 : loss : 0.026905, loss_ce: 0.007998\n",
            "iteration 8675 : loss : 0.028832, loss_ce: 0.008129\n",
            "iteration 8676 : loss : 0.027377, loss_ce: 0.008156\n",
            "iteration 8677 : loss : 0.025023, loss_ce: 0.008155\n",
            "iteration 8678 : loss : 0.029144, loss_ce: 0.013101\n",
            "iteration 8679 : loss : 0.030167, loss_ce: 0.007019\n",
            "iteration 8680 : loss : 0.021164, loss_ce: 0.008499\n",
            "iteration 8681 : loss : 0.028464, loss_ce: 0.007789\n",
            "iteration 8682 : loss : 0.030708, loss_ce: 0.005983\n",
            "iteration 8683 : loss : 0.026105, loss_ce: 0.009012\n",
            "iteration 8684 : loss : 0.026317, loss_ce: 0.011241\n",
            "iteration 8685 : loss : 0.028769, loss_ce: 0.006103\n",
            "iteration 8686 : loss : 0.034445, loss_ce: 0.010820\n",
            "iteration 8687 : loss : 0.020665, loss_ce: 0.004809\n",
            "iteration 8688 : loss : 0.028871, loss_ce: 0.015184\n",
            "iteration 8689 : loss : 0.022402, loss_ce: 0.006521\n",
            "iteration 8690 : loss : 0.078452, loss_ce: 0.009787\n",
            "iteration 8691 : loss : 0.021647, loss_ce: 0.007046\n",
            "iteration 8692 : loss : 0.028116, loss_ce: 0.006014\n",
            "iteration 8693 : loss : 0.023401, loss_ce: 0.010176\n",
            "iteration 8694 : loss : 0.025041, loss_ce: 0.009816\n",
            "iteration 8695 : loss : 0.026062, loss_ce: 0.006624\n",
            "iteration 8696 : loss : 0.027697, loss_ce: 0.011478\n",
            "iteration 8697 : loss : 0.024540, loss_ce: 0.008791\n",
            "iteration 8698 : loss : 0.031373, loss_ce: 0.010425\n",
            "iteration 8699 : loss : 0.023560, loss_ce: 0.008401\n",
            "iteration 8700 : loss : 0.025917, loss_ce: 0.009215\n",
            "iteration 8701 : loss : 0.027210, loss_ce: 0.009613\n",
            "iteration 8702 : loss : 0.021958, loss_ce: 0.007744\n",
            "iteration 8703 : loss : 0.033110, loss_ce: 0.010563\n",
            "iteration 8704 : loss : 0.026750, loss_ce: 0.009857\n",
            "iteration 8705 : loss : 0.027838, loss_ce: 0.012507\n",
            "iteration 8706 : loss : 0.027626, loss_ce: 0.013303\n",
            "iteration 8707 : loss : 0.029490, loss_ce: 0.011933\n",
            "iteration 8708 : loss : 0.022996, loss_ce: 0.009447\n",
            "iteration 8709 : loss : 0.024744, loss_ce: 0.007525\n",
            "iteration 8710 : loss : 0.023755, loss_ce: 0.006102\n",
            "iteration 8711 : loss : 0.031468, loss_ce: 0.005319\n",
            "iteration 8712 : loss : 0.024304, loss_ce: 0.008115\n",
            "iteration 8713 : loss : 0.027566, loss_ce: 0.011473\n",
            "iteration 8714 : loss : 0.023727, loss_ce: 0.007529\n",
            "iteration 8715 : loss : 0.024204, loss_ce: 0.009257\n",
            "iteration 8716 : loss : 0.021576, loss_ce: 0.005292\n",
            "iteration 8717 : loss : 0.018813, loss_ce: 0.004669\n",
            "iteration 8718 : loss : 0.020183, loss_ce: 0.006988\n",
            "iteration 8719 : loss : 0.025594, loss_ce: 0.009418\n",
            "iteration 8720 : loss : 0.027719, loss_ce: 0.009481\n",
            "iteration 8721 : loss : 0.024919, loss_ce: 0.007616\n",
            "iteration 8722 : loss : 0.030494, loss_ce: 0.015276\n",
            "iteration 8723 : loss : 0.025977, loss_ce: 0.010492\n",
            "iteration 8724 : loss : 0.075146, loss_ce: 0.004532\n",
            "iteration 8725 : loss : 0.029819, loss_ce: 0.011188\n",
            "iteration 8726 : loss : 0.030736, loss_ce: 0.007457\n",
            "iteration 8727 : loss : 0.022992, loss_ce: 0.007556\n",
            "iteration 8728 : loss : 0.027921, loss_ce: 0.008757\n",
            "iteration 8729 : loss : 0.026816, loss_ce: 0.007212\n",
            "iteration 8730 : loss : 0.023404, loss_ce: 0.009244\n",
            "iteration 8731 : loss : 0.029927, loss_ce: 0.014132\n",
            "iteration 8732 : loss : 0.034294, loss_ce: 0.012307\n",
            " 79%|██████████████████████      | 118/150 [3:33:07<57:54, 108.58s/it]iteration 8733 : loss : 0.023463, loss_ce: 0.009885\n",
            "iteration 8734 : loss : 0.025026, loss_ce: 0.007304\n",
            "iteration 8735 : loss : 0.020836, loss_ce: 0.006216\n",
            "iteration 8736 : loss : 0.022196, loss_ce: 0.007585\n",
            "iteration 8737 : loss : 0.024937, loss_ce: 0.008980\n",
            "iteration 8738 : loss : 0.024669, loss_ce: 0.006578\n",
            "iteration 8739 : loss : 0.024571, loss_ce: 0.007670\n",
            "iteration 8740 : loss : 0.023462, loss_ce: 0.008222\n",
            "iteration 8741 : loss : 0.024455, loss_ce: 0.007654\n",
            "iteration 8742 : loss : 0.023141, loss_ce: 0.007805\n",
            "iteration 8743 : loss : 0.027888, loss_ce: 0.008593\n",
            "iteration 8744 : loss : 0.019477, loss_ce: 0.005128\n",
            "iteration 8745 : loss : 0.023211, loss_ce: 0.007968\n",
            "iteration 8746 : loss : 0.024951, loss_ce: 0.007484\n",
            "iteration 8747 : loss : 0.023889, loss_ce: 0.005824\n",
            "iteration 8748 : loss : 0.026824, loss_ce: 0.012133\n",
            "iteration 8749 : loss : 0.027569, loss_ce: 0.010364\n",
            "iteration 8750 : loss : 0.026942, loss_ce: 0.012325\n",
            "iteration 8751 : loss : 0.027828, loss_ce: 0.007716\n",
            "iteration 8752 : loss : 0.023839, loss_ce: 0.011340\n",
            "iteration 8753 : loss : 0.073438, loss_ce: 0.005765\n",
            "iteration 8754 : loss : 0.024679, loss_ce: 0.008901\n",
            "iteration 8755 : loss : 0.024668, loss_ce: 0.008131\n",
            "iteration 8756 : loss : 0.033635, loss_ce: 0.010811\n",
            "iteration 8757 : loss : 0.025266, loss_ce: 0.013039\n",
            "iteration 8758 : loss : 0.024410, loss_ce: 0.009347\n",
            "iteration 8759 : loss : 0.030291, loss_ce: 0.010887\n",
            "iteration 8760 : loss : 0.026036, loss_ce: 0.007801\n",
            "iteration 8761 : loss : 0.024393, loss_ce: 0.007638\n",
            "iteration 8762 : loss : 0.026167, loss_ce: 0.010954\n",
            "iteration 8763 : loss : 0.079010, loss_ce: 0.010457\n",
            "iteration 8764 : loss : 0.024503, loss_ce: 0.006768\n",
            "iteration 8765 : loss : 0.029077, loss_ce: 0.006227\n",
            "iteration 8766 : loss : 0.076555, loss_ce: 0.010965\n",
            "iteration 8767 : loss : 0.024949, loss_ce: 0.007361\n",
            "iteration 8768 : loss : 0.021195, loss_ce: 0.006602\n",
            "iteration 8769 : loss : 0.077835, loss_ce: 0.008568\n",
            "iteration 8770 : loss : 0.027774, loss_ce: 0.013743\n",
            "iteration 8771 : loss : 0.022354, loss_ce: 0.007306\n",
            "iteration 8772 : loss : 0.025745, loss_ce: 0.007750\n",
            "iteration 8773 : loss : 0.025273, loss_ce: 0.012101\n",
            "iteration 8774 : loss : 0.023707, loss_ce: 0.008260\n",
            "iteration 8775 : loss : 0.024623, loss_ce: 0.009337\n",
            "iteration 8776 : loss : 0.027800, loss_ce: 0.009448\n",
            "iteration 8777 : loss : 0.028835, loss_ce: 0.012093\n",
            "iteration 8778 : loss : 0.023429, loss_ce: 0.011273\n",
            "iteration 8779 : loss : 0.024497, loss_ce: 0.007291\n",
            "iteration 8780 : loss : 0.024356, loss_ce: 0.007692\n",
            "iteration 8781 : loss : 0.026016, loss_ce: 0.006492\n",
            "iteration 8782 : loss : 0.034401, loss_ce: 0.009863\n",
            "iteration 8783 : loss : 0.020593, loss_ce: 0.007245\n",
            "iteration 8784 : loss : 0.028473, loss_ce: 0.006807\n",
            "iteration 8785 : loss : 0.021890, loss_ce: 0.008203\n",
            "iteration 8786 : loss : 0.022612, loss_ce: 0.006205\n",
            "iteration 8787 : loss : 0.040772, loss_ce: 0.006991\n",
            "iteration 8788 : loss : 0.075973, loss_ce: 0.005956\n",
            "iteration 8789 : loss : 0.037939, loss_ce: 0.008595\n",
            "iteration 8790 : loss : 0.029824, loss_ce: 0.007700\n",
            "iteration 8791 : loss : 0.026491, loss_ce: 0.007735\n",
            "iteration 8792 : loss : 0.041208, loss_ce: 0.008529\n",
            "iteration 8793 : loss : 0.021862, loss_ce: 0.006311\n",
            "iteration 8794 : loss : 0.026557, loss_ce: 0.011370\n",
            "iteration 8795 : loss : 0.028324, loss_ce: 0.009935\n",
            "iteration 8796 : loss : 0.029018, loss_ce: 0.009967\n",
            "iteration 8797 : loss : 0.026419, loss_ce: 0.009561\n",
            "iteration 8798 : loss : 0.025439, loss_ce: 0.010897\n",
            "iteration 8799 : loss : 0.020914, loss_ce: 0.005391\n",
            "iteration 8800 : loss : 0.024741, loss_ce: 0.009216\n",
            "iteration 8801 : loss : 0.024495, loss_ce: 0.009408\n",
            "iteration 8802 : loss : 0.027861, loss_ce: 0.007797\n",
            "iteration 8803 : loss : 0.025563, loss_ce: 0.008117\n",
            "iteration 8804 : loss : 0.023508, loss_ce: 0.007448\n",
            "iteration 8805 : loss : 0.029883, loss_ce: 0.012060\n",
            "iteration 8806 : loss : 0.025986, loss_ce: 0.012866\n",
            " 79%|██████████████████████▏     | 119/150 [3:34:54<55:54, 108.21s/it]iteration 8807 : loss : 0.052812, loss_ce: 0.007936\n",
            "iteration 8808 : loss : 0.032246, loss_ce: 0.008910\n",
            "iteration 8809 : loss : 0.022027, loss_ce: 0.008494\n",
            "iteration 8810 : loss : 0.028489, loss_ce: 0.010528\n",
            "iteration 8811 : loss : 0.050712, loss_ce: 0.008030\n",
            "iteration 8812 : loss : 0.032726, loss_ce: 0.005697\n",
            "iteration 8813 : loss : 0.034217, loss_ce: 0.012230\n",
            "iteration 8814 : loss : 0.073296, loss_ce: 0.004833\n",
            "iteration 8815 : loss : 0.026793, loss_ce: 0.006223\n",
            "iteration 8816 : loss : 0.029100, loss_ce: 0.007501\n",
            "iteration 8817 : loss : 0.135249, loss_ce: 0.003027\n",
            "iteration 8818 : loss : 0.019793, loss_ce: 0.004321\n",
            "iteration 8819 : loss : 0.029736, loss_ce: 0.006259\n",
            "iteration 8820 : loss : 0.029275, loss_ce: 0.010729\n",
            "iteration 8821 : loss : 0.027828, loss_ce: 0.012137\n",
            "iteration 8822 : loss : 0.021862, loss_ce: 0.006085\n",
            "iteration 8823 : loss : 0.024974, loss_ce: 0.006665\n",
            "iteration 8824 : loss : 0.024638, loss_ce: 0.010674\n",
            "iteration 8825 : loss : 0.025565, loss_ce: 0.008553\n",
            "iteration 8826 : loss : 0.023247, loss_ce: 0.007720\n",
            "iteration 8827 : loss : 0.024459, loss_ce: 0.009232\n",
            "iteration 8828 : loss : 0.028308, loss_ce: 0.011393\n",
            "iteration 8829 : loss : 0.027509, loss_ce: 0.009065\n",
            "iteration 8830 : loss : 0.022485, loss_ce: 0.007815\n",
            "iteration 8831 : loss : 0.024201, loss_ce: 0.010720\n",
            "iteration 8832 : loss : 0.035210, loss_ce: 0.008297\n",
            "iteration 8833 : loss : 0.024623, loss_ce: 0.007584\n",
            "iteration 8834 : loss : 0.077038, loss_ce: 0.008187\n",
            "iteration 8835 : loss : 0.078601, loss_ce: 0.012540\n",
            "iteration 8836 : loss : 0.037928, loss_ce: 0.006963\n",
            "iteration 8837 : loss : 0.022223, loss_ce: 0.008104\n",
            "iteration 8838 : loss : 0.033189, loss_ce: 0.007415\n",
            "iteration 8839 : loss : 0.072448, loss_ce: 0.004992\n",
            "iteration 8840 : loss : 0.024042, loss_ce: 0.010422\n",
            "iteration 8841 : loss : 0.020252, loss_ce: 0.005489\n",
            "iteration 8842 : loss : 0.035318, loss_ce: 0.020492\n",
            "iteration 8843 : loss : 0.023370, loss_ce: 0.005618\n",
            "iteration 8844 : loss : 0.027477, loss_ce: 0.006609\n",
            "iteration 8845 : loss : 0.023301, loss_ce: 0.008215\n",
            "iteration 8846 : loss : 0.027376, loss_ce: 0.007900\n",
            "iteration 8847 : loss : 0.028093, loss_ce: 0.012051\n",
            "iteration 8848 : loss : 0.023745, loss_ce: 0.008669\n",
            "iteration 8849 : loss : 0.031932, loss_ce: 0.012048\n",
            "iteration 8850 : loss : 0.022642, loss_ce: 0.006945\n",
            "iteration 8851 : loss : 0.029143, loss_ce: 0.009685\n",
            "iteration 8852 : loss : 0.028100, loss_ce: 0.006686\n",
            "iteration 8853 : loss : 0.024963, loss_ce: 0.009789\n",
            "iteration 8854 : loss : 0.024668, loss_ce: 0.007710\n",
            "iteration 8855 : loss : 0.031515, loss_ce: 0.007005\n",
            "iteration 8856 : loss : 0.021203, loss_ce: 0.008694\n",
            "iteration 8857 : loss : 0.022555, loss_ce: 0.006727\n",
            "iteration 8858 : loss : 0.028563, loss_ce: 0.012219\n",
            "iteration 8859 : loss : 0.026595, loss_ce: 0.010842\n",
            "iteration 8860 : loss : 0.029379, loss_ce: 0.008544\n",
            "iteration 8861 : loss : 0.022989, loss_ce: 0.008927\n",
            "iteration 8862 : loss : 0.029256, loss_ce: 0.016065\n",
            "iteration 8863 : loss : 0.025860, loss_ce: 0.008016\n",
            "iteration 8864 : loss : 0.024720, loss_ce: 0.010488\n",
            "iteration 8865 : loss : 0.027312, loss_ce: 0.011276\n",
            "iteration 8866 : loss : 0.025200, loss_ce: 0.010900\n",
            "iteration 8867 : loss : 0.026490, loss_ce: 0.010063\n",
            "iteration 8868 : loss : 0.067188, loss_ce: 0.005595\n",
            "iteration 8869 : loss : 0.079175, loss_ce: 0.007136\n",
            "iteration 8870 : loss : 0.073894, loss_ce: 0.006178\n",
            "iteration 8871 : loss : 0.026392, loss_ce: 0.008348\n",
            "iteration 8872 : loss : 0.024665, loss_ce: 0.010223\n",
            "iteration 8873 : loss : 0.029647, loss_ce: 0.011439\n",
            "iteration 8874 : loss : 0.029375, loss_ce: 0.008978\n",
            "iteration 8875 : loss : 0.018355, loss_ce: 0.004415\n",
            "iteration 8876 : loss : 0.022739, loss_ce: 0.009009\n",
            "iteration 8877 : loss : 0.027017, loss_ce: 0.007915\n",
            "iteration 8878 : loss : 0.023134, loss_ce: 0.009984\n",
            "iteration 8879 : loss : 0.028489, loss_ce: 0.010811\n",
            "iteration 8880 : loss : 0.026123, loss_ce: 0.006283\n",
            " 80%|██████████████████████▍     | 120/150 [3:36:42<54:03, 108.11s/it]iteration 8881 : loss : 0.024897, loss_ce: 0.004900\n",
            "iteration 8882 : loss : 0.024892, loss_ce: 0.007527\n",
            "iteration 8883 : loss : 0.030744, loss_ce: 0.009003\n",
            "iteration 8884 : loss : 0.026334, loss_ce: 0.010524\n",
            "iteration 8885 : loss : 0.078520, loss_ce: 0.007414\n",
            "iteration 8886 : loss : 0.027114, loss_ce: 0.012221\n",
            "iteration 8887 : loss : 0.029106, loss_ce: 0.012710\n",
            "iteration 8888 : loss : 0.033517, loss_ce: 0.007691\n",
            "iteration 8889 : loss : 0.024057, loss_ce: 0.006390\n",
            "iteration 8890 : loss : 0.028122, loss_ce: 0.013237\n",
            "iteration 8891 : loss : 0.026053, loss_ce: 0.007174\n",
            "iteration 8892 : loss : 0.023269, loss_ce: 0.006382\n",
            "iteration 8893 : loss : 0.022564, loss_ce: 0.008090\n",
            "iteration 8894 : loss : 0.067442, loss_ce: 0.011856\n",
            "iteration 8895 : loss : 0.028211, loss_ce: 0.009420\n",
            "iteration 8896 : loss : 0.029330, loss_ce: 0.005644\n",
            "iteration 8897 : loss : 0.025426, loss_ce: 0.010887\n",
            "iteration 8898 : loss : 0.022215, loss_ce: 0.004542\n",
            "iteration 8899 : loss : 0.024248, loss_ce: 0.007053\n",
            "iteration 8900 : loss : 0.023531, loss_ce: 0.010710\n",
            "iteration 8901 : loss : 0.028201, loss_ce: 0.012102\n",
            "iteration 8902 : loss : 0.024037, loss_ce: 0.010121\n",
            "iteration 8903 : loss : 0.025416, loss_ce: 0.006127\n",
            "iteration 8904 : loss : 0.030081, loss_ce: 0.011661\n",
            "iteration 8905 : loss : 0.030384, loss_ce: 0.011144\n",
            "iteration 8906 : loss : 0.023984, loss_ce: 0.009726\n",
            "iteration 8907 : loss : 0.026743, loss_ce: 0.011744\n",
            "iteration 8908 : loss : 0.076878, loss_ce: 0.006835\n",
            "iteration 8909 : loss : 0.022377, loss_ce: 0.006543\n",
            "iteration 8910 : loss : 0.031662, loss_ce: 0.009032\n",
            "iteration 8911 : loss : 0.025364, loss_ce: 0.011363\n",
            "iteration 8912 : loss : 0.027119, loss_ce: 0.010692\n",
            "iteration 8913 : loss : 0.024955, loss_ce: 0.008702\n",
            "iteration 8914 : loss : 0.025642, loss_ce: 0.009210\n",
            "iteration 8915 : loss : 0.022883, loss_ce: 0.007359\n",
            "iteration 8916 : loss : 0.023451, loss_ce: 0.005828\n",
            "iteration 8917 : loss : 0.023531, loss_ce: 0.006406\n",
            "iteration 8918 : loss : 0.024548, loss_ce: 0.008714\n",
            "iteration 8919 : loss : 0.022540, loss_ce: 0.008981\n",
            "iteration 8920 : loss : 0.027264, loss_ce: 0.011057\n",
            "iteration 8921 : loss : 0.028532, loss_ce: 0.012238\n",
            "iteration 8922 : loss : 0.029596, loss_ce: 0.012363\n",
            "iteration 8923 : loss : 0.024459, loss_ce: 0.012129\n",
            "iteration 8924 : loss : 0.029504, loss_ce: 0.006674\n",
            "iteration 8925 : loss : 0.021881, loss_ce: 0.007770\n",
            "iteration 8926 : loss : 0.024767, loss_ce: 0.006356\n",
            "iteration 8927 : loss : 0.071298, loss_ce: 0.004430\n",
            "iteration 8928 : loss : 0.031565, loss_ce: 0.007362\n",
            "iteration 8929 : loss : 0.076156, loss_ce: 0.004304\n",
            "iteration 8930 : loss : 0.024140, loss_ce: 0.005243\n",
            "iteration 8931 : loss : 0.024423, loss_ce: 0.006338\n",
            "iteration 8932 : loss : 0.027497, loss_ce: 0.010032\n",
            "iteration 8933 : loss : 0.024358, loss_ce: 0.010430\n",
            "iteration 8934 : loss : 0.024816, loss_ce: 0.007964\n",
            "iteration 8935 : loss : 0.025087, loss_ce: 0.008075\n",
            "iteration 8936 : loss : 0.022763, loss_ce: 0.009376\n",
            "iteration 8937 : loss : 0.077163, loss_ce: 0.005281\n",
            "iteration 8938 : loss : 0.025278, loss_ce: 0.010480\n",
            "iteration 8939 : loss : 0.047767, loss_ce: 0.008787\n",
            "iteration 8940 : loss : 0.030665, loss_ce: 0.009753\n",
            "iteration 8941 : loss : 0.025043, loss_ce: 0.008826\n",
            "iteration 8942 : loss : 0.024332, loss_ce: 0.006569\n",
            "iteration 8943 : loss : 0.050003, loss_ce: 0.011336\n",
            "iteration 8944 : loss : 0.026429, loss_ce: 0.010356\n",
            "iteration 8945 : loss : 0.077988, loss_ce: 0.009307\n",
            "iteration 8946 : loss : 0.034929, loss_ce: 0.013624\n",
            "iteration 8947 : loss : 0.029959, loss_ce: 0.012119\n",
            "iteration 8948 : loss : 0.028786, loss_ce: 0.008852\n",
            "iteration 8949 : loss : 0.029589, loss_ce: 0.008001\n",
            "iteration 8950 : loss : 0.029314, loss_ce: 0.009524\n",
            "iteration 8951 : loss : 0.032283, loss_ce: 0.011423\n",
            "iteration 8952 : loss : 0.028920, loss_ce: 0.014908\n",
            "iteration 8953 : loss : 0.024644, loss_ce: 0.009632\n",
            "iteration 8954 : loss : 0.027915, loss_ce: 0.006154\n",
            " 81%|██████████████████████▌     | 121/150 [3:38:30<52:11, 107.97s/it]iteration 8955 : loss : 0.023173, loss_ce: 0.007845\n",
            "iteration 8956 : loss : 0.081726, loss_ce: 0.006559\n",
            "iteration 8957 : loss : 0.075808, loss_ce: 0.009404\n",
            "iteration 8958 : loss : 0.028693, loss_ce: 0.010078\n",
            "iteration 8959 : loss : 0.025246, loss_ce: 0.006872\n",
            "iteration 8960 : loss : 0.078000, loss_ce: 0.005660\n",
            "iteration 8961 : loss : 0.053531, loss_ce: 0.006020\n",
            "iteration 8962 : loss : 0.027343, loss_ce: 0.008963\n",
            "iteration 8963 : loss : 0.074909, loss_ce: 0.004429\n",
            "iteration 8964 : loss : 0.029202, loss_ce: 0.008708\n",
            "iteration 8965 : loss : 0.036785, loss_ce: 0.008637\n",
            "iteration 8966 : loss : 0.025314, loss_ce: 0.009071\n",
            "iteration 8967 : loss : 0.028220, loss_ce: 0.016318\n",
            "iteration 8968 : loss : 0.031068, loss_ce: 0.014269\n",
            "iteration 8969 : loss : 0.029964, loss_ce: 0.011143\n",
            "iteration 8970 : loss : 0.029933, loss_ce: 0.012934\n",
            "iteration 8971 : loss : 0.024598, loss_ce: 0.011983\n",
            "iteration 8972 : loss : 0.027093, loss_ce: 0.009437\n",
            "iteration 8973 : loss : 0.027053, loss_ce: 0.010475\n",
            "iteration 8974 : loss : 0.027199, loss_ce: 0.010564\n",
            "iteration 8975 : loss : 0.026351, loss_ce: 0.009555\n",
            "iteration 8976 : loss : 0.028907, loss_ce: 0.012358\n",
            "iteration 8977 : loss : 0.032667, loss_ce: 0.013105\n",
            "iteration 8978 : loss : 0.028143, loss_ce: 0.008879\n",
            "iteration 8979 : loss : 0.026633, loss_ce: 0.009598\n",
            "iteration 8980 : loss : 0.027256, loss_ce: 0.010890\n",
            "iteration 8981 : loss : 0.022773, loss_ce: 0.007024\n",
            "iteration 8982 : loss : 0.076418, loss_ce: 0.005933\n",
            "iteration 8983 : loss : 0.025300, loss_ce: 0.011154\n",
            "iteration 8984 : loss : 0.053346, loss_ce: 0.008468\n",
            "iteration 8985 : loss : 0.024109, loss_ce: 0.008534\n",
            "iteration 8986 : loss : 0.026157, loss_ce: 0.011724\n",
            "iteration 8987 : loss : 0.022524, loss_ce: 0.006551\n",
            "iteration 8988 : loss : 0.026668, loss_ce: 0.010050\n",
            "iteration 8989 : loss : 0.026122, loss_ce: 0.008520\n",
            "iteration 8990 : loss : 0.031069, loss_ce: 0.011431\n",
            "iteration 8991 : loss : 0.024744, loss_ce: 0.006945\n",
            "iteration 8992 : loss : 0.028046, loss_ce: 0.009004\n",
            "iteration 8993 : loss : 0.029136, loss_ce: 0.013164\n",
            "iteration 8994 : loss : 0.026899, loss_ce: 0.009305\n",
            "iteration 8995 : loss : 0.027562, loss_ce: 0.013774\n",
            "iteration 8996 : loss : 0.025584, loss_ce: 0.008116\n",
            "iteration 8997 : loss : 0.031234, loss_ce: 0.009800\n",
            "iteration 8998 : loss : 0.027489, loss_ce: 0.009773\n",
            "iteration 8999 : loss : 0.024986, loss_ce: 0.011507\n",
            "iteration 9000 : loss : 0.032790, loss_ce: 0.013034\n",
            "iteration 9001 : loss : 0.027718, loss_ce: 0.007774\n",
            "iteration 9002 : loss : 0.093943, loss_ce: 0.008179\n",
            "iteration 9003 : loss : 0.028960, loss_ce: 0.010336\n",
            "iteration 9004 : loss : 0.023366, loss_ce: 0.008031\n",
            "iteration 9005 : loss : 0.027742, loss_ce: 0.009363\n",
            "iteration 9006 : loss : 0.077589, loss_ce: 0.003636\n",
            "iteration 9007 : loss : 0.024887, loss_ce: 0.007937\n",
            "iteration 9008 : loss : 0.023779, loss_ce: 0.009157\n",
            "iteration 9009 : loss : 0.024028, loss_ce: 0.011426\n",
            "iteration 9010 : loss : 0.026906, loss_ce: 0.008561\n",
            "iteration 9011 : loss : 0.023613, loss_ce: 0.007891\n",
            "iteration 9012 : loss : 0.025432, loss_ce: 0.006726\n",
            "iteration 9013 : loss : 0.030846, loss_ce: 0.012345\n",
            "iteration 9014 : loss : 0.031852, loss_ce: 0.012586\n",
            "iteration 9015 : loss : 0.029869, loss_ce: 0.010612\n",
            "iteration 9016 : loss : 0.025896, loss_ce: 0.009588\n",
            "iteration 9017 : loss : 0.032486, loss_ce: 0.008754\n",
            "iteration 9018 : loss : 0.025286, loss_ce: 0.013016\n",
            "iteration 9019 : loss : 0.027788, loss_ce: 0.010663\n",
            "iteration 9020 : loss : 0.028477, loss_ce: 0.007530\n",
            "iteration 9021 : loss : 0.071470, loss_ce: 0.005947\n",
            "iteration 9022 : loss : 0.028118, loss_ce: 0.009199\n",
            "iteration 9023 : loss : 0.020690, loss_ce: 0.006089\n",
            "iteration 9024 : loss : 0.030034, loss_ce: 0.007510\n",
            "iteration 9025 : loss : 0.027060, loss_ce: 0.009977\n",
            "iteration 9026 : loss : 0.023784, loss_ce: 0.005714\n",
            "iteration 9027 : loss : 0.025382, loss_ce: 0.006083\n",
            "iteration 9028 : loss : 0.032386, loss_ce: 0.016919\n",
            " 81%|██████████████████████▊     | 122/150 [3:40:19<50:34, 108.38s/it]iteration 9029 : loss : 0.023323, loss_ce: 0.007133\n",
            "iteration 9030 : loss : 0.028397, loss_ce: 0.005509\n",
            "iteration 9031 : loss : 0.025061, loss_ce: 0.006895\n",
            "iteration 9032 : loss : 0.078390, loss_ce: 0.005032\n",
            "iteration 9033 : loss : 0.024710, loss_ce: 0.006039\n",
            "iteration 9034 : loss : 0.029985, loss_ce: 0.011173\n",
            "iteration 9035 : loss : 0.023890, loss_ce: 0.007978\n",
            "iteration 9036 : loss : 0.027652, loss_ce: 0.010142\n",
            "iteration 9037 : loss : 0.035042, loss_ce: 0.008266\n",
            "iteration 9038 : loss : 0.029408, loss_ce: 0.010958\n",
            "iteration 9039 : loss : 0.025191, loss_ce: 0.008202\n",
            "iteration 9040 : loss : 0.028829, loss_ce: 0.010948\n",
            "iteration 9041 : loss : 0.073889, loss_ce: 0.005506\n",
            "iteration 9042 : loss : 0.024540, loss_ce: 0.007705\n",
            "iteration 9043 : loss : 0.028215, loss_ce: 0.010284\n",
            "iteration 9044 : loss : 0.027160, loss_ce: 0.012140\n",
            "iteration 9045 : loss : 0.074333, loss_ce: 0.007182\n",
            "iteration 9046 : loss : 0.029425, loss_ce: 0.014188\n",
            "iteration 9047 : loss : 0.021138, loss_ce: 0.007993\n",
            "iteration 9048 : loss : 0.082332, loss_ce: 0.006547\n",
            "iteration 9049 : loss : 0.072256, loss_ce: 0.005340\n",
            "iteration 9050 : loss : 0.038414, loss_ce: 0.003759\n",
            "iteration 9051 : loss : 0.026473, loss_ce: 0.013353\n",
            "iteration 9052 : loss : 0.026337, loss_ce: 0.009958\n",
            "iteration 9053 : loss : 0.082251, loss_ce: 0.006399\n",
            "iteration 9054 : loss : 0.025182, loss_ce: 0.009905\n",
            "iteration 9055 : loss : 0.029014, loss_ce: 0.010332\n",
            "iteration 9056 : loss : 0.024903, loss_ce: 0.011942\n",
            "iteration 9057 : loss : 0.077468, loss_ce: 0.006688\n",
            "iteration 9058 : loss : 0.027990, loss_ce: 0.009832\n",
            "iteration 9059 : loss : 0.027394, loss_ce: 0.009105\n",
            "iteration 9060 : loss : 0.027744, loss_ce: 0.009884\n",
            "iteration 9061 : loss : 0.027101, loss_ce: 0.011041\n",
            "iteration 9062 : loss : 0.026499, loss_ce: 0.010359\n",
            "iteration 9063 : loss : 0.079124, loss_ce: 0.010668\n",
            "iteration 9064 : loss : 0.028167, loss_ce: 0.012902\n",
            "iteration 9065 : loss : 0.039719, loss_ce: 0.011133\n",
            "iteration 9066 : loss : 0.024328, loss_ce: 0.006923\n",
            "iteration 9067 : loss : 0.025136, loss_ce: 0.010710\n",
            "iteration 9068 : loss : 0.027186, loss_ce: 0.010478\n",
            "iteration 9069 : loss : 0.025624, loss_ce: 0.009973\n",
            "iteration 9070 : loss : 0.025399, loss_ce: 0.005258\n",
            "iteration 9071 : loss : 0.074573, loss_ce: 0.004934\n",
            "iteration 9072 : loss : 0.024692, loss_ce: 0.008995\n",
            "iteration 9073 : loss : 0.028940, loss_ce: 0.010425\n",
            "iteration 9074 : loss : 0.025813, loss_ce: 0.010358\n",
            "iteration 9075 : loss : 0.027506, loss_ce: 0.010992\n",
            "iteration 9076 : loss : 0.026657, loss_ce: 0.008820\n",
            "iteration 9077 : loss : 0.034979, loss_ce: 0.010301\n",
            "iteration 9078 : loss : 0.027777, loss_ce: 0.009332\n",
            "iteration 9079 : loss : 0.025193, loss_ce: 0.010346\n",
            "iteration 9080 : loss : 0.026657, loss_ce: 0.009073\n",
            "iteration 9081 : loss : 0.021076, loss_ce: 0.007150\n",
            "iteration 9082 : loss : 0.025458, loss_ce: 0.008774\n",
            "iteration 9083 : loss : 0.025482, loss_ce: 0.007662\n",
            "iteration 9084 : loss : 0.024744, loss_ce: 0.005600\n",
            "iteration 9085 : loss : 0.027404, loss_ce: 0.008485\n",
            "iteration 9086 : loss : 0.022418, loss_ce: 0.007597\n",
            "iteration 9087 : loss : 0.023529, loss_ce: 0.010240\n",
            "iteration 9088 : loss : 0.027213, loss_ce: 0.005044\n",
            "iteration 9089 : loss : 0.026608, loss_ce: 0.013530\n",
            "iteration 9090 : loss : 0.045940, loss_ce: 0.008063\n",
            "iteration 9091 : loss : 0.022668, loss_ce: 0.009069\n",
            "iteration 9092 : loss : 0.025744, loss_ce: 0.011720\n",
            "iteration 9093 : loss : 0.074697, loss_ce: 0.004802\n",
            "iteration 9094 : loss : 0.025390, loss_ce: 0.005589\n",
            "iteration 9095 : loss : 0.098530, loss_ce: 0.008061\n",
            "iteration 9096 : loss : 0.025630, loss_ce: 0.012821\n",
            "iteration 9097 : loss : 0.026453, loss_ce: 0.012546\n",
            "iteration 9098 : loss : 0.026754, loss_ce: 0.009136\n",
            "iteration 9099 : loss : 0.029172, loss_ce: 0.009302\n",
            "iteration 9100 : loss : 0.022150, loss_ce: 0.007019\n",
            "iteration 9101 : loss : 0.023159, loss_ce: 0.006767\n",
            "iteration 9102 : loss : 0.028496, loss_ce: 0.011576\n",
            " 82%|██████████████████████▉     | 123/150 [3:42:08<48:47, 108.42s/it]iteration 9103 : loss : 0.025432, loss_ce: 0.010340\n",
            "iteration 9104 : loss : 0.027146, loss_ce: 0.008890\n",
            "iteration 9105 : loss : 0.074510, loss_ce: 0.006245\n",
            "iteration 9106 : loss : 0.025197, loss_ce: 0.011179\n",
            "iteration 9107 : loss : 0.077061, loss_ce: 0.007661\n",
            "iteration 9108 : loss : 0.127433, loss_ce: 0.004183\n",
            "iteration 9109 : loss : 0.026569, loss_ce: 0.010069\n",
            "iteration 9110 : loss : 0.032527, loss_ce: 0.008524\n",
            "iteration 9111 : loss : 0.022893, loss_ce: 0.008587\n",
            "iteration 9112 : loss : 0.025747, loss_ce: 0.008141\n",
            "iteration 9113 : loss : 0.034664, loss_ce: 0.007318\n",
            "iteration 9114 : loss : 0.024745, loss_ce: 0.008600\n",
            "iteration 9115 : loss : 0.022157, loss_ce: 0.007374\n",
            "iteration 9116 : loss : 0.056444, loss_ce: 0.006301\n",
            "iteration 9117 : loss : 0.023989, loss_ce: 0.010551\n",
            "iteration 9118 : loss : 0.022757, loss_ce: 0.006473\n",
            "iteration 9119 : loss : 0.027040, loss_ce: 0.010937\n",
            "iteration 9120 : loss : 0.073791, loss_ce: 0.007574\n",
            "iteration 9121 : loss : 0.024078, loss_ce: 0.010646\n",
            "iteration 9122 : loss : 0.026839, loss_ce: 0.007362\n",
            "iteration 9123 : loss : 0.020908, loss_ce: 0.006283\n",
            "iteration 9124 : loss : 0.032369, loss_ce: 0.008504\n",
            "iteration 9125 : loss : 0.020789, loss_ce: 0.004732\n",
            "iteration 9126 : loss : 0.027204, loss_ce: 0.011864\n",
            "iteration 9127 : loss : 0.026343, loss_ce: 0.008423\n",
            "iteration 9128 : loss : 0.022129, loss_ce: 0.006874\n",
            "iteration 9129 : loss : 0.024621, loss_ce: 0.009402\n",
            "iteration 9130 : loss : 0.025735, loss_ce: 0.009417\n",
            "iteration 9131 : loss : 0.023866, loss_ce: 0.006725\n",
            "iteration 9132 : loss : 0.028841, loss_ce: 0.007586\n",
            "iteration 9133 : loss : 0.027006, loss_ce: 0.010017\n",
            "iteration 9134 : loss : 0.028021, loss_ce: 0.011509\n",
            "iteration 9135 : loss : 0.024150, loss_ce: 0.005615\n",
            "iteration 9136 : loss : 0.028754, loss_ce: 0.008178\n",
            "iteration 9137 : loss : 0.029855, loss_ce: 0.011043\n",
            "iteration 9138 : loss : 0.026390, loss_ce: 0.009260\n",
            "iteration 9139 : loss : 0.031244, loss_ce: 0.012529\n",
            "iteration 9140 : loss : 0.071479, loss_ce: 0.005772\n",
            "iteration 9141 : loss : 0.026182, loss_ce: 0.010462\n",
            "iteration 9142 : loss : 0.026311, loss_ce: 0.009995\n",
            "iteration 9143 : loss : 0.028356, loss_ce: 0.008303\n",
            "iteration 9144 : loss : 0.025559, loss_ce: 0.010937\n",
            "iteration 9145 : loss : 0.025821, loss_ce: 0.009756\n",
            "iteration 9146 : loss : 0.024327, loss_ce: 0.009386\n",
            "iteration 9147 : loss : 0.025216, loss_ce: 0.008697\n",
            "iteration 9148 : loss : 0.028996, loss_ce: 0.012444\n",
            "iteration 9149 : loss : 0.030189, loss_ce: 0.009132\n",
            "iteration 9150 : loss : 0.022130, loss_ce: 0.007986\n",
            "iteration 9151 : loss : 0.028127, loss_ce: 0.009575\n",
            "iteration 9152 : loss : 0.030390, loss_ce: 0.013373\n",
            "iteration 9153 : loss : 0.024491, loss_ce: 0.008130\n",
            "iteration 9154 : loss : 0.077931, loss_ce: 0.004544\n",
            "iteration 9155 : loss : 0.025540, loss_ce: 0.009974\n",
            "iteration 9156 : loss : 0.026217, loss_ce: 0.012515\n",
            "iteration 9157 : loss : 0.028912, loss_ce: 0.008959\n",
            "iteration 9158 : loss : 0.026980, loss_ce: 0.007310\n",
            "iteration 9159 : loss : 0.029875, loss_ce: 0.008749\n",
            "iteration 9160 : loss : 0.027299, loss_ce: 0.006200\n",
            "iteration 9161 : loss : 0.023992, loss_ce: 0.007105\n",
            "iteration 9162 : loss : 0.024860, loss_ce: 0.008569\n",
            "iteration 9163 : loss : 0.086370, loss_ce: 0.006674\n",
            "iteration 9164 : loss : 0.027713, loss_ce: 0.012652\n",
            "iteration 9165 : loss : 0.027337, loss_ce: 0.007908\n",
            "iteration 9166 : loss : 0.028687, loss_ce: 0.012019\n",
            "iteration 9167 : loss : 0.028083, loss_ce: 0.010978\n",
            "iteration 9168 : loss : 0.034154, loss_ce: 0.005903\n",
            "iteration 9169 : loss : 0.025727, loss_ce: 0.011881\n",
            "iteration 9170 : loss : 0.025534, loss_ce: 0.009286\n",
            "iteration 9171 : loss : 0.077864, loss_ce: 0.007145\n",
            "iteration 9172 : loss : 0.022058, loss_ce: 0.008409\n",
            "iteration 9173 : loss : 0.025504, loss_ce: 0.007191\n",
            "iteration 9174 : loss : 0.027224, loss_ce: 0.007603\n",
            "iteration 9175 : loss : 0.045175, loss_ce: 0.010101\n",
            "iteration 9176 : loss : 0.025115, loss_ce: 0.012697\n",
            " 83%|███████████████████████▏    | 124/150 [3:43:55<46:48, 108.02s/it]iteration 9177 : loss : 0.077490, loss_ce: 0.007934\n",
            "iteration 9178 : loss : 0.044611, loss_ce: 0.013460\n",
            "iteration 9179 : loss : 0.029191, loss_ce: 0.007585\n",
            "iteration 9180 : loss : 0.026848, loss_ce: 0.009824\n",
            "iteration 9181 : loss : 0.026088, loss_ce: 0.007039\n",
            "iteration 9182 : loss : 0.027106, loss_ce: 0.007427\n",
            "iteration 9183 : loss : 0.022231, loss_ce: 0.007551\n",
            "iteration 9184 : loss : 0.026482, loss_ce: 0.007155\n",
            "iteration 9185 : loss : 0.027278, loss_ce: 0.005881\n",
            "iteration 9186 : loss : 0.024577, loss_ce: 0.011993\n",
            "iteration 9187 : loss : 0.027853, loss_ce: 0.006932\n",
            "iteration 9188 : loss : 0.027964, loss_ce: 0.011540\n",
            "iteration 9189 : loss : 0.025001, loss_ce: 0.010960\n",
            "iteration 9190 : loss : 0.029197, loss_ce: 0.005302\n",
            "iteration 9191 : loss : 0.026098, loss_ce: 0.009183\n",
            "iteration 9192 : loss : 0.028353, loss_ce: 0.010222\n",
            "iteration 9193 : loss : 0.028469, loss_ce: 0.011101\n",
            "iteration 9194 : loss : 0.029028, loss_ce: 0.010687\n",
            "iteration 9195 : loss : 0.025222, loss_ce: 0.009652\n",
            "iteration 9196 : loss : 0.032395, loss_ce: 0.012236\n",
            "iteration 9197 : loss : 0.030001, loss_ce: 0.008196\n",
            "iteration 9198 : loss : 0.022772, loss_ce: 0.007661\n",
            "iteration 9199 : loss : 0.023561, loss_ce: 0.006088\n",
            "iteration 9200 : loss : 0.026667, loss_ce: 0.011761\n",
            "iteration 9201 : loss : 0.026883, loss_ce: 0.008127\n",
            "iteration 9202 : loss : 0.022878, loss_ce: 0.005851\n",
            "iteration 9203 : loss : 0.025506, loss_ce: 0.009382\n",
            "iteration 9204 : loss : 0.027676, loss_ce: 0.004707\n",
            "iteration 9205 : loss : 0.025873, loss_ce: 0.003740\n",
            "iteration 9206 : loss : 0.075942, loss_ce: 0.004390\n",
            "iteration 9207 : loss : 0.024081, loss_ce: 0.004906\n",
            "iteration 9208 : loss : 0.025467, loss_ce: 0.007831\n",
            "iteration 9209 : loss : 0.026469, loss_ce: 0.008207\n",
            "iteration 9210 : loss : 0.025674, loss_ce: 0.008698\n",
            "iteration 9211 : loss : 0.022027, loss_ce: 0.009234\n",
            "iteration 9212 : loss : 0.026881, loss_ce: 0.008619\n",
            "iteration 9213 : loss : 0.030261, loss_ce: 0.010922\n",
            "iteration 9214 : loss : 0.029359, loss_ce: 0.010061\n",
            "iteration 9215 : loss : 0.029260, loss_ce: 0.009669\n",
            "iteration 9216 : loss : 0.029569, loss_ce: 0.012190\n",
            "iteration 9217 : loss : 0.028506, loss_ce: 0.012303\n",
            "iteration 9218 : loss : 0.026737, loss_ce: 0.011311\n",
            "iteration 9219 : loss : 0.028163, loss_ce: 0.011674\n",
            "iteration 9220 : loss : 0.023151, loss_ce: 0.010354\n",
            "iteration 9221 : loss : 0.023291, loss_ce: 0.010197\n",
            "iteration 9222 : loss : 0.028749, loss_ce: 0.009552\n",
            "iteration 9223 : loss : 0.027301, loss_ce: 0.009847\n",
            "iteration 9224 : loss : 0.024262, loss_ce: 0.006455\n",
            "iteration 9225 : loss : 0.026183, loss_ce: 0.008858\n",
            "iteration 9226 : loss : 0.025050, loss_ce: 0.008823\n",
            "iteration 9227 : loss : 0.029349, loss_ce: 0.006573\n",
            "iteration 9228 : loss : 0.026112, loss_ce: 0.011022\n",
            "iteration 9229 : loss : 0.026077, loss_ce: 0.012505\n",
            "iteration 9230 : loss : 0.030703, loss_ce: 0.013078\n",
            "iteration 9231 : loss : 0.021414, loss_ce: 0.007483\n",
            "iteration 9232 : loss : 0.029217, loss_ce: 0.009477\n",
            "iteration 9233 : loss : 0.028775, loss_ce: 0.009993\n",
            "iteration 9234 : loss : 0.021518, loss_ce: 0.006559\n",
            "iteration 9235 : loss : 0.027970, loss_ce: 0.006658\n",
            "iteration 9236 : loss : 0.022875, loss_ce: 0.008095\n",
            "iteration 9237 : loss : 0.023994, loss_ce: 0.007739\n",
            "iteration 9238 : loss : 0.029949, loss_ce: 0.013908\n",
            "iteration 9239 : loss : 0.084221, loss_ce: 0.003718\n",
            "iteration 9240 : loss : 0.026017, loss_ce: 0.005524\n",
            "iteration 9241 : loss : 0.022492, loss_ce: 0.007025\n",
            "iteration 9242 : loss : 0.023345, loss_ce: 0.008782\n",
            "iteration 9243 : loss : 0.030030, loss_ce: 0.014113\n",
            "iteration 9244 : loss : 0.022646, loss_ce: 0.007185\n",
            "iteration 9245 : loss : 0.032429, loss_ce: 0.006083\n",
            "iteration 9246 : loss : 0.025088, loss_ce: 0.007475\n",
            "iteration 9247 : loss : 0.026015, loss_ce: 0.007359\n",
            "iteration 9248 : loss : 0.020749, loss_ce: 0.009487\n",
            "iteration 9249 : loss : 0.023025, loss_ce: 0.008963\n",
            "iteration 9250 : loss : 0.076455, loss_ce: 0.007288\n",
            " 83%|███████████████████████▎    | 125/150 [3:45:43<44:57, 107.91s/it]iteration 9251 : loss : 0.030408, loss_ce: 0.008763\n",
            "iteration 9252 : loss : 0.023725, loss_ce: 0.010930\n",
            "iteration 9253 : loss : 0.025873, loss_ce: 0.006429\n",
            "iteration 9254 : loss : 0.026174, loss_ce: 0.008038\n",
            "iteration 9255 : loss : 0.077263, loss_ce: 0.004772\n",
            "iteration 9256 : loss : 0.022488, loss_ce: 0.006029\n",
            "iteration 9257 : loss : 0.073786, loss_ce: 0.008931\n",
            "iteration 9258 : loss : 0.023210, loss_ce: 0.007547\n",
            "iteration 9259 : loss : 0.025748, loss_ce: 0.011369\n",
            "iteration 9260 : loss : 0.076236, loss_ce: 0.010328\n",
            "iteration 9261 : loss : 0.024475, loss_ce: 0.009506\n",
            "iteration 9262 : loss : 0.025259, loss_ce: 0.007541\n",
            "iteration 9263 : loss : 0.025191, loss_ce: 0.009530\n",
            "iteration 9264 : loss : 0.020718, loss_ce: 0.006040\n",
            "iteration 9265 : loss : 0.026439, loss_ce: 0.009553\n",
            "iteration 9266 : loss : 0.021828, loss_ce: 0.009207\n",
            "iteration 9267 : loss : 0.023703, loss_ce: 0.012899\n",
            "iteration 9268 : loss : 0.029198, loss_ce: 0.012528\n",
            "iteration 9269 : loss : 0.027813, loss_ce: 0.003680\n",
            "iteration 9270 : loss : 0.025990, loss_ce: 0.010453\n",
            "iteration 9271 : loss : 0.026381, loss_ce: 0.007913\n",
            "iteration 9272 : loss : 0.024702, loss_ce: 0.009754\n",
            "iteration 9273 : loss : 0.022359, loss_ce: 0.007659\n",
            "iteration 9274 : loss : 0.025582, loss_ce: 0.008837\n",
            "iteration 9275 : loss : 0.020071, loss_ce: 0.006018\n",
            "iteration 9276 : loss : 0.028085, loss_ce: 0.008190\n",
            "iteration 9277 : loss : 0.022740, loss_ce: 0.006491\n",
            "iteration 9278 : loss : 0.026952, loss_ce: 0.009364\n",
            "iteration 9279 : loss : 0.028921, loss_ce: 0.014607\n",
            "iteration 9280 : loss : 0.075467, loss_ce: 0.003937\n",
            "iteration 9281 : loss : 0.023691, loss_ce: 0.009820\n",
            "iteration 9282 : loss : 0.027265, loss_ce: 0.007417\n",
            "iteration 9283 : loss : 0.030394, loss_ce: 0.011155\n",
            "iteration 9284 : loss : 0.023191, loss_ce: 0.005499\n",
            "iteration 9285 : loss : 0.023820, loss_ce: 0.006864\n",
            "iteration 9286 : loss : 0.024489, loss_ce: 0.010246\n",
            "iteration 9287 : loss : 0.025879, loss_ce: 0.008128\n",
            "iteration 9288 : loss : 0.022842, loss_ce: 0.005736\n",
            "iteration 9289 : loss : 0.024891, loss_ce: 0.008447\n",
            "iteration 9290 : loss : 0.024563, loss_ce: 0.007420\n",
            "iteration 9291 : loss : 0.029728, loss_ce: 0.013650\n",
            "iteration 9292 : loss : 0.023940, loss_ce: 0.007050\n",
            "iteration 9293 : loss : 0.027026, loss_ce: 0.010365\n",
            "iteration 9294 : loss : 0.024573, loss_ce: 0.008598\n",
            "iteration 9295 : loss : 0.022271, loss_ce: 0.010852\n",
            "iteration 9296 : loss : 0.023164, loss_ce: 0.007382\n",
            "iteration 9297 : loss : 0.022632, loss_ce: 0.008109\n",
            "iteration 9298 : loss : 0.026998, loss_ce: 0.008055\n",
            "iteration 9299 : loss : 0.023608, loss_ce: 0.007449\n",
            "iteration 9300 : loss : 0.072387, loss_ce: 0.006321\n",
            "iteration 9301 : loss : 0.027417, loss_ce: 0.009132\n",
            "iteration 9302 : loss : 0.027106, loss_ce: 0.006973\n",
            "iteration 9303 : loss : 0.027909, loss_ce: 0.012190\n",
            "iteration 9304 : loss : 0.024100, loss_ce: 0.007849\n",
            "iteration 9305 : loss : 0.025481, loss_ce: 0.010081\n",
            "iteration 9306 : loss : 0.074903, loss_ce: 0.007095\n",
            "iteration 9307 : loss : 0.026031, loss_ce: 0.011300\n",
            "iteration 9308 : loss : 0.023588, loss_ce: 0.007409\n",
            "iteration 9309 : loss : 0.031055, loss_ce: 0.009256\n",
            "iteration 9310 : loss : 0.048197, loss_ce: 0.010974\n",
            "iteration 9311 : loss : 0.022154, loss_ce: 0.008717\n",
            "iteration 9312 : loss : 0.023336, loss_ce: 0.007840\n",
            "iteration 9313 : loss : 0.029351, loss_ce: 0.010769\n",
            "iteration 9314 : loss : 0.075930, loss_ce: 0.006291\n",
            "iteration 9315 : loss : 0.078283, loss_ce: 0.008061\n",
            "iteration 9316 : loss : 0.023736, loss_ce: 0.006435\n",
            "iteration 9317 : loss : 0.026981, loss_ce: 0.009264\n",
            "iteration 9318 : loss : 0.020467, loss_ce: 0.005281\n",
            "iteration 9319 : loss : 0.026188, loss_ce: 0.006696\n",
            "iteration 9320 : loss : 0.028304, loss_ce: 0.011095\n",
            "iteration 9321 : loss : 0.023977, loss_ce: 0.008150\n",
            "iteration 9322 : loss : 0.042351, loss_ce: 0.007932\n",
            "iteration 9323 : loss : 0.073974, loss_ce: 0.006932\n",
            "iteration 9324 : loss : 0.026087, loss_ce: 0.009760\n",
            " 84%|███████████████████████▌    | 126/150 [3:47:31<43:14, 108.11s/it]iteration 9325 : loss : 0.029752, loss_ce: 0.007913\n",
            "iteration 9326 : loss : 0.021158, loss_ce: 0.008260\n",
            "iteration 9327 : loss : 0.035802, loss_ce: 0.008903\n",
            "iteration 9328 : loss : 0.072419, loss_ce: 0.005009\n",
            "iteration 9329 : loss : 0.026335, loss_ce: 0.008190\n",
            "iteration 9330 : loss : 0.080555, loss_ce: 0.008278\n",
            "iteration 9331 : loss : 0.023446, loss_ce: 0.006184\n",
            "iteration 9332 : loss : 0.021947, loss_ce: 0.004199\n",
            "iteration 9333 : loss : 0.019351, loss_ce: 0.007313\n",
            "iteration 9334 : loss : 0.028156, loss_ce: 0.012724\n",
            "iteration 9335 : loss : 0.023944, loss_ce: 0.008222\n",
            "iteration 9336 : loss : 0.023920, loss_ce: 0.011159\n",
            "iteration 9337 : loss : 0.023337, loss_ce: 0.008637\n",
            "iteration 9338 : loss : 0.023495, loss_ce: 0.010878\n",
            "iteration 9339 : loss : 0.028145, loss_ce: 0.004505\n",
            "iteration 9340 : loss : 0.023334, loss_ce: 0.009148\n",
            "iteration 9341 : loss : 0.026857, loss_ce: 0.010969\n",
            "iteration 9342 : loss : 0.073140, loss_ce: 0.004832\n",
            "iteration 9343 : loss : 0.027481, loss_ce: 0.010590\n",
            "iteration 9344 : loss : 0.021501, loss_ce: 0.007025\n",
            "iteration 9345 : loss : 0.027282, loss_ce: 0.004844\n",
            "iteration 9346 : loss : 0.021790, loss_ce: 0.007295\n",
            "iteration 9347 : loss : 0.026135, loss_ce: 0.006739\n",
            "iteration 9348 : loss : 0.023446, loss_ce: 0.009187\n",
            "iteration 9349 : loss : 0.029011, loss_ce: 0.005586\n",
            "iteration 9350 : loss : 0.028245, loss_ce: 0.012545\n",
            "iteration 9351 : loss : 0.026635, loss_ce: 0.007715\n",
            "iteration 9352 : loss : 0.028141, loss_ce: 0.009817\n",
            "iteration 9353 : loss : 0.036848, loss_ce: 0.005053\n",
            "iteration 9354 : loss : 0.023747, loss_ce: 0.007111\n",
            "iteration 9355 : loss : 0.024107, loss_ce: 0.009043\n",
            "iteration 9356 : loss : 0.026222, loss_ce: 0.005211\n",
            "iteration 9357 : loss : 0.027503, loss_ce: 0.009542\n",
            "iteration 9358 : loss : 0.026367, loss_ce: 0.009534\n",
            "iteration 9359 : loss : 0.026187, loss_ce: 0.010489\n",
            "iteration 9360 : loss : 0.023596, loss_ce: 0.007895\n",
            "iteration 9361 : loss : 0.025905, loss_ce: 0.009314\n",
            "iteration 9362 : loss : 0.022214, loss_ce: 0.006344\n",
            "iteration 9363 : loss : 0.025616, loss_ce: 0.008412\n",
            "iteration 9364 : loss : 0.024238, loss_ce: 0.006456\n",
            "iteration 9365 : loss : 0.025470, loss_ce: 0.011019\n",
            "iteration 9366 : loss : 0.033239, loss_ce: 0.009645\n",
            "iteration 9367 : loss : 0.024082, loss_ce: 0.010528\n",
            "iteration 9368 : loss : 0.027560, loss_ce: 0.011286\n",
            "iteration 9369 : loss : 0.024385, loss_ce: 0.008737\n",
            "iteration 9370 : loss : 0.027209, loss_ce: 0.012592\n",
            "iteration 9371 : loss : 0.075959, loss_ce: 0.007015\n",
            "iteration 9372 : loss : 0.023607, loss_ce: 0.011638\n",
            "iteration 9373 : loss : 0.035053, loss_ce: 0.007966\n",
            "iteration 9374 : loss : 0.072865, loss_ce: 0.003667\n",
            "iteration 9375 : loss : 0.021415, loss_ce: 0.005220\n",
            "iteration 9376 : loss : 0.036542, loss_ce: 0.008524\n",
            "iteration 9377 : loss : 0.026636, loss_ce: 0.012307\n",
            "iteration 9378 : loss : 0.026772, loss_ce: 0.010206\n",
            "iteration 9379 : loss : 0.023306, loss_ce: 0.008965\n",
            "iteration 9380 : loss : 0.022726, loss_ce: 0.007715\n",
            "iteration 9381 : loss : 0.027319, loss_ce: 0.009901\n",
            "iteration 9382 : loss : 0.026185, loss_ce: 0.008795\n",
            "iteration 9383 : loss : 0.024058, loss_ce: 0.006870\n",
            "iteration 9384 : loss : 0.026503, loss_ce: 0.009747\n",
            "iteration 9385 : loss : 0.022957, loss_ce: 0.006122\n",
            "iteration 9386 : loss : 0.022098, loss_ce: 0.010443\n",
            "iteration 9387 : loss : 0.023705, loss_ce: 0.008920\n",
            "iteration 9388 : loss : 0.025492, loss_ce: 0.013188\n",
            "iteration 9389 : loss : 0.026689, loss_ce: 0.009581\n",
            "iteration 9390 : loss : 0.029841, loss_ce: 0.012124\n",
            "iteration 9391 : loss : 0.044024, loss_ce: 0.009282\n",
            "iteration 9392 : loss : 0.025623, loss_ce: 0.011143\n",
            "iteration 9393 : loss : 0.029093, loss_ce: 0.009033\n",
            "iteration 9394 : loss : 0.026139, loss_ce: 0.004446\n",
            "iteration 9395 : loss : 0.022752, loss_ce: 0.004846\n",
            "iteration 9396 : loss : 0.022619, loss_ce: 0.008226\n",
            "iteration 9397 : loss : 0.027619, loss_ce: 0.010581\n",
            "iteration 9398 : loss : 0.028759, loss_ce: 0.008004\n",
            " 85%|███████████████████████▋    | 127/150 [3:49:20<41:28, 108.21s/it]iteration 9399 : loss : 0.022960, loss_ce: 0.008017\n",
            "iteration 9400 : loss : 0.025820, loss_ce: 0.010789\n",
            "iteration 9401 : loss : 0.027494, loss_ce: 0.010504\n",
            "iteration 9402 : loss : 0.022934, loss_ce: 0.008265\n",
            "iteration 9403 : loss : 0.029334, loss_ce: 0.009641\n",
            "iteration 9404 : loss : 0.025316, loss_ce: 0.007218\n",
            "iteration 9405 : loss : 0.024004, loss_ce: 0.006272\n",
            "iteration 9406 : loss : 0.026101, loss_ce: 0.010707\n",
            "iteration 9407 : loss : 0.073854, loss_ce: 0.006399\n",
            "iteration 9408 : loss : 0.026112, loss_ce: 0.011954\n",
            "iteration 9409 : loss : 0.025235, loss_ce: 0.011544\n",
            "iteration 9410 : loss : 0.025929, loss_ce: 0.010910\n",
            "iteration 9411 : loss : 0.030779, loss_ce: 0.006130\n",
            "iteration 9412 : loss : 0.026584, loss_ce: 0.004927\n",
            "iteration 9413 : loss : 0.021373, loss_ce: 0.010248\n",
            "iteration 9414 : loss : 0.022784, loss_ce: 0.008278\n",
            "iteration 9415 : loss : 0.023699, loss_ce: 0.006578\n",
            "iteration 9416 : loss : 0.025971, loss_ce: 0.012291\n",
            "iteration 9417 : loss : 0.034322, loss_ce: 0.010670\n",
            "iteration 9418 : loss : 0.025633, loss_ce: 0.006110\n",
            "iteration 9419 : loss : 0.024678, loss_ce: 0.009394\n",
            "iteration 9420 : loss : 0.026935, loss_ce: 0.006173\n",
            "iteration 9421 : loss : 0.028849, loss_ce: 0.013676\n",
            "iteration 9422 : loss : 0.019513, loss_ce: 0.006625\n",
            "iteration 9423 : loss : 0.028164, loss_ce: 0.004408\n",
            "iteration 9424 : loss : 0.027278, loss_ce: 0.006563\n",
            "iteration 9425 : loss : 0.026306, loss_ce: 0.011014\n",
            "iteration 9426 : loss : 0.026185, loss_ce: 0.008273\n",
            "iteration 9427 : loss : 0.075366, loss_ce: 0.005427\n",
            "iteration 9428 : loss : 0.024926, loss_ce: 0.009444\n",
            "iteration 9429 : loss : 0.023978, loss_ce: 0.007309\n",
            "iteration 9430 : loss : 0.024297, loss_ce: 0.007346\n",
            "iteration 9431 : loss : 0.022158, loss_ce: 0.009044\n",
            "iteration 9432 : loss : 0.023460, loss_ce: 0.006890\n",
            "iteration 9433 : loss : 0.077681, loss_ce: 0.005042\n",
            "iteration 9434 : loss : 0.024468, loss_ce: 0.010464\n",
            "iteration 9435 : loss : 0.026269, loss_ce: 0.009976\n",
            "iteration 9436 : loss : 0.024190, loss_ce: 0.008292\n",
            "iteration 9437 : loss : 0.027272, loss_ce: 0.008692\n",
            "iteration 9438 : loss : 0.023770, loss_ce: 0.008028\n",
            "iteration 9439 : loss : 0.024518, loss_ce: 0.008899\n",
            "iteration 9440 : loss : 0.027961, loss_ce: 0.009678\n",
            "iteration 9441 : loss : 0.021527, loss_ce: 0.005749\n",
            "iteration 9442 : loss : 0.023690, loss_ce: 0.007060\n",
            "iteration 9443 : loss : 0.022474, loss_ce: 0.006674\n",
            "iteration 9444 : loss : 0.024027, loss_ce: 0.011129\n",
            "iteration 9445 : loss : 0.023692, loss_ce: 0.011095\n",
            "iteration 9446 : loss : 0.024458, loss_ce: 0.007178\n",
            "iteration 9447 : loss : 0.028643, loss_ce: 0.013876\n",
            "iteration 9448 : loss : 0.020674, loss_ce: 0.006121\n",
            "iteration 9449 : loss : 0.022416, loss_ce: 0.007734\n",
            "iteration 9450 : loss : 0.027556, loss_ce: 0.005331\n",
            "iteration 9451 : loss : 0.021704, loss_ce: 0.007237\n",
            "iteration 9452 : loss : 0.024068, loss_ce: 0.006980\n",
            "iteration 9453 : loss : 0.025085, loss_ce: 0.007263\n",
            "iteration 9454 : loss : 0.023163, loss_ce: 0.005706\n",
            "iteration 9455 : loss : 0.026769, loss_ce: 0.009496\n",
            "iteration 9456 : loss : 0.074348, loss_ce: 0.008267\n",
            "iteration 9457 : loss : 0.027088, loss_ce: 0.010805\n",
            "iteration 9458 : loss : 0.023945, loss_ce: 0.011025\n",
            "iteration 9459 : loss : 0.030375, loss_ce: 0.012114\n",
            "iteration 9460 : loss : 0.027432, loss_ce: 0.007878\n",
            "iteration 9461 : loss : 0.035955, loss_ce: 0.006980\n",
            "iteration 9462 : loss : 0.023369, loss_ce: 0.006406\n",
            "iteration 9463 : loss : 0.027278, loss_ce: 0.010971\n",
            "iteration 9464 : loss : 0.075265, loss_ce: 0.006398\n",
            "iteration 9465 : loss : 0.093247, loss_ce: 0.005938\n",
            "iteration 9466 : loss : 0.032008, loss_ce: 0.008479\n",
            "iteration 9467 : loss : 0.024498, loss_ce: 0.012755\n",
            "iteration 9468 : loss : 0.026168, loss_ce: 0.012968\n",
            "iteration 9469 : loss : 0.027347, loss_ce: 0.009378\n",
            "iteration 9470 : loss : 0.026710, loss_ce: 0.006431\n",
            "iteration 9471 : loss : 0.026459, loss_ce: 0.009585\n",
            "iteration 9472 : loss : 0.074806, loss_ce: 0.007656\n",
            " 85%|███████████████████████▉    | 128/150 [3:51:08<39:40, 108.19s/it]iteration 9473 : loss : 0.045857, loss_ce: 0.002052\n",
            "iteration 9474 : loss : 0.027307, loss_ce: 0.012158\n",
            "iteration 9475 : loss : 0.023486, loss_ce: 0.005010\n",
            "iteration 9476 : loss : 0.031370, loss_ce: 0.006698\n",
            "iteration 9477 : loss : 0.025459, loss_ce: 0.007966\n",
            "iteration 9478 : loss : 0.032849, loss_ce: 0.006437\n",
            "iteration 9479 : loss : 0.024247, loss_ce: 0.008701\n",
            "iteration 9480 : loss : 0.024137, loss_ce: 0.010877\n",
            "iteration 9481 : loss : 0.025178, loss_ce: 0.012289\n",
            "iteration 9482 : loss : 0.019524, loss_ce: 0.008112\n",
            "iteration 9483 : loss : 0.027293, loss_ce: 0.007155\n",
            "iteration 9484 : loss : 0.074557, loss_ce: 0.007922\n",
            "iteration 9485 : loss : 0.028453, loss_ce: 0.010422\n",
            "iteration 9486 : loss : 0.072009, loss_ce: 0.006067\n",
            "iteration 9487 : loss : 0.022383, loss_ce: 0.007070\n",
            "iteration 9488 : loss : 0.024280, loss_ce: 0.006401\n",
            "iteration 9489 : loss : 0.024094, loss_ce: 0.008834\n",
            "iteration 9490 : loss : 0.026156, loss_ce: 0.011992\n",
            "iteration 9491 : loss : 0.028064, loss_ce: 0.006828\n",
            "iteration 9492 : loss : 0.022642, loss_ce: 0.007954\n",
            "iteration 9493 : loss : 0.025175, loss_ce: 0.006988\n",
            "iteration 9494 : loss : 0.026816, loss_ce: 0.009635\n",
            "iteration 9495 : loss : 0.074995, loss_ce: 0.008322\n",
            "iteration 9496 : loss : 0.025616, loss_ce: 0.008705\n",
            "iteration 9497 : loss : 0.029751, loss_ce: 0.012988\n",
            "iteration 9498 : loss : 0.024518, loss_ce: 0.007303\n",
            "iteration 9499 : loss : 0.045385, loss_ce: 0.007463\n",
            "iteration 9500 : loss : 0.076515, loss_ce: 0.006071\n",
            "iteration 9501 : loss : 0.023303, loss_ce: 0.008179\n",
            "iteration 9502 : loss : 0.023690, loss_ce: 0.007827\n",
            "iteration 9503 : loss : 0.029305, loss_ce: 0.011315\n",
            "iteration 9504 : loss : 0.021532, loss_ce: 0.007011\n",
            "iteration 9505 : loss : 0.027025, loss_ce: 0.013541\n",
            "iteration 9506 : loss : 0.023297, loss_ce: 0.008668\n",
            "iteration 9507 : loss : 0.026310, loss_ce: 0.012339\n",
            "iteration 9508 : loss : 0.024305, loss_ce: 0.010265\n",
            "iteration 9509 : loss : 0.025598, loss_ce: 0.010796\n",
            "iteration 9510 : loss : 0.026187, loss_ce: 0.010968\n",
            "iteration 9511 : loss : 0.029611, loss_ce: 0.007897\n",
            "iteration 9512 : loss : 0.026689, loss_ce: 0.010821\n",
            "iteration 9513 : loss : 0.031809, loss_ce: 0.008691\n",
            "iteration 9514 : loss : 0.074013, loss_ce: 0.004221\n",
            "iteration 9515 : loss : 0.024920, loss_ce: 0.008920\n",
            "iteration 9516 : loss : 0.036633, loss_ce: 0.007997\n",
            "iteration 9517 : loss : 0.026190, loss_ce: 0.007694\n",
            "iteration 9518 : loss : 0.024310, loss_ce: 0.008631\n",
            "iteration 9519 : loss : 0.025962, loss_ce: 0.009591\n",
            "iteration 9520 : loss : 0.024475, loss_ce: 0.012915\n",
            "iteration 9521 : loss : 0.025349, loss_ce: 0.010417\n",
            "iteration 9522 : loss : 0.021740, loss_ce: 0.006397\n",
            "iteration 9523 : loss : 0.020299, loss_ce: 0.006436\n",
            "iteration 9524 : loss : 0.025634, loss_ce: 0.010982\n",
            "iteration 9525 : loss : 0.078563, loss_ce: 0.013568\n",
            "iteration 9526 : loss : 0.021283, loss_ce: 0.007338\n",
            "iteration 9527 : loss : 0.026920, loss_ce: 0.010234\n",
            "iteration 9528 : loss : 0.030242, loss_ce: 0.006800\n",
            "iteration 9529 : loss : 0.023720, loss_ce: 0.008698\n",
            "iteration 9530 : loss : 0.022888, loss_ce: 0.004790\n",
            "iteration 9531 : loss : 0.032572, loss_ce: 0.006794\n",
            "iteration 9532 : loss : 0.028476, loss_ce: 0.007183\n",
            "iteration 9533 : loss : 0.028222, loss_ce: 0.008984\n",
            "iteration 9534 : loss : 0.026363, loss_ce: 0.008761\n",
            "iteration 9535 : loss : 0.077961, loss_ce: 0.009417\n",
            "iteration 9536 : loss : 0.023866, loss_ce: 0.011573\n",
            "iteration 9537 : loss : 0.028257, loss_ce: 0.011219\n",
            "iteration 9538 : loss : 0.023281, loss_ce: 0.008867\n",
            "iteration 9539 : loss : 0.029794, loss_ce: 0.013186\n",
            "iteration 9540 : loss : 0.074359, loss_ce: 0.005233\n",
            "iteration 9541 : loss : 0.020655, loss_ce: 0.003139\n",
            "iteration 9542 : loss : 0.023676, loss_ce: 0.009097\n",
            "iteration 9543 : loss : 0.026864, loss_ce: 0.007891\n",
            "iteration 9544 : loss : 0.024770, loss_ce: 0.005807\n",
            "iteration 9545 : loss : 0.024907, loss_ce: 0.007435\n",
            "iteration 9546 : loss : 0.023117, loss_ce: 0.008185\n",
            " 86%|████████████████████████    | 129/150 [3:52:56<37:49, 108.09s/it]iteration 9547 : loss : 0.074309, loss_ce: 0.005837\n",
            "iteration 9548 : loss : 0.026841, loss_ce: 0.006393\n",
            "iteration 9549 : loss : 0.028905, loss_ce: 0.009468\n",
            "iteration 9550 : loss : 0.029239, loss_ce: 0.014534\n",
            "iteration 9551 : loss : 0.022771, loss_ce: 0.007247\n",
            "iteration 9552 : loss : 0.023301, loss_ce: 0.007440\n",
            "iteration 9553 : loss : 0.024209, loss_ce: 0.010784\n",
            "iteration 9554 : loss : 0.022655, loss_ce: 0.009707\n",
            "iteration 9555 : loss : 0.019665, loss_ce: 0.005639\n",
            "iteration 9556 : loss : 0.021165, loss_ce: 0.006800\n",
            "iteration 9557 : loss : 0.026815, loss_ce: 0.011018\n",
            "iteration 9558 : loss : 0.029118, loss_ce: 0.009805\n",
            "iteration 9559 : loss : 0.029071, loss_ce: 0.007445\n",
            "iteration 9560 : loss : 0.025211, loss_ce: 0.007714\n",
            "iteration 9561 : loss : 0.021366, loss_ce: 0.006052\n",
            "iteration 9562 : loss : 0.025197, loss_ce: 0.008779\n",
            "iteration 9563 : loss : 0.020563, loss_ce: 0.007618\n",
            "iteration 9564 : loss : 0.026813, loss_ce: 0.007590\n",
            "iteration 9565 : loss : 0.086737, loss_ce: 0.009363\n",
            "iteration 9566 : loss : 0.027155, loss_ce: 0.008412\n",
            "iteration 9567 : loss : 0.023851, loss_ce: 0.009958\n",
            "iteration 9568 : loss : 0.023623, loss_ce: 0.006796\n",
            "iteration 9569 : loss : 0.028388, loss_ce: 0.008513\n",
            "iteration 9570 : loss : 0.023809, loss_ce: 0.008032\n",
            "iteration 9571 : loss : 0.022245, loss_ce: 0.007013\n",
            "iteration 9572 : loss : 0.022352, loss_ce: 0.008910\n",
            "iteration 9573 : loss : 0.075907, loss_ce: 0.005889\n",
            "iteration 9574 : loss : 0.022318, loss_ce: 0.009954\n",
            "iteration 9575 : loss : 0.026965, loss_ce: 0.012737\n",
            "iteration 9576 : loss : 0.021814, loss_ce: 0.007268\n",
            "iteration 9577 : loss : 0.025126, loss_ce: 0.007986\n",
            "iteration 9578 : loss : 0.026000, loss_ce: 0.010360\n",
            "iteration 9579 : loss : 0.026180, loss_ce: 0.007551\n",
            "iteration 9580 : loss : 0.024517, loss_ce: 0.011175\n",
            "iteration 9581 : loss : 0.029060, loss_ce: 0.010718\n",
            "iteration 9582 : loss : 0.022846, loss_ce: 0.007495\n",
            "iteration 9583 : loss : 0.028026, loss_ce: 0.010114\n",
            "iteration 9584 : loss : 0.026714, loss_ce: 0.007062\n",
            "iteration 9585 : loss : 0.026148, loss_ce: 0.006006\n",
            "iteration 9586 : loss : 0.033858, loss_ce: 0.008035\n",
            "iteration 9587 : loss : 0.029408, loss_ce: 0.006687\n",
            "iteration 9588 : loss : 0.029307, loss_ce: 0.007059\n",
            "iteration 9589 : loss : 0.024050, loss_ce: 0.006180\n",
            "iteration 9590 : loss : 0.074364, loss_ce: 0.005879\n",
            "iteration 9591 : loss : 0.024124, loss_ce: 0.009429\n",
            "iteration 9592 : loss : 0.024490, loss_ce: 0.007988\n",
            "iteration 9593 : loss : 0.020647, loss_ce: 0.007458\n",
            "iteration 9594 : loss : 0.027194, loss_ce: 0.009398\n",
            "iteration 9595 : loss : 0.025631, loss_ce: 0.010443\n",
            "iteration 9596 : loss : 0.026495, loss_ce: 0.014195\n",
            "iteration 9597 : loss : 0.027721, loss_ce: 0.010777\n",
            "iteration 9598 : loss : 0.028674, loss_ce: 0.013610\n",
            "iteration 9599 : loss : 0.019442, loss_ce: 0.004576\n",
            "iteration 9600 : loss : 0.022841, loss_ce: 0.007817\n",
            "iteration 9601 : loss : 0.042103, loss_ce: 0.008377\n",
            "iteration 9602 : loss : 0.026140, loss_ce: 0.012109\n",
            "iteration 9603 : loss : 0.026024, loss_ce: 0.006482\n",
            "iteration 9604 : loss : 0.024585, loss_ce: 0.009473\n",
            "iteration 9605 : loss : 0.026342, loss_ce: 0.011603\n",
            "iteration 9606 : loss : 0.026389, loss_ce: 0.010372\n",
            "iteration 9607 : loss : 0.027590, loss_ce: 0.008663\n",
            "iteration 9608 : loss : 0.021881, loss_ce: 0.006798\n",
            "iteration 9609 : loss : 0.025729, loss_ce: 0.010332\n",
            "iteration 9610 : loss : 0.026063, loss_ce: 0.007445\n",
            "iteration 9611 : loss : 0.027913, loss_ce: 0.006774\n",
            "iteration 9612 : loss : 0.073091, loss_ce: 0.005479\n",
            "iteration 9613 : loss : 0.024583, loss_ce: 0.010724\n",
            "iteration 9614 : loss : 0.039828, loss_ce: 0.009338\n",
            "iteration 9615 : loss : 0.025137, loss_ce: 0.007695\n",
            "iteration 9616 : loss : 0.072470, loss_ce: 0.005318\n",
            "iteration 9617 : loss : 0.024862, loss_ce: 0.012581\n",
            "iteration 9618 : loss : 0.075795, loss_ce: 0.006517\n",
            "iteration 9619 : loss : 0.023839, loss_ce: 0.006777\n",
            "iteration 9620 : loss : 0.024709, loss_ce: 0.008070\n",
            " 87%|████████████████████████▎   | 130/150 [3:54:44<36:06, 108.33s/it]iteration 9621 : loss : 0.024259, loss_ce: 0.008923\n",
            "iteration 9622 : loss : 0.026908, loss_ce: 0.013412\n",
            "iteration 9623 : loss : 0.026275, loss_ce: 0.009590\n",
            "iteration 9624 : loss : 0.024244, loss_ce: 0.010049\n",
            "iteration 9625 : loss : 0.026635, loss_ce: 0.010342\n",
            "iteration 9626 : loss : 0.025647, loss_ce: 0.007848\n",
            "iteration 9627 : loss : 0.024131, loss_ce: 0.008051\n",
            "iteration 9628 : loss : 0.020312, loss_ce: 0.005480\n",
            "iteration 9629 : loss : 0.025387, loss_ce: 0.009890\n",
            "iteration 9630 : loss : 0.023452, loss_ce: 0.007732\n",
            "iteration 9631 : loss : 0.022298, loss_ce: 0.007667\n",
            "iteration 9632 : loss : 0.026917, loss_ce: 0.009504\n",
            "iteration 9633 : loss : 0.019619, loss_ce: 0.006940\n",
            "iteration 9634 : loss : 0.023504, loss_ce: 0.009070\n",
            "iteration 9635 : loss : 0.025243, loss_ce: 0.008125\n",
            "iteration 9636 : loss : 0.023464, loss_ce: 0.011547\n",
            "iteration 9637 : loss : 0.023007, loss_ce: 0.009512\n",
            "iteration 9638 : loss : 0.025304, loss_ce: 0.008112\n",
            "iteration 9639 : loss : 0.026893, loss_ce: 0.007879\n",
            "iteration 9640 : loss : 0.022944, loss_ce: 0.008502\n",
            "iteration 9641 : loss : 0.025462, loss_ce: 0.008489\n",
            "iteration 9642 : loss : 0.024184, loss_ce: 0.008826\n",
            "iteration 9643 : loss : 0.075089, loss_ce: 0.006808\n",
            "iteration 9644 : loss : 0.021944, loss_ce: 0.008230\n",
            "iteration 9645 : loss : 0.031794, loss_ce: 0.006625\n",
            "iteration 9646 : loss : 0.024731, loss_ce: 0.010602\n",
            "iteration 9647 : loss : 0.026675, loss_ce: 0.009771\n",
            "iteration 9648 : loss : 0.025765, loss_ce: 0.006586\n",
            "iteration 9649 : loss : 0.026235, loss_ce: 0.010340\n",
            "iteration 9650 : loss : 0.022647, loss_ce: 0.007053\n",
            "iteration 9651 : loss : 0.022801, loss_ce: 0.007017\n",
            "iteration 9652 : loss : 0.022673, loss_ce: 0.009546\n",
            "iteration 9653 : loss : 0.087635, loss_ce: 0.006863\n",
            "iteration 9654 : loss : 0.020234, loss_ce: 0.003628\n",
            "iteration 9655 : loss : 0.023965, loss_ce: 0.004676\n",
            "iteration 9656 : loss : 0.030168, loss_ce: 0.009590\n",
            "iteration 9657 : loss : 0.022194, loss_ce: 0.009422\n",
            "iteration 9658 : loss : 0.019846, loss_ce: 0.005873\n",
            "iteration 9659 : loss : 0.030339, loss_ce: 0.009415\n",
            "iteration 9660 : loss : 0.075362, loss_ce: 0.006088\n",
            "iteration 9661 : loss : 0.022092, loss_ce: 0.005594\n",
            "iteration 9662 : loss : 0.027078, loss_ce: 0.010372\n",
            "iteration 9663 : loss : 0.027286, loss_ce: 0.009900\n",
            "iteration 9664 : loss : 0.029314, loss_ce: 0.010138\n",
            "iteration 9665 : loss : 0.023024, loss_ce: 0.008336\n",
            "iteration 9666 : loss : 0.020428, loss_ce: 0.006416\n",
            "iteration 9667 : loss : 0.022575, loss_ce: 0.007471\n",
            "iteration 9668 : loss : 0.025949, loss_ce: 0.012039\n",
            "iteration 9669 : loss : 0.023376, loss_ce: 0.010862\n",
            "iteration 9670 : loss : 0.025530, loss_ce: 0.008637\n",
            "iteration 9671 : loss : 0.020722, loss_ce: 0.005618\n",
            "iteration 9672 : loss : 0.030023, loss_ce: 0.009293\n",
            "iteration 9673 : loss : 0.029212, loss_ce: 0.008706\n",
            "iteration 9674 : loss : 0.024475, loss_ce: 0.010133\n",
            "iteration 9675 : loss : 0.022349, loss_ce: 0.007857\n",
            "iteration 9676 : loss : 0.019847, loss_ce: 0.006535\n",
            "iteration 9677 : loss : 0.020057, loss_ce: 0.006309\n",
            "iteration 9678 : loss : 0.024383, loss_ce: 0.011868\n",
            "iteration 9679 : loss : 0.022526, loss_ce: 0.007085\n",
            "iteration 9680 : loss : 0.023246, loss_ce: 0.006564\n",
            "iteration 9681 : loss : 0.025656, loss_ce: 0.006849\n",
            "iteration 9682 : loss : 0.022548, loss_ce: 0.004389\n",
            "iteration 9683 : loss : 0.027113, loss_ce: 0.003369\n",
            "iteration 9684 : loss : 0.028157, loss_ce: 0.008476\n",
            "iteration 9685 : loss : 0.029008, loss_ce: 0.013374\n",
            "iteration 9686 : loss : 0.028237, loss_ce: 0.014866\n",
            "iteration 9687 : loss : 0.024739, loss_ce: 0.010272\n",
            "iteration 9688 : loss : 0.023803, loss_ce: 0.007118\n",
            "iteration 9689 : loss : 0.027396, loss_ce: 0.007544\n",
            "iteration 9690 : loss : 0.026301, loss_ce: 0.005660\n",
            "iteration 9691 : loss : 0.024422, loss_ce: 0.008473\n",
            "iteration 9692 : loss : 0.021982, loss_ce: 0.008628\n",
            "iteration 9693 : loss : 0.031529, loss_ce: 0.012544\n",
            "iteration 9694 : loss : 0.024307, loss_ce: 0.007671\n",
            " 87%|████████████████████████▍   | 131/150 [3:56:34<34:23, 108.60s/it]iteration 9695 : loss : 0.023984, loss_ce: 0.006392\n",
            "iteration 9696 : loss : 0.026290, loss_ce: 0.012005\n",
            "iteration 9697 : loss : 0.026487, loss_ce: 0.007762\n",
            "iteration 9698 : loss : 0.023597, loss_ce: 0.008825\n",
            "iteration 9699 : loss : 0.026793, loss_ce: 0.008211\n",
            "iteration 9700 : loss : 0.022005, loss_ce: 0.007415\n",
            "iteration 9701 : loss : 0.023762, loss_ce: 0.007906\n",
            "iteration 9702 : loss : 0.079975, loss_ce: 0.002922\n",
            "iteration 9703 : loss : 0.019931, loss_ce: 0.006906\n",
            "iteration 9704 : loss : 0.024339, loss_ce: 0.007980\n",
            "iteration 9705 : loss : 0.021828, loss_ce: 0.007592\n",
            "iteration 9706 : loss : 0.028729, loss_ce: 0.004359\n",
            "iteration 9707 : loss : 0.023362, loss_ce: 0.010410\n",
            "iteration 9708 : loss : 0.024710, loss_ce: 0.007604\n",
            "iteration 9709 : loss : 0.021740, loss_ce: 0.004460\n",
            "iteration 9710 : loss : 0.022193, loss_ce: 0.007598\n",
            "iteration 9711 : loss : 0.025001, loss_ce: 0.008220\n",
            "iteration 9712 : loss : 0.075989, loss_ce: 0.005052\n",
            "iteration 9713 : loss : 0.023516, loss_ce: 0.007900\n",
            "iteration 9714 : loss : 0.077245, loss_ce: 0.007193\n",
            "iteration 9715 : loss : 0.076159, loss_ce: 0.007334\n",
            "iteration 9716 : loss : 0.025993, loss_ce: 0.005386\n",
            "iteration 9717 : loss : 0.023044, loss_ce: 0.005952\n",
            "iteration 9718 : loss : 0.027494, loss_ce: 0.013763\n",
            "iteration 9719 : loss : 0.025809, loss_ce: 0.009994\n",
            "iteration 9720 : loss : 0.024186, loss_ce: 0.009683\n",
            "iteration 9721 : loss : 0.019322, loss_ce: 0.006051\n",
            "iteration 9722 : loss : 0.024659, loss_ce: 0.005955\n",
            "iteration 9723 : loss : 0.022093, loss_ce: 0.007170\n",
            "iteration 9724 : loss : 0.026607, loss_ce: 0.006188\n",
            "iteration 9725 : loss : 0.060626, loss_ce: 0.006856\n",
            "iteration 9726 : loss : 0.024880, loss_ce: 0.008151\n",
            "iteration 9727 : loss : 0.026269, loss_ce: 0.009640\n",
            "iteration 9728 : loss : 0.026941, loss_ce: 0.008746\n",
            "iteration 9729 : loss : 0.026943, loss_ce: 0.006839\n",
            "iteration 9730 : loss : 0.029174, loss_ce: 0.011018\n",
            "iteration 9731 : loss : 0.026468, loss_ce: 0.011045\n",
            "iteration 9732 : loss : 0.021262, loss_ce: 0.005923\n",
            "iteration 9733 : loss : 0.027307, loss_ce: 0.010599\n",
            "iteration 9734 : loss : 0.028251, loss_ce: 0.011922\n",
            "iteration 9735 : loss : 0.029848, loss_ce: 0.009368\n",
            "iteration 9736 : loss : 0.026926, loss_ce: 0.013424\n",
            "iteration 9737 : loss : 0.027802, loss_ce: 0.010870\n",
            "iteration 9738 : loss : 0.024207, loss_ce: 0.009641\n",
            "iteration 9739 : loss : 0.022306, loss_ce: 0.007091\n",
            "iteration 9740 : loss : 0.026278, loss_ce: 0.007442\n",
            "iteration 9741 : loss : 0.023748, loss_ce: 0.010037\n",
            "iteration 9742 : loss : 0.022255, loss_ce: 0.007392\n",
            "iteration 9743 : loss : 0.029178, loss_ce: 0.013555\n",
            "iteration 9744 : loss : 0.020390, loss_ce: 0.005845\n",
            "iteration 9745 : loss : 0.028529, loss_ce: 0.014838\n",
            "iteration 9746 : loss : 0.022723, loss_ce: 0.007533\n",
            "iteration 9747 : loss : 0.030819, loss_ce: 0.007070\n",
            "iteration 9748 : loss : 0.025271, loss_ce: 0.009584\n",
            "iteration 9749 : loss : 0.032947, loss_ce: 0.011121\n",
            "iteration 9750 : loss : 0.027649, loss_ce: 0.008943\n",
            "iteration 9751 : loss : 0.023286, loss_ce: 0.010799\n",
            "iteration 9752 : loss : 0.023153, loss_ce: 0.008590\n",
            "iteration 9753 : loss : 0.027991, loss_ce: 0.012222\n",
            "iteration 9754 : loss : 0.078808, loss_ce: 0.007578\n",
            "iteration 9755 : loss : 0.027486, loss_ce: 0.009635\n",
            "iteration 9756 : loss : 0.024788, loss_ce: 0.011819\n",
            "iteration 9757 : loss : 0.031346, loss_ce: 0.008297\n",
            "iteration 9758 : loss : 0.022524, loss_ce: 0.006691\n",
            "iteration 9759 : loss : 0.027507, loss_ce: 0.010882\n",
            "iteration 9760 : loss : 0.024102, loss_ce: 0.011255\n",
            "iteration 9761 : loss : 0.026725, loss_ce: 0.009515\n",
            "iteration 9762 : loss : 0.029708, loss_ce: 0.011974\n",
            "iteration 9763 : loss : 0.033879, loss_ce: 0.004494\n",
            "iteration 9764 : loss : 0.025230, loss_ce: 0.009796\n",
            "iteration 9765 : loss : 0.028754, loss_ce: 0.010911\n",
            "iteration 9766 : loss : 0.021569, loss_ce: 0.008224\n",
            "iteration 9767 : loss : 0.029329, loss_ce: 0.005063\n",
            "iteration 9768 : loss : 0.024799, loss_ce: 0.013064\n",
            " 88%|████████████████████████▋   | 132/150 [3:58:22<32:31, 108.44s/it]iteration 9769 : loss : 0.029216, loss_ce: 0.009617\n",
            "iteration 9770 : loss : 0.023344, loss_ce: 0.007222\n",
            "iteration 9771 : loss : 0.028330, loss_ce: 0.014434\n",
            "iteration 9772 : loss : 0.022323, loss_ce: 0.009430\n",
            "iteration 9773 : loss : 0.025828, loss_ce: 0.011637\n",
            "iteration 9774 : loss : 0.077524, loss_ce: 0.007366\n",
            "iteration 9775 : loss : 0.021426, loss_ce: 0.009955\n",
            "iteration 9776 : loss : 0.029201, loss_ce: 0.012910\n",
            "iteration 9777 : loss : 0.024587, loss_ce: 0.009589\n",
            "iteration 9778 : loss : 0.025432, loss_ce: 0.010911\n",
            "iteration 9779 : loss : 0.027134, loss_ce: 0.006317\n",
            "iteration 9780 : loss : 0.023674, loss_ce: 0.006816\n",
            "iteration 9781 : loss : 0.028366, loss_ce: 0.009281\n",
            "iteration 9782 : loss : 0.025011, loss_ce: 0.007462\n",
            "iteration 9783 : loss : 0.024427, loss_ce: 0.010728\n",
            "iteration 9784 : loss : 0.024342, loss_ce: 0.010557\n",
            "iteration 9785 : loss : 0.023848, loss_ce: 0.004856\n",
            "iteration 9786 : loss : 0.022796, loss_ce: 0.006109\n",
            "iteration 9787 : loss : 0.024418, loss_ce: 0.010188\n",
            "iteration 9788 : loss : 0.024586, loss_ce: 0.008126\n",
            "iteration 9789 : loss : 0.020831, loss_ce: 0.008442\n",
            "iteration 9790 : loss : 0.078328, loss_ce: 0.008692\n",
            "iteration 9791 : loss : 0.026946, loss_ce: 0.008218\n",
            "iteration 9792 : loss : 0.026992, loss_ce: 0.011258\n",
            "iteration 9793 : loss : 0.031797, loss_ce: 0.007832\n",
            "iteration 9794 : loss : 0.021005, loss_ce: 0.005503\n",
            "iteration 9795 : loss : 0.023159, loss_ce: 0.005322\n",
            "iteration 9796 : loss : 0.024733, loss_ce: 0.006632\n",
            "iteration 9797 : loss : 0.022487, loss_ce: 0.007391\n",
            "iteration 9798 : loss : 0.027608, loss_ce: 0.009725\n",
            "iteration 9799 : loss : 0.033717, loss_ce: 0.009744\n",
            "iteration 9800 : loss : 0.022420, loss_ce: 0.006302\n",
            "iteration 9801 : loss : 0.075905, loss_ce: 0.009546\n",
            "iteration 9802 : loss : 0.023800, loss_ce: 0.003923\n",
            "iteration 9803 : loss : 0.025973, loss_ce: 0.009066\n",
            "iteration 9804 : loss : 0.020383, loss_ce: 0.004955\n",
            "iteration 9805 : loss : 0.023380, loss_ce: 0.008527\n",
            "iteration 9806 : loss : 0.076261, loss_ce: 0.008393\n",
            "iteration 9807 : loss : 0.027496, loss_ce: 0.007806\n",
            "iteration 9808 : loss : 0.026247, loss_ce: 0.006937\n",
            "iteration 9809 : loss : 0.023341, loss_ce: 0.006692\n",
            "iteration 9810 : loss : 0.024845, loss_ce: 0.007605\n",
            "iteration 9811 : loss : 0.024193, loss_ce: 0.010798\n",
            "iteration 9812 : loss : 0.024895, loss_ce: 0.009276\n",
            "iteration 9813 : loss : 0.028313, loss_ce: 0.005617\n",
            "iteration 9814 : loss : 0.023053, loss_ce: 0.007125\n",
            "iteration 9815 : loss : 0.076523, loss_ce: 0.006382\n",
            "iteration 9816 : loss : 0.027070, loss_ce: 0.010483\n",
            "iteration 9817 : loss : 0.024929, loss_ce: 0.008796\n",
            "iteration 9818 : loss : 0.020547, loss_ce: 0.006042\n",
            "iteration 9819 : loss : 0.026031, loss_ce: 0.007018\n",
            "iteration 9820 : loss : 0.074311, loss_ce: 0.008584\n",
            "iteration 9821 : loss : 0.026855, loss_ce: 0.010077\n",
            "iteration 9822 : loss : 0.028505, loss_ce: 0.009321\n",
            "iteration 9823 : loss : 0.028341, loss_ce: 0.005908\n",
            "iteration 9824 : loss : 0.022269, loss_ce: 0.005432\n",
            "iteration 9825 : loss : 0.025743, loss_ce: 0.011363\n",
            "iteration 9826 : loss : 0.022470, loss_ce: 0.007729\n",
            "iteration 9827 : loss : 0.023111, loss_ce: 0.008065\n",
            "iteration 9828 : loss : 0.030242, loss_ce: 0.010086\n",
            "iteration 9829 : loss : 0.022889, loss_ce: 0.010315\n",
            "iteration 9830 : loss : 0.021427, loss_ce: 0.005686\n",
            "iteration 9831 : loss : 0.023162, loss_ce: 0.008881\n",
            "iteration 9832 : loss : 0.024309, loss_ce: 0.010842\n",
            "iteration 9833 : loss : 0.025523, loss_ce: 0.009038\n",
            "iteration 9834 : loss : 0.032719, loss_ce: 0.009877\n",
            "iteration 9835 : loss : 0.076282, loss_ce: 0.006919\n",
            "iteration 9836 : loss : 0.025761, loss_ce: 0.004616\n",
            "iteration 9837 : loss : 0.023118, loss_ce: 0.010152\n",
            "iteration 9838 : loss : 0.024102, loss_ce: 0.009310\n",
            "iteration 9839 : loss : 0.025644, loss_ce: 0.008879\n",
            "iteration 9840 : loss : 0.072231, loss_ce: 0.003518\n",
            "iteration 9841 : loss : 0.027586, loss_ce: 0.015125\n",
            "iteration 9842 : loss : 0.027550, loss_ce: 0.011496\n",
            " 89%|████████████████████████▊   | 133/150 [4:00:09<30:38, 108.14s/it]iteration 9843 : loss : 0.030224, loss_ce: 0.005664\n",
            "iteration 9844 : loss : 0.023953, loss_ce: 0.006957\n",
            "iteration 9845 : loss : 0.021573, loss_ce: 0.009385\n",
            "iteration 9846 : loss : 0.024297, loss_ce: 0.007687\n",
            "iteration 9847 : loss : 0.026573, loss_ce: 0.009024\n",
            "iteration 9848 : loss : 0.023725, loss_ce: 0.006353\n",
            "iteration 9849 : loss : 0.025331, loss_ce: 0.007691\n",
            "iteration 9850 : loss : 0.028149, loss_ce: 0.006255\n",
            "iteration 9851 : loss : 0.025026, loss_ce: 0.009478\n",
            "iteration 9852 : loss : 0.026871, loss_ce: 0.004655\n",
            "iteration 9853 : loss : 0.024477, loss_ce: 0.007877\n",
            "iteration 9854 : loss : 0.024971, loss_ce: 0.008371\n",
            "iteration 9855 : loss : 0.075553, loss_ce: 0.008052\n",
            "iteration 9856 : loss : 0.023119, loss_ce: 0.008054\n",
            "iteration 9857 : loss : 0.025710, loss_ce: 0.010441\n",
            "iteration 9858 : loss : 0.027738, loss_ce: 0.013578\n",
            "iteration 9859 : loss : 0.021321, loss_ce: 0.008042\n",
            "iteration 9860 : loss : 0.026405, loss_ce: 0.006224\n",
            "iteration 9861 : loss : 0.025192, loss_ce: 0.010353\n",
            "iteration 9862 : loss : 0.022333, loss_ce: 0.009639\n",
            "iteration 9863 : loss : 0.028953, loss_ce: 0.008960\n",
            "iteration 9864 : loss : 0.025353, loss_ce: 0.006153\n",
            "iteration 9865 : loss : 0.027262, loss_ce: 0.007841\n",
            "iteration 9866 : loss : 0.023576, loss_ce: 0.007924\n",
            "iteration 9867 : loss : 0.024651, loss_ce: 0.008184\n",
            "iteration 9868 : loss : 0.025401, loss_ce: 0.011816\n",
            "iteration 9869 : loss : 0.074491, loss_ce: 0.007524\n",
            "iteration 9870 : loss : 0.052584, loss_ce: 0.009115\n",
            "iteration 9871 : loss : 0.027531, loss_ce: 0.006187\n",
            "iteration 9872 : loss : 0.030491, loss_ce: 0.009563\n",
            "iteration 9873 : loss : 0.031376, loss_ce: 0.011480\n",
            "iteration 9874 : loss : 0.023294, loss_ce: 0.007371\n",
            "iteration 9875 : loss : 0.025601, loss_ce: 0.006645\n",
            "iteration 9876 : loss : 0.023618, loss_ce: 0.006295\n",
            "iteration 9877 : loss : 0.023735, loss_ce: 0.006889\n",
            "iteration 9878 : loss : 0.025496, loss_ce: 0.007598\n",
            "iteration 9879 : loss : 0.023577, loss_ce: 0.010093\n",
            "iteration 9880 : loss : 0.023593, loss_ce: 0.007626\n",
            "iteration 9881 : loss : 0.020588, loss_ce: 0.009448\n",
            "iteration 9882 : loss : 0.025921, loss_ce: 0.006258\n",
            "iteration 9883 : loss : 0.024452, loss_ce: 0.008228\n",
            "iteration 9884 : loss : 0.024152, loss_ce: 0.010061\n",
            "iteration 9885 : loss : 0.079946, loss_ce: 0.005106\n",
            "iteration 9886 : loss : 0.022229, loss_ce: 0.005047\n",
            "iteration 9887 : loss : 0.023625, loss_ce: 0.005278\n",
            "iteration 9888 : loss : 0.022922, loss_ce: 0.008773\n",
            "iteration 9889 : loss : 0.022369, loss_ce: 0.007426\n",
            "iteration 9890 : loss : 0.024680, loss_ce: 0.007681\n",
            "iteration 9891 : loss : 0.028689, loss_ce: 0.010426\n",
            "iteration 9892 : loss : 0.027683, loss_ce: 0.006797\n",
            "iteration 9893 : loss : 0.023032, loss_ce: 0.007953\n",
            "iteration 9894 : loss : 0.125951, loss_ce: 0.003821\n",
            "iteration 9895 : loss : 0.027732, loss_ce: 0.010074\n",
            "iteration 9896 : loss : 0.018592, loss_ce: 0.006958\n",
            "iteration 9897 : loss : 0.024274, loss_ce: 0.008661\n",
            "iteration 9898 : loss : 0.028237, loss_ce: 0.010253\n",
            "iteration 9899 : loss : 0.024731, loss_ce: 0.006355\n",
            "iteration 9900 : loss : 0.023564, loss_ce: 0.011838\n",
            "iteration 9901 : loss : 0.035705, loss_ce: 0.009018\n",
            "iteration 9902 : loss : 0.027898, loss_ce: 0.008473\n",
            "iteration 9903 : loss : 0.023825, loss_ce: 0.008740\n",
            "iteration 9904 : loss : 0.024366, loss_ce: 0.007166\n",
            "iteration 9905 : loss : 0.025810, loss_ce: 0.010319\n",
            "iteration 9906 : loss : 0.025531, loss_ce: 0.009228\n",
            "iteration 9907 : loss : 0.032770, loss_ce: 0.012070\n",
            "iteration 9908 : loss : 0.027714, loss_ce: 0.011060\n",
            "iteration 9909 : loss : 0.026997, loss_ce: 0.010667\n",
            "iteration 9910 : loss : 0.025272, loss_ce: 0.007825\n",
            "iteration 9911 : loss : 0.022434, loss_ce: 0.007754\n",
            "iteration 9912 : loss : 0.027597, loss_ce: 0.007819\n",
            "iteration 9913 : loss : 0.023576, loss_ce: 0.008772\n",
            "iteration 9914 : loss : 0.026366, loss_ce: 0.010881\n",
            "iteration 9915 : loss : 0.028934, loss_ce: 0.013195\n",
            "iteration 9916 : loss : 0.024913, loss_ce: 0.010539\n",
            " 89%|█████████████████████████   | 134/150 [4:01:58<28:52, 108.27s/it]iteration 9917 : loss : 0.022458, loss_ce: 0.008027\n",
            "iteration 9918 : loss : 0.029340, loss_ce: 0.012718\n",
            "iteration 9919 : loss : 0.020168, loss_ce: 0.007556\n",
            "iteration 9920 : loss : 0.059942, loss_ce: 0.008274\n",
            "iteration 9921 : loss : 0.023558, loss_ce: 0.008735\n",
            "iteration 9922 : loss : 0.029092, loss_ce: 0.010384\n",
            "iteration 9923 : loss : 0.032539, loss_ce: 0.005791\n",
            "iteration 9924 : loss : 0.077614, loss_ce: 0.005843\n",
            "iteration 9925 : loss : 0.021170, loss_ce: 0.008794\n",
            "iteration 9926 : loss : 0.023349, loss_ce: 0.009718\n",
            "iteration 9927 : loss : 0.023698, loss_ce: 0.008022\n",
            "iteration 9928 : loss : 0.025838, loss_ce: 0.008780\n",
            "iteration 9929 : loss : 0.034285, loss_ce: 0.010183\n",
            "iteration 9930 : loss : 0.029517, loss_ce: 0.008496\n",
            "iteration 9931 : loss : 0.026548, loss_ce: 0.008614\n",
            "iteration 9932 : loss : 0.031315, loss_ce: 0.009608\n",
            "iteration 9933 : loss : 0.025264, loss_ce: 0.010492\n",
            "iteration 9934 : loss : 0.025333, loss_ce: 0.007318\n",
            "iteration 9935 : loss : 0.022353, loss_ce: 0.007593\n",
            "iteration 9936 : loss : 0.079676, loss_ce: 0.006324\n",
            "iteration 9937 : loss : 0.028456, loss_ce: 0.013772\n",
            "iteration 9938 : loss : 0.026554, loss_ce: 0.011812\n",
            "iteration 9939 : loss : 0.029901, loss_ce: 0.013449\n",
            "iteration 9940 : loss : 0.025453, loss_ce: 0.008353\n",
            "iteration 9941 : loss : 0.075294, loss_ce: 0.007230\n",
            "iteration 9942 : loss : 0.023799, loss_ce: 0.007210\n",
            "iteration 9943 : loss : 0.022926, loss_ce: 0.009180\n",
            "iteration 9944 : loss : 0.030643, loss_ce: 0.013246\n",
            "iteration 9945 : loss : 0.025929, loss_ce: 0.011510\n",
            "iteration 9946 : loss : 0.075444, loss_ce: 0.003728\n",
            "iteration 9947 : loss : 0.021989, loss_ce: 0.005751\n",
            "iteration 9948 : loss : 0.024102, loss_ce: 0.009870\n",
            "iteration 9949 : loss : 0.022239, loss_ce: 0.006892\n",
            "iteration 9950 : loss : 0.021308, loss_ce: 0.005553\n",
            "iteration 9951 : loss : 0.021555, loss_ce: 0.007273\n",
            "iteration 9952 : loss : 0.022075, loss_ce: 0.009412\n",
            "iteration 9953 : loss : 0.074455, loss_ce: 0.004647\n",
            "iteration 9954 : loss : 0.027136, loss_ce: 0.010046\n",
            "iteration 9955 : loss : 0.025535, loss_ce: 0.010998\n",
            "iteration 9956 : loss : 0.123443, loss_ce: 0.004590\n",
            "iteration 9957 : loss : 0.025606, loss_ce: 0.008140\n",
            "iteration 9958 : loss : 0.028383, loss_ce: 0.008455\n",
            "iteration 9959 : loss : 0.029555, loss_ce: 0.011114\n",
            "iteration 9960 : loss : 0.024783, loss_ce: 0.007403\n",
            "iteration 9961 : loss : 0.025871, loss_ce: 0.009462\n",
            "iteration 9962 : loss : 0.020923, loss_ce: 0.005368\n",
            "iteration 9963 : loss : 0.025099, loss_ce: 0.008400\n",
            "iteration 9964 : loss : 0.022071, loss_ce: 0.006786\n",
            "iteration 9965 : loss : 0.022090, loss_ce: 0.006355\n",
            "iteration 9966 : loss : 0.023177, loss_ce: 0.007161\n",
            "iteration 9967 : loss : 0.028161, loss_ce: 0.009453\n",
            "iteration 9968 : loss : 0.025318, loss_ce: 0.007478\n",
            "iteration 9969 : loss : 0.027103, loss_ce: 0.010708\n",
            "iteration 9970 : loss : 0.024514, loss_ce: 0.003864\n",
            "iteration 9971 : loss : 0.023533, loss_ce: 0.009322\n",
            "iteration 9972 : loss : 0.023687, loss_ce: 0.009212\n",
            "iteration 9973 : loss : 0.027986, loss_ce: 0.008727\n",
            "iteration 9974 : loss : 0.074057, loss_ce: 0.005653\n",
            "iteration 9975 : loss : 0.027812, loss_ce: 0.010788\n",
            "iteration 9976 : loss : 0.027257, loss_ce: 0.006695\n",
            "iteration 9977 : loss : 0.028535, loss_ce: 0.011968\n",
            "iteration 9978 : loss : 0.029239, loss_ce: 0.011557\n",
            "iteration 9979 : loss : 0.017751, loss_ce: 0.005032\n",
            "iteration 9980 : loss : 0.024869, loss_ce: 0.008449\n",
            "iteration 9981 : loss : 0.029647, loss_ce: 0.009965\n",
            "iteration 9982 : loss : 0.030307, loss_ce: 0.008231\n",
            "iteration 9983 : loss : 0.073856, loss_ce: 0.006957\n",
            "iteration 9984 : loss : 0.028475, loss_ce: 0.007495\n",
            "iteration 9985 : loss : 0.023563, loss_ce: 0.009343\n",
            "iteration 9986 : loss : 0.025099, loss_ce: 0.009164\n",
            "iteration 9987 : loss : 0.025621, loss_ce: 0.011307\n",
            "iteration 9988 : loss : 0.023765, loss_ce: 0.007238\n",
            "iteration 9989 : loss : 0.026024, loss_ce: 0.010165\n",
            "iteration 9990 : loss : 0.023850, loss_ce: 0.008860\n",
            " 90%|█████████████████████████▏  | 135/150 [4:03:47<27:08, 108.56s/it]iteration 9991 : loss : 0.023617, loss_ce: 0.007741\n",
            "iteration 9992 : loss : 0.026783, loss_ce: 0.010083\n",
            "iteration 9993 : loss : 0.022536, loss_ce: 0.007144\n",
            "iteration 9994 : loss : 0.021448, loss_ce: 0.007491\n",
            "iteration 9995 : loss : 0.025494, loss_ce: 0.004672\n",
            "iteration 9996 : loss : 0.021294, loss_ce: 0.006946\n",
            "iteration 9997 : loss : 0.017973, loss_ce: 0.006266\n",
            "iteration 9998 : loss : 0.020894, loss_ce: 0.007900\n",
            "iteration 9999 : loss : 0.035854, loss_ce: 0.006998\n",
            "iteration 10000 : loss : 0.024400, loss_ce: 0.006637\n",
            "iteration 10001 : loss : 0.024953, loss_ce: 0.009310\n",
            "iteration 10002 : loss : 0.023236, loss_ce: 0.007195\n",
            "iteration 10003 : loss : 0.075985, loss_ce: 0.006718\n",
            "iteration 10004 : loss : 0.072776, loss_ce: 0.005606\n",
            "iteration 10005 : loss : 0.026576, loss_ce: 0.009870\n",
            "iteration 10006 : loss : 0.023095, loss_ce: 0.008920\n",
            "iteration 10007 : loss : 0.025389, loss_ce: 0.007417\n",
            "iteration 10008 : loss : 0.026416, loss_ce: 0.010795\n",
            "iteration 10009 : loss : 0.022510, loss_ce: 0.009151\n",
            "iteration 10010 : loss : 0.024862, loss_ce: 0.007907\n",
            "iteration 10011 : loss : 0.023527, loss_ce: 0.010177\n",
            "iteration 10012 : loss : 0.023219, loss_ce: 0.010901\n",
            "iteration 10013 : loss : 0.026679, loss_ce: 0.012135\n",
            "iteration 10014 : loss : 0.022365, loss_ce: 0.008285\n",
            "iteration 10015 : loss : 0.024768, loss_ce: 0.007155\n",
            "iteration 10016 : loss : 0.023418, loss_ce: 0.006574\n",
            "iteration 10017 : loss : 0.021632, loss_ce: 0.008068\n",
            "iteration 10018 : loss : 0.025934, loss_ce: 0.007800\n",
            "iteration 10019 : loss : 0.038724, loss_ce: 0.005746\n",
            "iteration 10020 : loss : 0.028550, loss_ce: 0.009063\n",
            "iteration 10021 : loss : 0.021228, loss_ce: 0.008327\n",
            "iteration 10022 : loss : 0.024177, loss_ce: 0.008518\n",
            "iteration 10023 : loss : 0.075088, loss_ce: 0.008447\n",
            "iteration 10024 : loss : 0.028072, loss_ce: 0.007020\n",
            "iteration 10025 : loss : 0.021370, loss_ce: 0.007034\n",
            "iteration 10026 : loss : 0.027066, loss_ce: 0.008010\n",
            "iteration 10027 : loss : 0.026673, loss_ce: 0.007865\n",
            "iteration 10028 : loss : 0.070595, loss_ce: 0.006365\n",
            "iteration 10029 : loss : 0.026770, loss_ce: 0.009271\n",
            "iteration 10030 : loss : 0.025856, loss_ce: 0.009962\n",
            "iteration 10031 : loss : 0.079512, loss_ce: 0.008263\n",
            "iteration 10032 : loss : 0.024142, loss_ce: 0.006925\n",
            "iteration 10033 : loss : 0.075683, loss_ce: 0.005641\n",
            "iteration 10034 : loss : 0.024442, loss_ce: 0.009729\n",
            "iteration 10035 : loss : 0.029572, loss_ce: 0.008318\n",
            "iteration 10036 : loss : 0.021890, loss_ce: 0.006324\n",
            "iteration 10037 : loss : 0.022675, loss_ce: 0.009839\n",
            "iteration 10038 : loss : 0.020879, loss_ce: 0.009164\n",
            "iteration 10039 : loss : 0.024938, loss_ce: 0.006185\n",
            "iteration 10040 : loss : 0.018106, loss_ce: 0.004039\n",
            "iteration 10041 : loss : 0.021732, loss_ce: 0.006331\n",
            "iteration 10042 : loss : 0.026627, loss_ce: 0.012943\n",
            "iteration 10043 : loss : 0.021271, loss_ce: 0.007694\n",
            "iteration 10044 : loss : 0.030224, loss_ce: 0.007029\n",
            "iteration 10045 : loss : 0.021769, loss_ce: 0.007937\n",
            "iteration 10046 : loss : 0.024264, loss_ce: 0.009549\n",
            "iteration 10047 : loss : 0.028297, loss_ce: 0.009862\n",
            "iteration 10048 : loss : 0.022628, loss_ce: 0.007993\n",
            "iteration 10049 : loss : 0.078537, loss_ce: 0.008104\n",
            "iteration 10050 : loss : 0.024327, loss_ce: 0.008674\n",
            "iteration 10051 : loss : 0.024287, loss_ce: 0.008842\n",
            "iteration 10052 : loss : 0.028423, loss_ce: 0.010771\n",
            "iteration 10053 : loss : 0.026170, loss_ce: 0.010164\n",
            "iteration 10054 : loss : 0.022792, loss_ce: 0.009264\n",
            "iteration 10055 : loss : 0.027016, loss_ce: 0.009477\n",
            "iteration 10056 : loss : 0.025574, loss_ce: 0.007907\n",
            "iteration 10057 : loss : 0.023708, loss_ce: 0.009813\n",
            "iteration 10058 : loss : 0.032207, loss_ce: 0.009029\n",
            "iteration 10059 : loss : 0.023702, loss_ce: 0.010566\n",
            "iteration 10060 : loss : 0.030209, loss_ce: 0.013052\n",
            "iteration 10061 : loss : 0.026985, loss_ce: 0.010220\n",
            "iteration 10062 : loss : 0.024464, loss_ce: 0.010954\n",
            "iteration 10063 : loss : 0.023821, loss_ce: 0.005460\n",
            "iteration 10064 : loss : 0.025093, loss_ce: 0.007570\n",
            " 91%|█████████████████████████▍  | 136/150 [4:05:35<25:16, 108.33s/it]iteration 10065 : loss : 0.021267, loss_ce: 0.009339\n",
            "iteration 10066 : loss : 0.028789, loss_ce: 0.003813\n",
            "iteration 10067 : loss : 0.029184, loss_ce: 0.009107\n",
            "iteration 10068 : loss : 0.023885, loss_ce: 0.009865\n",
            "iteration 10069 : loss : 0.026769, loss_ce: 0.009796\n",
            "iteration 10070 : loss : 0.076399, loss_ce: 0.003266\n",
            "iteration 10071 : loss : 0.023114, loss_ce: 0.006304\n",
            "iteration 10072 : loss : 0.024984, loss_ce: 0.010468\n",
            "iteration 10073 : loss : 0.021598, loss_ce: 0.007697\n",
            "iteration 10074 : loss : 0.023551, loss_ce: 0.007437\n",
            "iteration 10075 : loss : 0.072914, loss_ce: 0.005424\n",
            "iteration 10076 : loss : 0.025499, loss_ce: 0.010723\n",
            "iteration 10077 : loss : 0.022648, loss_ce: 0.007419\n",
            "iteration 10078 : loss : 0.021229, loss_ce: 0.006908\n",
            "iteration 10079 : loss : 0.024798, loss_ce: 0.011269\n",
            "iteration 10080 : loss : 0.021968, loss_ce: 0.008000\n",
            "iteration 10081 : loss : 0.075423, loss_ce: 0.007087\n",
            "iteration 10082 : loss : 0.022785, loss_ce: 0.007419\n",
            "iteration 10083 : loss : 0.026159, loss_ce: 0.011295\n",
            "iteration 10084 : loss : 0.021354, loss_ce: 0.009090\n",
            "iteration 10085 : loss : 0.025000, loss_ce: 0.010246\n",
            "iteration 10086 : loss : 0.034228, loss_ce: 0.010240\n",
            "iteration 10087 : loss : 0.075580, loss_ce: 0.007291\n",
            "iteration 10088 : loss : 0.023279, loss_ce: 0.008858\n",
            "iteration 10089 : loss : 0.029518, loss_ce: 0.009032\n",
            "iteration 10090 : loss : 0.024906, loss_ce: 0.008919\n",
            "iteration 10091 : loss : 0.024715, loss_ce: 0.011151\n",
            "iteration 10092 : loss : 0.016136, loss_ce: 0.002982\n",
            "iteration 10093 : loss : 0.027904, loss_ce: 0.007547\n",
            "iteration 10094 : loss : 0.024062, loss_ce: 0.004289\n",
            "iteration 10095 : loss : 0.021738, loss_ce: 0.007529\n",
            "iteration 10096 : loss : 0.020498, loss_ce: 0.006038\n",
            "iteration 10097 : loss : 0.026633, loss_ce: 0.010549\n",
            "iteration 10098 : loss : 0.034932, loss_ce: 0.009654\n",
            "iteration 10099 : loss : 0.024500, loss_ce: 0.009234\n",
            "iteration 10100 : loss : 0.022166, loss_ce: 0.010109\n",
            "iteration 10101 : loss : 0.034212, loss_ce: 0.008273\n",
            "iteration 10102 : loss : 0.024620, loss_ce: 0.011189\n",
            "iteration 10103 : loss : 0.026214, loss_ce: 0.008826\n",
            "iteration 10104 : loss : 0.023587, loss_ce: 0.012502\n",
            "iteration 10105 : loss : 0.042089, loss_ce: 0.006377\n",
            "iteration 10106 : loss : 0.024584, loss_ce: 0.008182\n",
            "iteration 10107 : loss : 0.024796, loss_ce: 0.010810\n",
            "iteration 10108 : loss : 0.022744, loss_ce: 0.006451\n",
            "iteration 10109 : loss : 0.025864, loss_ce: 0.007591\n",
            "iteration 10110 : loss : 0.025981, loss_ce: 0.012312\n",
            "iteration 10111 : loss : 0.020972, loss_ce: 0.005440\n",
            "iteration 10112 : loss : 0.021926, loss_ce: 0.008202\n",
            "iteration 10113 : loss : 0.030369, loss_ce: 0.011436\n",
            "iteration 10114 : loss : 0.025548, loss_ce: 0.008260\n",
            "iteration 10115 : loss : 0.019488, loss_ce: 0.004727\n",
            "iteration 10116 : loss : 0.032052, loss_ce: 0.006943\n",
            "iteration 10117 : loss : 0.022221, loss_ce: 0.009783\n",
            "iteration 10118 : loss : 0.021122, loss_ce: 0.005498\n",
            "iteration 10119 : loss : 0.027451, loss_ce: 0.009075\n",
            "iteration 10120 : loss : 0.077596, loss_ce: 0.005257\n",
            "iteration 10121 : loss : 0.022939, loss_ce: 0.007725\n",
            "iteration 10122 : loss : 0.025837, loss_ce: 0.009357\n",
            "iteration 10123 : loss : 0.031456, loss_ce: 0.011854\n",
            "iteration 10124 : loss : 0.026326, loss_ce: 0.008550\n",
            "iteration 10125 : loss : 0.029282, loss_ce: 0.008080\n",
            "iteration 10126 : loss : 0.029402, loss_ce: 0.010290\n",
            "iteration 10127 : loss : 0.025402, loss_ce: 0.006486\n",
            "iteration 10128 : loss : 0.020544, loss_ce: 0.007068\n",
            "iteration 10129 : loss : 0.025488, loss_ce: 0.010946\n",
            "iteration 10130 : loss : 0.025166, loss_ce: 0.009112\n",
            "iteration 10131 : loss : 0.022239, loss_ce: 0.007004\n",
            "iteration 10132 : loss : 0.024648, loss_ce: 0.010145\n",
            "iteration 10133 : loss : 0.020954, loss_ce: 0.010875\n",
            "iteration 10134 : loss : 0.025553, loss_ce: 0.005863\n",
            "iteration 10135 : loss : 0.027009, loss_ce: 0.008513\n",
            "iteration 10136 : loss : 0.025117, loss_ce: 0.008174\n",
            "iteration 10137 : loss : 0.025486, loss_ce: 0.007057\n",
            "iteration 10138 : loss : 0.026234, loss_ce: 0.009617\n",
            " 91%|█████████████████████████▌  | 137/150 [4:07:22<23:23, 107.98s/it]iteration 10139 : loss : 0.021406, loss_ce: 0.005265\n",
            "iteration 10140 : loss : 0.028680, loss_ce: 0.007691\n",
            "iteration 10141 : loss : 0.026999, loss_ce: 0.009558\n",
            "iteration 10142 : loss : 0.075829, loss_ce: 0.007389\n",
            "iteration 10143 : loss : 0.024617, loss_ce: 0.010985\n",
            "iteration 10144 : loss : 0.029309, loss_ce: 0.006338\n",
            "iteration 10145 : loss : 0.024240, loss_ce: 0.009106\n",
            "iteration 10146 : loss : 0.024205, loss_ce: 0.006923\n",
            "iteration 10147 : loss : 0.022393, loss_ce: 0.007633\n",
            "iteration 10148 : loss : 0.075436, loss_ce: 0.004867\n",
            "iteration 10149 : loss : 0.030880, loss_ce: 0.012715\n",
            "iteration 10150 : loss : 0.024451, loss_ce: 0.007808\n",
            "iteration 10151 : loss : 0.024531, loss_ce: 0.011432\n",
            "iteration 10152 : loss : 0.024269, loss_ce: 0.010626\n",
            "iteration 10153 : loss : 0.024586, loss_ce: 0.008176\n",
            "iteration 10154 : loss : 0.028339, loss_ce: 0.013009\n",
            "iteration 10155 : loss : 0.023798, loss_ce: 0.006938\n",
            "iteration 10156 : loss : 0.023104, loss_ce: 0.007786\n",
            "iteration 10157 : loss : 0.026911, loss_ce: 0.007864\n",
            "iteration 10158 : loss : 0.024576, loss_ce: 0.010527\n",
            "iteration 10159 : loss : 0.017254, loss_ce: 0.004941\n",
            "iteration 10160 : loss : 0.025511, loss_ce: 0.011767\n",
            "iteration 10161 : loss : 0.075647, loss_ce: 0.002379\n",
            "iteration 10162 : loss : 0.026923, loss_ce: 0.009474\n",
            "iteration 10163 : loss : 0.024729, loss_ce: 0.005443\n",
            "iteration 10164 : loss : 0.021463, loss_ce: 0.010145\n",
            "iteration 10165 : loss : 0.022119, loss_ce: 0.010617\n",
            "iteration 10166 : loss : 0.025433, loss_ce: 0.010123\n",
            "iteration 10167 : loss : 0.020563, loss_ce: 0.005268\n",
            "iteration 10168 : loss : 0.026283, loss_ce: 0.007561\n",
            "iteration 10169 : loss : 0.022479, loss_ce: 0.008090\n",
            "iteration 10170 : loss : 0.021424, loss_ce: 0.005210\n",
            "iteration 10171 : loss : 0.022409, loss_ce: 0.007789\n",
            "iteration 10172 : loss : 0.019859, loss_ce: 0.007743\n",
            "iteration 10173 : loss : 0.023308, loss_ce: 0.007985\n",
            "iteration 10174 : loss : 0.026246, loss_ce: 0.008888\n",
            "iteration 10175 : loss : 0.023942, loss_ce: 0.009309\n",
            "iteration 10176 : loss : 0.077833, loss_ce: 0.004034\n",
            "iteration 10177 : loss : 0.023363, loss_ce: 0.009297\n",
            "iteration 10178 : loss : 0.071765, loss_ce: 0.003480\n",
            "iteration 10179 : loss : 0.024577, loss_ce: 0.005476\n",
            "iteration 10180 : loss : 0.024456, loss_ce: 0.008856\n",
            "iteration 10181 : loss : 0.022712, loss_ce: 0.009334\n",
            "iteration 10182 : loss : 0.023426, loss_ce: 0.010809\n",
            "iteration 10183 : loss : 0.025214, loss_ce: 0.011111\n",
            "iteration 10184 : loss : 0.026694, loss_ce: 0.008230\n",
            "iteration 10185 : loss : 0.024238, loss_ce: 0.006923\n",
            "iteration 10186 : loss : 0.024951, loss_ce: 0.005900\n",
            "iteration 10187 : loss : 0.025847, loss_ce: 0.005724\n",
            "iteration 10188 : loss : 0.027337, loss_ce: 0.010727\n",
            "iteration 10189 : loss : 0.026103, loss_ce: 0.011559\n",
            "iteration 10190 : loss : 0.022287, loss_ce: 0.008660\n",
            "iteration 10191 : loss : 0.025364, loss_ce: 0.008158\n",
            "iteration 10192 : loss : 0.023245, loss_ce: 0.007932\n",
            "iteration 10193 : loss : 0.022255, loss_ce: 0.010486\n",
            "iteration 10194 : loss : 0.025883, loss_ce: 0.010839\n",
            "iteration 10195 : loss : 0.024806, loss_ce: 0.005720\n",
            "iteration 10196 : loss : 0.024527, loss_ce: 0.007724\n",
            "iteration 10197 : loss : 0.022995, loss_ce: 0.007909\n",
            "iteration 10198 : loss : 0.023061, loss_ce: 0.006942\n",
            "iteration 10199 : loss : 0.024633, loss_ce: 0.012383\n",
            "iteration 10200 : loss : 0.020427, loss_ce: 0.006267\n",
            "iteration 10201 : loss : 0.024461, loss_ce: 0.009419\n",
            "iteration 10202 : loss : 0.019837, loss_ce: 0.005203\n",
            "iteration 10203 : loss : 0.023647, loss_ce: 0.010440\n",
            "iteration 10204 : loss : 0.075224, loss_ce: 0.007216\n",
            "iteration 10205 : loss : 0.028852, loss_ce: 0.009237\n",
            "iteration 10206 : loss : 0.022598, loss_ce: 0.009556\n",
            "iteration 10207 : loss : 0.021285, loss_ce: 0.008272\n",
            "iteration 10208 : loss : 0.029723, loss_ce: 0.012432\n",
            "iteration 10209 : loss : 0.024592, loss_ce: 0.006457\n",
            "iteration 10210 : loss : 0.025319, loss_ce: 0.008913\n",
            "iteration 10211 : loss : 0.030305, loss_ce: 0.010743\n",
            "iteration 10212 : loss : 0.030053, loss_ce: 0.011161\n",
            " 92%|█████████████████████████▊  | 138/150 [4:09:11<21:40, 108.34s/it]iteration 10213 : loss : 0.023019, loss_ce: 0.008039\n",
            "iteration 10214 : loss : 0.023771, loss_ce: 0.007482\n",
            "iteration 10215 : loss : 0.026222, loss_ce: 0.009238\n",
            "iteration 10216 : loss : 0.025211, loss_ce: 0.009879\n",
            "iteration 10217 : loss : 0.020728, loss_ce: 0.005087\n",
            "iteration 10218 : loss : 0.025929, loss_ce: 0.008803\n",
            "iteration 10219 : loss : 0.022566, loss_ce: 0.009798\n",
            "iteration 10220 : loss : 0.020555, loss_ce: 0.006359\n",
            "iteration 10221 : loss : 0.023917, loss_ce: 0.007667\n",
            "iteration 10222 : loss : 0.023582, loss_ce: 0.010680\n",
            "iteration 10223 : loss : 0.026734, loss_ce: 0.008384\n",
            "iteration 10224 : loss : 0.059014, loss_ce: 0.004852\n",
            "iteration 10225 : loss : 0.024750, loss_ce: 0.008360\n",
            "iteration 10226 : loss : 0.028847, loss_ce: 0.008967\n",
            "iteration 10227 : loss : 0.028249, loss_ce: 0.009021\n",
            "iteration 10228 : loss : 0.026680, loss_ce: 0.009031\n",
            "iteration 10229 : loss : 0.030209, loss_ce: 0.009089\n",
            "iteration 10230 : loss : 0.025979, loss_ce: 0.006950\n",
            "iteration 10231 : loss : 0.024088, loss_ce: 0.005266\n",
            "iteration 10232 : loss : 0.024177, loss_ce: 0.007875\n",
            "iteration 10233 : loss : 0.025136, loss_ce: 0.006616\n",
            "iteration 10234 : loss : 0.025498, loss_ce: 0.010302\n",
            "iteration 10235 : loss : 0.019485, loss_ce: 0.007470\n",
            "iteration 10236 : loss : 0.075415, loss_ce: 0.005848\n",
            "iteration 10237 : loss : 0.075803, loss_ce: 0.008046\n",
            "iteration 10238 : loss : 0.076987, loss_ce: 0.006789\n",
            "iteration 10239 : loss : 0.019368, loss_ce: 0.006729\n",
            "iteration 10240 : loss : 0.026872, loss_ce: 0.008612\n",
            "iteration 10241 : loss : 0.022307, loss_ce: 0.008793\n",
            "iteration 10242 : loss : 0.028075, loss_ce: 0.012857\n",
            "iteration 10243 : loss : 0.074898, loss_ce: 0.005497\n",
            "iteration 10244 : loss : 0.030676, loss_ce: 0.011333\n",
            "iteration 10245 : loss : 0.024150, loss_ce: 0.005534\n",
            "iteration 10246 : loss : 0.023406, loss_ce: 0.010802\n",
            "iteration 10247 : loss : 0.021640, loss_ce: 0.007998\n",
            "iteration 10248 : loss : 0.022050, loss_ce: 0.007879\n",
            "iteration 10249 : loss : 0.025678, loss_ce: 0.009930\n",
            "iteration 10250 : loss : 0.026574, loss_ce: 0.011375\n",
            "iteration 10251 : loss : 0.026982, loss_ce: 0.014489\n",
            "iteration 10252 : loss : 0.024122, loss_ce: 0.006684\n",
            "iteration 10253 : loss : 0.021401, loss_ce: 0.008326\n",
            "iteration 10254 : loss : 0.024349, loss_ce: 0.010092\n",
            "iteration 10255 : loss : 0.030217, loss_ce: 0.011451\n",
            "iteration 10256 : loss : 0.025359, loss_ce: 0.012882\n",
            "iteration 10257 : loss : 0.036397, loss_ce: 0.006075\n",
            "iteration 10258 : loss : 0.026387, loss_ce: 0.009013\n",
            "iteration 10259 : loss : 0.019705, loss_ce: 0.005644\n",
            "iteration 10260 : loss : 0.023133, loss_ce: 0.006580\n",
            "iteration 10261 : loss : 0.021695, loss_ce: 0.007979\n",
            "iteration 10262 : loss : 0.026935, loss_ce: 0.007672\n",
            "iteration 10263 : loss : 0.024987, loss_ce: 0.007828\n",
            "iteration 10264 : loss : 0.021315, loss_ce: 0.006391\n",
            "iteration 10265 : loss : 0.022587, loss_ce: 0.007180\n",
            "iteration 10266 : loss : 0.025114, loss_ce: 0.007586\n",
            "iteration 10267 : loss : 0.022626, loss_ce: 0.008367\n",
            "iteration 10268 : loss : 0.026965, loss_ce: 0.006858\n",
            "iteration 10269 : loss : 0.023684, loss_ce: 0.010991\n",
            "iteration 10270 : loss : 0.072941, loss_ce: 0.005585\n",
            "iteration 10271 : loss : 0.026164, loss_ce: 0.008753\n",
            "iteration 10272 : loss : 0.025750, loss_ce: 0.012034\n",
            "iteration 10273 : loss : 0.023362, loss_ce: 0.005699\n",
            "iteration 10274 : loss : 0.025146, loss_ce: 0.010431\n",
            "iteration 10275 : loss : 0.025598, loss_ce: 0.008084\n",
            "iteration 10276 : loss : 0.025003, loss_ce: 0.007187\n",
            "iteration 10277 : loss : 0.023745, loss_ce: 0.008621\n",
            "iteration 10278 : loss : 0.028649, loss_ce: 0.008923\n",
            "iteration 10279 : loss : 0.025817, loss_ce: 0.013729\n",
            "iteration 10280 : loss : 0.027004, loss_ce: 0.010329\n",
            "iteration 10281 : loss : 0.026353, loss_ce: 0.010385\n",
            "iteration 10282 : loss : 0.021688, loss_ce: 0.004338\n",
            "iteration 10283 : loss : 0.023990, loss_ce: 0.007489\n",
            "iteration 10284 : loss : 0.022143, loss_ce: 0.006555\n",
            "iteration 10285 : loss : 0.023736, loss_ce: 0.008488\n",
            "iteration 10286 : loss : 0.023693, loss_ce: 0.006389\n",
            " 93%|█████████████████████████▉  | 139/150 [4:11:00<19:54, 108.55s/it]iteration 10287 : loss : 0.029051, loss_ce: 0.008667\n",
            "iteration 10288 : loss : 0.022713, loss_ce: 0.007389\n",
            "iteration 10289 : loss : 0.028657, loss_ce: 0.011095\n",
            "iteration 10290 : loss : 0.025000, loss_ce: 0.010115\n",
            "iteration 10291 : loss : 0.022036, loss_ce: 0.006643\n",
            "iteration 10292 : loss : 0.024595, loss_ce: 0.010062\n",
            "iteration 10293 : loss : 0.050102, loss_ce: 0.006975\n",
            "iteration 10294 : loss : 0.024579, loss_ce: 0.009900\n",
            "iteration 10295 : loss : 0.037222, loss_ce: 0.006872\n",
            "iteration 10296 : loss : 0.025222, loss_ce: 0.009343\n",
            "iteration 10297 : loss : 0.023389, loss_ce: 0.009265\n",
            "iteration 10298 : loss : 0.022174, loss_ce: 0.005664\n",
            "iteration 10299 : loss : 0.078625, loss_ce: 0.006808\n",
            "iteration 10300 : loss : 0.029779, loss_ce: 0.010155\n",
            "iteration 10301 : loss : 0.074847, loss_ce: 0.006630\n",
            "iteration 10302 : loss : 0.026789, loss_ce: 0.005489\n",
            "iteration 10303 : loss : 0.029779, loss_ce: 0.008295\n",
            "iteration 10304 : loss : 0.035668, loss_ce: 0.005564\n",
            "iteration 10305 : loss : 0.027621, loss_ce: 0.009675\n",
            "iteration 10306 : loss : 0.019479, loss_ce: 0.007591\n",
            "iteration 10307 : loss : 0.016021, loss_ce: 0.004877\n",
            "iteration 10308 : loss : 0.022745, loss_ce: 0.010607\n",
            "iteration 10309 : loss : 0.022893, loss_ce: 0.009357\n",
            "iteration 10310 : loss : 0.020357, loss_ce: 0.005524\n",
            "iteration 10311 : loss : 0.024597, loss_ce: 0.008710\n",
            "iteration 10312 : loss : 0.030327, loss_ce: 0.012267\n",
            "iteration 10313 : loss : 0.025812, loss_ce: 0.008160\n",
            "iteration 10314 : loss : 0.021861, loss_ce: 0.005069\n",
            "iteration 10315 : loss : 0.025924, loss_ce: 0.012617\n",
            "iteration 10316 : loss : 0.022243, loss_ce: 0.005825\n",
            "iteration 10317 : loss : 0.075870, loss_ce: 0.008105\n",
            "iteration 10318 : loss : 0.023756, loss_ce: 0.009482\n",
            "iteration 10319 : loss : 0.021282, loss_ce: 0.006870\n",
            "iteration 10320 : loss : 0.020806, loss_ce: 0.006109\n",
            "iteration 10321 : loss : 0.025684, loss_ce: 0.012347\n",
            "iteration 10322 : loss : 0.079761, loss_ce: 0.010842\n",
            "iteration 10323 : loss : 0.026794, loss_ce: 0.007726\n",
            "iteration 10324 : loss : 0.024891, loss_ce: 0.009996\n",
            "iteration 10325 : loss : 0.025016, loss_ce: 0.007725\n",
            "iteration 10326 : loss : 0.086260, loss_ce: 0.002533\n",
            "iteration 10327 : loss : 0.021934, loss_ce: 0.007294\n",
            "iteration 10328 : loss : 0.023893, loss_ce: 0.008702\n",
            "iteration 10329 : loss : 0.075933, loss_ce: 0.005321\n",
            "iteration 10330 : loss : 0.026302, loss_ce: 0.010113\n",
            "iteration 10331 : loss : 0.037893, loss_ce: 0.008891\n",
            "iteration 10332 : loss : 0.023893, loss_ce: 0.007859\n",
            "iteration 10333 : loss : 0.027525, loss_ce: 0.009354\n",
            "iteration 10334 : loss : 0.022516, loss_ce: 0.010706\n",
            "iteration 10335 : loss : 0.024252, loss_ce: 0.007206\n",
            "iteration 10336 : loss : 0.023238, loss_ce: 0.007041\n",
            "iteration 10337 : loss : 0.022339, loss_ce: 0.005977\n",
            "iteration 10338 : loss : 0.028033, loss_ce: 0.010398\n",
            "iteration 10339 : loss : 0.025952, loss_ce: 0.011892\n",
            "iteration 10340 : loss : 0.023457, loss_ce: 0.007681\n",
            "iteration 10341 : loss : 0.023924, loss_ce: 0.007114\n",
            "iteration 10342 : loss : 0.022372, loss_ce: 0.008055\n",
            "iteration 10343 : loss : 0.022838, loss_ce: 0.010559\n",
            "iteration 10344 : loss : 0.023034, loss_ce: 0.006081\n",
            "iteration 10345 : loss : 0.025978, loss_ce: 0.010062\n",
            "iteration 10346 : loss : 0.026317, loss_ce: 0.008958\n",
            "iteration 10347 : loss : 0.024596, loss_ce: 0.009931\n",
            "iteration 10348 : loss : 0.024187, loss_ce: 0.010273\n",
            "iteration 10349 : loss : 0.021097, loss_ce: 0.008181\n",
            "iteration 10350 : loss : 0.023181, loss_ce: 0.008029\n",
            "iteration 10351 : loss : 0.022397, loss_ce: 0.009203\n",
            "iteration 10352 : loss : 0.023345, loss_ce: 0.007990\n",
            "iteration 10353 : loss : 0.076111, loss_ce: 0.009200\n",
            "iteration 10354 : loss : 0.021883, loss_ce: 0.007284\n",
            "iteration 10355 : loss : 0.023373, loss_ce: 0.008726\n",
            "iteration 10356 : loss : 0.073674, loss_ce: 0.005007\n",
            "iteration 10357 : loss : 0.022247, loss_ce: 0.007737\n",
            "iteration 10358 : loss : 0.024889, loss_ce: 0.009653\n",
            "iteration 10359 : loss : 0.024563, loss_ce: 0.008166\n",
            "iteration 10360 : loss : 0.030585, loss_ce: 0.008689\n",
            " 93%|██████████████████████████▏ | 140/150 [4:12:48<18:03, 108.32s/it]iteration 10361 : loss : 0.022517, loss_ce: 0.007116\n",
            "iteration 10362 : loss : 0.023446, loss_ce: 0.009967\n",
            "iteration 10363 : loss : 0.029814, loss_ce: 0.009782\n",
            "iteration 10364 : loss : 0.024450, loss_ce: 0.009305\n",
            "iteration 10365 : loss : 0.021959, loss_ce: 0.008142\n",
            "iteration 10366 : loss : 0.025448, loss_ce: 0.005987\n",
            "iteration 10367 : loss : 0.078291, loss_ce: 0.008707\n",
            "iteration 10368 : loss : 0.016345, loss_ce: 0.008399\n",
            "iteration 10369 : loss : 0.023994, loss_ce: 0.010224\n",
            "iteration 10370 : loss : 0.021566, loss_ce: 0.007234\n",
            "iteration 10371 : loss : 0.020200, loss_ce: 0.006315\n",
            "iteration 10372 : loss : 0.025951, loss_ce: 0.008904\n",
            "iteration 10373 : loss : 0.027193, loss_ce: 0.006390\n",
            "iteration 10374 : loss : 0.021858, loss_ce: 0.008305\n",
            "iteration 10375 : loss : 0.030009, loss_ce: 0.006286\n",
            "iteration 10376 : loss : 0.023439, loss_ce: 0.007579\n",
            "iteration 10377 : loss : 0.026352, loss_ce: 0.013171\n",
            "iteration 10378 : loss : 0.072132, loss_ce: 0.003565\n",
            "iteration 10379 : loss : 0.072276, loss_ce: 0.005508\n",
            "iteration 10380 : loss : 0.021146, loss_ce: 0.006798\n",
            "iteration 10381 : loss : 0.025164, loss_ce: 0.011444\n",
            "iteration 10382 : loss : 0.024938, loss_ce: 0.006549\n",
            "iteration 10383 : loss : 0.023457, loss_ce: 0.009883\n",
            "iteration 10384 : loss : 0.024656, loss_ce: 0.010754\n",
            "iteration 10385 : loss : 0.030359, loss_ce: 0.008452\n",
            "iteration 10386 : loss : 0.023520, loss_ce: 0.008313\n",
            "iteration 10387 : loss : 0.025689, loss_ce: 0.009763\n",
            "iteration 10388 : loss : 0.035893, loss_ce: 0.008732\n",
            "iteration 10389 : loss : 0.020703, loss_ce: 0.009285\n",
            "iteration 10390 : loss : 0.027633, loss_ce: 0.010535\n",
            "iteration 10391 : loss : 0.026583, loss_ce: 0.008180\n",
            "iteration 10392 : loss : 0.026623, loss_ce: 0.007841\n",
            "iteration 10393 : loss : 0.018833, loss_ce: 0.005923\n",
            "iteration 10394 : loss : 0.023261, loss_ce: 0.008926\n",
            "iteration 10395 : loss : 0.026255, loss_ce: 0.011602\n",
            "iteration 10396 : loss : 0.026669, loss_ce: 0.012809\n",
            "iteration 10397 : loss : 0.025434, loss_ce: 0.008473\n",
            "iteration 10398 : loss : 0.036626, loss_ce: 0.008302\n",
            "iteration 10399 : loss : 0.024084, loss_ce: 0.006378\n",
            "iteration 10400 : loss : 0.023901, loss_ce: 0.007582\n",
            "iteration 10401 : loss : 0.031669, loss_ce: 0.008494\n",
            "iteration 10402 : loss : 0.023871, loss_ce: 0.007554\n",
            "iteration 10403 : loss : 0.025923, loss_ce: 0.007330\n",
            "iteration 10404 : loss : 0.028587, loss_ce: 0.008620\n",
            "iteration 10405 : loss : 0.021944, loss_ce: 0.007804\n",
            "iteration 10406 : loss : 0.024047, loss_ce: 0.006941\n",
            "iteration 10407 : loss : 0.027414, loss_ce: 0.009335\n",
            "iteration 10408 : loss : 0.025957, loss_ce: 0.008507\n",
            "iteration 10409 : loss : 0.025821, loss_ce: 0.011627\n",
            "iteration 10410 : loss : 0.023893, loss_ce: 0.007206\n",
            "iteration 10411 : loss : 0.023721, loss_ce: 0.008708\n",
            "iteration 10412 : loss : 0.026215, loss_ce: 0.004713\n",
            "iteration 10413 : loss : 0.023904, loss_ce: 0.008121\n",
            "iteration 10414 : loss : 0.022667, loss_ce: 0.008343\n",
            "iteration 10415 : loss : 0.021878, loss_ce: 0.007946\n",
            "iteration 10416 : loss : 0.020704, loss_ce: 0.007218\n",
            "iteration 10417 : loss : 0.023211, loss_ce: 0.009794\n",
            "iteration 10418 : loss : 0.024169, loss_ce: 0.009029\n",
            "iteration 10419 : loss : 0.025751, loss_ce: 0.008821\n",
            "iteration 10420 : loss : 0.020566, loss_ce: 0.008521\n",
            "iteration 10421 : loss : 0.043821, loss_ce: 0.005551\n",
            "iteration 10422 : loss : 0.025948, loss_ce: 0.010404\n",
            "iteration 10423 : loss : 0.026400, loss_ce: 0.007286\n",
            "iteration 10424 : loss : 0.022371, loss_ce: 0.008891\n",
            "iteration 10425 : loss : 0.023616, loss_ce: 0.008722\n",
            "iteration 10426 : loss : 0.021918, loss_ce: 0.008113\n",
            "iteration 10427 : loss : 0.024996, loss_ce: 0.009418\n",
            "iteration 10428 : loss : 0.021709, loss_ce: 0.007288\n",
            "iteration 10429 : loss : 0.025516, loss_ce: 0.004526\n",
            "iteration 10430 : loss : 0.025418, loss_ce: 0.012137\n",
            "iteration 10431 : loss : 0.074965, loss_ce: 0.005856\n",
            "iteration 10432 : loss : 0.021824, loss_ce: 0.006966\n",
            "iteration 10433 : loss : 0.027885, loss_ce: 0.012020\n",
            "iteration 10434 : loss : 0.022953, loss_ce: 0.007330\n",
            " 94%|██████████████████████████▎ | 141/150 [4:14:35<16:12, 108.08s/it]iteration 10435 : loss : 0.022376, loss_ce: 0.010249\n",
            "iteration 10436 : loss : 0.028625, loss_ce: 0.009686\n",
            "iteration 10437 : loss : 0.024334, loss_ce: 0.006773\n",
            "iteration 10438 : loss : 0.025145, loss_ce: 0.008764\n",
            "iteration 10439 : loss : 0.028990, loss_ce: 0.011521\n",
            "iteration 10440 : loss : 0.018697, loss_ce: 0.004896\n",
            "iteration 10441 : loss : 0.032567, loss_ce: 0.004574\n",
            "iteration 10442 : loss : 0.028018, loss_ce: 0.010330\n",
            "iteration 10443 : loss : 0.026034, loss_ce: 0.005941\n",
            "iteration 10444 : loss : 0.024603, loss_ce: 0.007947\n",
            "iteration 10445 : loss : 0.027254, loss_ce: 0.010035\n",
            "iteration 10446 : loss : 0.021680, loss_ce: 0.005893\n",
            "iteration 10447 : loss : 0.024017, loss_ce: 0.009682\n",
            "iteration 10448 : loss : 0.022770, loss_ce: 0.008794\n",
            "iteration 10449 : loss : 0.034218, loss_ce: 0.007699\n",
            "iteration 10450 : loss : 0.025344, loss_ce: 0.007471\n",
            "iteration 10451 : loss : 0.024174, loss_ce: 0.010355\n",
            "iteration 10452 : loss : 0.027573, loss_ce: 0.012702\n",
            "iteration 10453 : loss : 0.026261, loss_ce: 0.009523\n",
            "iteration 10454 : loss : 0.027045, loss_ce: 0.009211\n",
            "iteration 10455 : loss : 0.020744, loss_ce: 0.006928\n",
            "iteration 10456 : loss : 0.025027, loss_ce: 0.010853\n",
            "iteration 10457 : loss : 0.028270, loss_ce: 0.009786\n",
            "iteration 10458 : loss : 0.025915, loss_ce: 0.009979\n",
            "iteration 10459 : loss : 0.026784, loss_ce: 0.006792\n",
            "iteration 10460 : loss : 0.021767, loss_ce: 0.008829\n",
            "iteration 10461 : loss : 0.021699, loss_ce: 0.005261\n",
            "iteration 10462 : loss : 0.036907, loss_ce: 0.009144\n",
            "iteration 10463 : loss : 0.024563, loss_ce: 0.004946\n",
            "iteration 10464 : loss : 0.026874, loss_ce: 0.006578\n",
            "iteration 10465 : loss : 0.022691, loss_ce: 0.005704\n",
            "iteration 10466 : loss : 0.020973, loss_ce: 0.008824\n",
            "iteration 10467 : loss : 0.032761, loss_ce: 0.012306\n",
            "iteration 10468 : loss : 0.075050, loss_ce: 0.004879\n",
            "iteration 10469 : loss : 0.026797, loss_ce: 0.011998\n",
            "iteration 10470 : loss : 0.023562, loss_ce: 0.007908\n",
            "iteration 10471 : loss : 0.021323, loss_ce: 0.011456\n",
            "iteration 10472 : loss : 0.028558, loss_ce: 0.009066\n",
            "iteration 10473 : loss : 0.023628, loss_ce: 0.005595\n",
            "iteration 10474 : loss : 0.024039, loss_ce: 0.007478\n",
            "iteration 10475 : loss : 0.019979, loss_ce: 0.006830\n",
            "iteration 10476 : loss : 0.023355, loss_ce: 0.006457\n",
            "iteration 10477 : loss : 0.028132, loss_ce: 0.013391\n",
            "iteration 10478 : loss : 0.024628, loss_ce: 0.008241\n",
            "iteration 10479 : loss : 0.019386, loss_ce: 0.006515\n",
            "iteration 10480 : loss : 0.021413, loss_ce: 0.007492\n",
            "iteration 10481 : loss : 0.025545, loss_ce: 0.006374\n",
            "iteration 10482 : loss : 0.023278, loss_ce: 0.007496\n",
            "iteration 10483 : loss : 0.027429, loss_ce: 0.013199\n",
            "iteration 10484 : loss : 0.026808, loss_ce: 0.008704\n",
            "iteration 10485 : loss : 0.022792, loss_ce: 0.006636\n",
            "iteration 10486 : loss : 0.025110, loss_ce: 0.008020\n",
            "iteration 10487 : loss : 0.022929, loss_ce: 0.007818\n",
            "iteration 10488 : loss : 0.036085, loss_ce: 0.008457\n",
            "iteration 10489 : loss : 0.024714, loss_ce: 0.003957\n",
            "iteration 10490 : loss : 0.024658, loss_ce: 0.010694\n",
            "iteration 10491 : loss : 0.025874, loss_ce: 0.007826\n",
            "iteration 10492 : loss : 0.023608, loss_ce: 0.005191\n",
            "iteration 10493 : loss : 0.022832, loss_ce: 0.006565\n",
            "iteration 10494 : loss : 0.027229, loss_ce: 0.009089\n",
            "iteration 10495 : loss : 0.024887, loss_ce: 0.011869\n",
            "iteration 10496 : loss : 0.024174, loss_ce: 0.009724\n",
            "iteration 10497 : loss : 0.022462, loss_ce: 0.007078\n",
            "iteration 10498 : loss : 0.029050, loss_ce: 0.008735\n",
            "iteration 10499 : loss : 0.026750, loss_ce: 0.006478\n",
            "iteration 10500 : loss : 0.075948, loss_ce: 0.007007\n",
            "iteration 10501 : loss : 0.024082, loss_ce: 0.007687\n",
            "iteration 10502 : loss : 0.018610, loss_ce: 0.006163\n",
            "iteration 10503 : loss : 0.022870, loss_ce: 0.006903\n",
            "iteration 10504 : loss : 0.022704, loss_ce: 0.008680\n",
            "iteration 10505 : loss : 0.032688, loss_ce: 0.013216\n",
            "iteration 10506 : loss : 0.018814, loss_ce: 0.005862\n",
            "iteration 10507 : loss : 0.021842, loss_ce: 0.008871\n",
            "iteration 10508 : loss : 0.022542, loss_ce: 0.008700\n",
            " 95%|██████████████████████████▌ | 142/150 [4:16:24<14:26, 108.29s/it]iteration 10509 : loss : 0.029385, loss_ce: 0.007992\n",
            "iteration 10510 : loss : 0.031727, loss_ce: 0.009098\n",
            "iteration 10511 : loss : 0.025044, loss_ce: 0.005849\n",
            "iteration 10512 : loss : 0.072372, loss_ce: 0.004394\n",
            "iteration 10513 : loss : 0.024371, loss_ce: 0.009983\n",
            "iteration 10514 : loss : 0.022916, loss_ce: 0.004059\n",
            "iteration 10515 : loss : 0.023999, loss_ce: 0.006332\n",
            "iteration 10516 : loss : 0.021132, loss_ce: 0.007137\n",
            "iteration 10517 : loss : 0.022142, loss_ce: 0.005051\n",
            "iteration 10518 : loss : 0.024486, loss_ce: 0.009515\n",
            "iteration 10519 : loss : 0.023362, loss_ce: 0.010012\n",
            "iteration 10520 : loss : 0.025850, loss_ce: 0.008051\n",
            "iteration 10521 : loss : 0.027307, loss_ce: 0.008479\n",
            "iteration 10522 : loss : 0.022450, loss_ce: 0.007908\n",
            "iteration 10523 : loss : 0.024275, loss_ce: 0.007885\n",
            "iteration 10524 : loss : 0.027252, loss_ce: 0.009377\n",
            "iteration 10525 : loss : 0.080392, loss_ce: 0.005100\n",
            "iteration 10526 : loss : 0.025705, loss_ce: 0.007509\n",
            "iteration 10527 : loss : 0.026004, loss_ce: 0.009988\n",
            "iteration 10528 : loss : 0.018284, loss_ce: 0.004818\n",
            "iteration 10529 : loss : 0.019137, loss_ce: 0.006981\n",
            "iteration 10530 : loss : 0.026152, loss_ce: 0.010984\n",
            "iteration 10531 : loss : 0.026336, loss_ce: 0.009686\n",
            "iteration 10532 : loss : 0.075077, loss_ce: 0.006086\n",
            "iteration 10533 : loss : 0.027873, loss_ce: 0.011457\n",
            "iteration 10534 : loss : 0.021478, loss_ce: 0.006669\n",
            "iteration 10535 : loss : 0.025226, loss_ce: 0.008139\n",
            "iteration 10536 : loss : 0.025199, loss_ce: 0.009930\n",
            "iteration 10537 : loss : 0.024248, loss_ce: 0.008131\n",
            "iteration 10538 : loss : 0.021284, loss_ce: 0.003908\n",
            "iteration 10539 : loss : 0.026598, loss_ce: 0.011189\n",
            "iteration 10540 : loss : 0.025620, loss_ce: 0.006598\n",
            "iteration 10541 : loss : 0.023363, loss_ce: 0.011437\n",
            "iteration 10542 : loss : 0.026302, loss_ce: 0.007517\n",
            "iteration 10543 : loss : 0.023702, loss_ce: 0.008031\n",
            "iteration 10544 : loss : 0.022931, loss_ce: 0.009014\n",
            "iteration 10545 : loss : 0.027177, loss_ce: 0.009355\n",
            "iteration 10546 : loss : 0.026793, loss_ce: 0.010158\n",
            "iteration 10547 : loss : 0.024919, loss_ce: 0.008875\n",
            "iteration 10548 : loss : 0.024210, loss_ce: 0.007524\n",
            "iteration 10549 : loss : 0.025728, loss_ce: 0.009581\n",
            "iteration 10550 : loss : 0.022530, loss_ce: 0.008513\n",
            "iteration 10551 : loss : 0.023143, loss_ce: 0.008332\n",
            "iteration 10552 : loss : 0.023093, loss_ce: 0.007675\n",
            "iteration 10553 : loss : 0.021384, loss_ce: 0.008012\n",
            "iteration 10554 : loss : 0.025401, loss_ce: 0.007028\n",
            "iteration 10555 : loss : 0.024931, loss_ce: 0.004954\n",
            "iteration 10556 : loss : 0.023709, loss_ce: 0.007616\n",
            "iteration 10557 : loss : 0.024790, loss_ce: 0.011260\n",
            "iteration 10558 : loss : 0.023902, loss_ce: 0.008197\n",
            "iteration 10559 : loss : 0.024026, loss_ce: 0.005871\n",
            "iteration 10560 : loss : 0.025146, loss_ce: 0.011685\n",
            "iteration 10561 : loss : 0.025044, loss_ce: 0.008311\n",
            "iteration 10562 : loss : 0.057589, loss_ce: 0.006561\n",
            "iteration 10563 : loss : 0.024736, loss_ce: 0.011501\n",
            "iteration 10564 : loss : 0.029961, loss_ce: 0.007978\n",
            "iteration 10565 : loss : 0.023769, loss_ce: 0.010722\n",
            "iteration 10566 : loss : 0.022214, loss_ce: 0.009611\n",
            "iteration 10567 : loss : 0.023759, loss_ce: 0.008728\n",
            "iteration 10568 : loss : 0.075583, loss_ce: 0.007517\n",
            "iteration 10569 : loss : 0.024007, loss_ce: 0.007996\n",
            "iteration 10570 : loss : 0.020105, loss_ce: 0.008464\n",
            "iteration 10571 : loss : 0.020685, loss_ce: 0.006682\n",
            "iteration 10572 : loss : 0.028811, loss_ce: 0.015545\n",
            "iteration 10573 : loss : 0.028513, loss_ce: 0.012606\n",
            "iteration 10574 : loss : 0.022070, loss_ce: 0.006667\n",
            "iteration 10575 : loss : 0.022795, loss_ce: 0.005525\n",
            "iteration 10576 : loss : 0.022527, loss_ce: 0.005051\n",
            "iteration 10577 : loss : 0.020528, loss_ce: 0.006445\n",
            "iteration 10578 : loss : 0.021773, loss_ce: 0.008466\n",
            "iteration 10579 : loss : 0.024993, loss_ce: 0.011288\n",
            "iteration 10580 : loss : 0.023673, loss_ce: 0.008527\n",
            "iteration 10581 : loss : 0.023155, loss_ce: 0.008230\n",
            "iteration 10582 : loss : 0.021819, loss_ce: 0.010302\n",
            " 95%|██████████████████████████▋ | 143/150 [4:18:14<12:40, 108.62s/it]iteration 10583 : loss : 0.021259, loss_ce: 0.006394\n",
            "iteration 10584 : loss : 0.024362, loss_ce: 0.007824\n",
            "iteration 10585 : loss : 0.074919, loss_ce: 0.008902\n",
            "iteration 10586 : loss : 0.021710, loss_ce: 0.008633\n",
            "iteration 10587 : loss : 0.024742, loss_ce: 0.010632\n",
            "iteration 10588 : loss : 0.027102, loss_ce: 0.009556\n",
            "iteration 10589 : loss : 0.023525, loss_ce: 0.007736\n",
            "iteration 10590 : loss : 0.077300, loss_ce: 0.006902\n",
            "iteration 10591 : loss : 0.028709, loss_ce: 0.010483\n",
            "iteration 10592 : loss : 0.021416, loss_ce: 0.006683\n",
            "iteration 10593 : loss : 0.022701, loss_ce: 0.007941\n",
            "iteration 10594 : loss : 0.027328, loss_ce: 0.010527\n",
            "iteration 10595 : loss : 0.080373, loss_ce: 0.006725\n",
            "iteration 10596 : loss : 0.022126, loss_ce: 0.009403\n",
            "iteration 10597 : loss : 0.027947, loss_ce: 0.008051\n",
            "iteration 10598 : loss : 0.019785, loss_ce: 0.005662\n",
            "iteration 10599 : loss : 0.025136, loss_ce: 0.009813\n",
            "iteration 10600 : loss : 0.024068, loss_ce: 0.010119\n",
            "iteration 10601 : loss : 0.026069, loss_ce: 0.012022\n",
            "iteration 10602 : loss : 0.022608, loss_ce: 0.008727\n",
            "iteration 10603 : loss : 0.026270, loss_ce: 0.007492\n",
            "iteration 10604 : loss : 0.025540, loss_ce: 0.008760\n",
            "iteration 10605 : loss : 0.024143, loss_ce: 0.007916\n",
            "iteration 10606 : loss : 0.022620, loss_ce: 0.007082\n",
            "iteration 10607 : loss : 0.078539, loss_ce: 0.004764\n",
            "iteration 10608 : loss : 0.025611, loss_ce: 0.009359\n",
            "iteration 10609 : loss : 0.023868, loss_ce: 0.006564\n",
            "iteration 10610 : loss : 0.128420, loss_ce: 0.005689\n",
            "iteration 10611 : loss : 0.025482, loss_ce: 0.012703\n",
            "iteration 10612 : loss : 0.076576, loss_ce: 0.010698\n",
            "iteration 10613 : loss : 0.023411, loss_ce: 0.008256\n",
            "iteration 10614 : loss : 0.025159, loss_ce: 0.009351\n",
            "iteration 10615 : loss : 0.020353, loss_ce: 0.009016\n",
            "iteration 10616 : loss : 0.075924, loss_ce: 0.006402\n",
            "iteration 10617 : loss : 0.026419, loss_ce: 0.010496\n",
            "iteration 10618 : loss : 0.025675, loss_ce: 0.009857\n",
            "iteration 10619 : loss : 0.023891, loss_ce: 0.008076\n",
            "iteration 10620 : loss : 0.028129, loss_ce: 0.007426\n",
            "iteration 10621 : loss : 0.024335, loss_ce: 0.008029\n",
            "iteration 10622 : loss : 0.024748, loss_ce: 0.008250\n",
            "iteration 10623 : loss : 0.024627, loss_ce: 0.008633\n",
            "iteration 10624 : loss : 0.025724, loss_ce: 0.005000\n",
            "iteration 10625 : loss : 0.024570, loss_ce: 0.006322\n",
            "iteration 10626 : loss : 0.024324, loss_ce: 0.009044\n",
            "iteration 10627 : loss : 0.022225, loss_ce: 0.009325\n",
            "iteration 10628 : loss : 0.023106, loss_ce: 0.009851\n",
            "iteration 10629 : loss : 0.020256, loss_ce: 0.007734\n",
            "iteration 10630 : loss : 0.024497, loss_ce: 0.008304\n",
            "iteration 10631 : loss : 0.032496, loss_ce: 0.007492\n",
            "iteration 10632 : loss : 0.024270, loss_ce: 0.005163\n",
            "iteration 10633 : loss : 0.020751, loss_ce: 0.003629\n",
            "iteration 10634 : loss : 0.025236, loss_ce: 0.012031\n",
            "iteration 10635 : loss : 0.024695, loss_ce: 0.010157\n",
            "iteration 10636 : loss : 0.024694, loss_ce: 0.009134\n",
            "iteration 10637 : loss : 0.019843, loss_ce: 0.007563\n",
            "iteration 10638 : loss : 0.029120, loss_ce: 0.010327\n",
            "iteration 10639 : loss : 0.025284, loss_ce: 0.009663\n",
            "iteration 10640 : loss : 0.022988, loss_ce: 0.007573\n",
            "iteration 10641 : loss : 0.025536, loss_ce: 0.006659\n",
            "iteration 10642 : loss : 0.023463, loss_ce: 0.008375\n",
            "iteration 10643 : loss : 0.026374, loss_ce: 0.008921\n",
            "iteration 10644 : loss : 0.039060, loss_ce: 0.009258\n",
            "iteration 10645 : loss : 0.024457, loss_ce: 0.008806\n",
            "iteration 10646 : loss : 0.021729, loss_ce: 0.008870\n",
            "iteration 10647 : loss : 0.022448, loss_ce: 0.008309\n",
            "iteration 10648 : loss : 0.027084, loss_ce: 0.007665\n",
            "iteration 10649 : loss : 0.025111, loss_ce: 0.008286\n",
            "iteration 10650 : loss : 0.021151, loss_ce: 0.005896\n",
            "iteration 10651 : loss : 0.074395, loss_ce: 0.005701\n",
            "iteration 10652 : loss : 0.021742, loss_ce: 0.009019\n",
            "iteration 10653 : loss : 0.021831, loss_ce: 0.007358\n",
            "iteration 10654 : loss : 0.025601, loss_ce: 0.008877\n",
            "iteration 10655 : loss : 0.025840, loss_ce: 0.006213\n",
            "iteration 10656 : loss : 0.023794, loss_ce: 0.006247\n",
            " 96%|██████████████████████████▉ | 144/150 [4:20:02<10:50, 108.43s/it]iteration 10657 : loss : 0.023365, loss_ce: 0.008048\n",
            "iteration 10658 : loss : 0.020162, loss_ce: 0.007226\n",
            "iteration 10659 : loss : 0.019734, loss_ce: 0.005663\n",
            "iteration 10660 : loss : 0.020190, loss_ce: 0.006505\n",
            "iteration 10661 : loss : 0.020629, loss_ce: 0.007082\n",
            "iteration 10662 : loss : 0.023358, loss_ce: 0.008297\n",
            "iteration 10663 : loss : 0.022545, loss_ce: 0.008151\n",
            "iteration 10664 : loss : 0.020948, loss_ce: 0.008649\n",
            "iteration 10665 : loss : 0.024805, loss_ce: 0.007076\n",
            "iteration 10666 : loss : 0.021265, loss_ce: 0.007844\n",
            "iteration 10667 : loss : 0.019438, loss_ce: 0.008448\n",
            "iteration 10668 : loss : 0.023157, loss_ce: 0.007785\n",
            "iteration 10669 : loss : 0.026250, loss_ce: 0.008021\n",
            "iteration 10670 : loss : 0.021992, loss_ce: 0.008502\n",
            "iteration 10671 : loss : 0.023619, loss_ce: 0.007104\n",
            "iteration 10672 : loss : 0.027544, loss_ce: 0.012672\n",
            "iteration 10673 : loss : 0.024356, loss_ce: 0.012299\n",
            "iteration 10674 : loss : 0.024250, loss_ce: 0.009121\n",
            "iteration 10675 : loss : 0.022529, loss_ce: 0.007595\n",
            "iteration 10676 : loss : 0.018683, loss_ce: 0.003210\n",
            "iteration 10677 : loss : 0.075813, loss_ce: 0.008014\n",
            "iteration 10678 : loss : 0.076727, loss_ce: 0.007488\n",
            "iteration 10679 : loss : 0.028718, loss_ce: 0.010583\n",
            "iteration 10680 : loss : 0.023465, loss_ce: 0.010311\n",
            "iteration 10681 : loss : 0.026171, loss_ce: 0.008797\n",
            "iteration 10682 : loss : 0.075665, loss_ce: 0.006960\n",
            "iteration 10683 : loss : 0.023534, loss_ce: 0.011388\n",
            "iteration 10684 : loss : 0.025775, loss_ce: 0.011522\n",
            "iteration 10685 : loss : 0.024040, loss_ce: 0.006088\n",
            "iteration 10686 : loss : 0.027348, loss_ce: 0.006014\n",
            "iteration 10687 : loss : 0.021471, loss_ce: 0.007327\n",
            "iteration 10688 : loss : 0.020330, loss_ce: 0.007798\n",
            "iteration 10689 : loss : 0.028911, loss_ce: 0.007531\n",
            "iteration 10690 : loss : 0.023589, loss_ce: 0.008002\n",
            "iteration 10691 : loss : 0.025030, loss_ce: 0.010418\n",
            "iteration 10692 : loss : 0.023061, loss_ce: 0.007314\n",
            "iteration 10693 : loss : 0.024498, loss_ce: 0.008060\n",
            "iteration 10694 : loss : 0.026679, loss_ce: 0.013615\n",
            "iteration 10695 : loss : 0.025149, loss_ce: 0.007200\n",
            "iteration 10696 : loss : 0.025107, loss_ce: 0.010898\n",
            "iteration 10697 : loss : 0.075863, loss_ce: 0.008387\n",
            "iteration 10698 : loss : 0.020307, loss_ce: 0.009399\n",
            "iteration 10699 : loss : 0.025186, loss_ce: 0.004847\n",
            "iteration 10700 : loss : 0.021756, loss_ce: 0.006100\n",
            "iteration 10701 : loss : 0.026668, loss_ce: 0.009208\n",
            "iteration 10702 : loss : 0.025661, loss_ce: 0.009376\n",
            "iteration 10703 : loss : 0.023428, loss_ce: 0.007635\n",
            "iteration 10704 : loss : 0.025755, loss_ce: 0.007901\n",
            "iteration 10705 : loss : 0.024467, loss_ce: 0.008763\n",
            "iteration 10706 : loss : 0.027836, loss_ce: 0.016190\n",
            "iteration 10707 : loss : 0.022474, loss_ce: 0.007075\n",
            "iteration 10708 : loss : 0.072911, loss_ce: 0.004742\n",
            "iteration 10709 : loss : 0.023756, loss_ce: 0.008791\n",
            "iteration 10710 : loss : 0.027996, loss_ce: 0.006670\n",
            "iteration 10711 : loss : 0.023552, loss_ce: 0.007938\n",
            "iteration 10712 : loss : 0.027058, loss_ce: 0.012176\n",
            "iteration 10713 : loss : 0.021387, loss_ce: 0.009187\n",
            "iteration 10714 : loss : 0.024594, loss_ce: 0.007997\n",
            "iteration 10715 : loss : 0.028801, loss_ce: 0.010649\n",
            "iteration 10716 : loss : 0.024078, loss_ce: 0.008006\n",
            "iteration 10717 : loss : 0.022161, loss_ce: 0.008871\n",
            "iteration 10718 : loss : 0.023659, loss_ce: 0.010387\n",
            "iteration 10719 : loss : 0.025709, loss_ce: 0.008596\n",
            "iteration 10720 : loss : 0.025785, loss_ce: 0.007445\n",
            "iteration 10721 : loss : 0.027871, loss_ce: 0.007537\n",
            "iteration 10722 : loss : 0.028683, loss_ce: 0.006260\n",
            "iteration 10723 : loss : 0.029500, loss_ce: 0.009978\n",
            "iteration 10724 : loss : 0.026209, loss_ce: 0.010496\n",
            "iteration 10725 : loss : 0.024007, loss_ce: 0.004568\n",
            "iteration 10726 : loss : 0.023885, loss_ce: 0.006912\n",
            "iteration 10727 : loss : 0.020317, loss_ce: 0.006508\n",
            "iteration 10728 : loss : 0.025493, loss_ce: 0.007673\n",
            "iteration 10729 : loss : 0.077537, loss_ce: 0.006322\n",
            "iteration 10730 : loss : 0.122584, loss_ce: 0.004061\n",
            " 97%|███████████████████████████ | 145/150 [4:21:49<09:01, 108.23s/it]iteration 10731 : loss : 0.024088, loss_ce: 0.009845\n",
            "iteration 10732 : loss : 0.023965, loss_ce: 0.009817\n",
            "iteration 10733 : loss : 0.024603, loss_ce: 0.008471\n",
            "iteration 10734 : loss : 0.122194, loss_ce: 0.003016\n",
            "iteration 10735 : loss : 0.026760, loss_ce: 0.011961\n",
            "iteration 10736 : loss : 0.023116, loss_ce: 0.006839\n",
            "iteration 10737 : loss : 0.022185, loss_ce: 0.006450\n",
            "iteration 10738 : loss : 0.025193, loss_ce: 0.010487\n",
            "iteration 10739 : loss : 0.024806, loss_ce: 0.006456\n",
            "iteration 10740 : loss : 0.023369, loss_ce: 0.008079\n",
            "iteration 10741 : loss : 0.032020, loss_ce: 0.008644\n",
            "iteration 10742 : loss : 0.026721, loss_ce: 0.013016\n",
            "iteration 10743 : loss : 0.025223, loss_ce: 0.008189\n",
            "iteration 10744 : loss : 0.077480, loss_ce: 0.006956\n",
            "iteration 10745 : loss : 0.025860, loss_ce: 0.009031\n",
            "iteration 10746 : loss : 0.027877, loss_ce: 0.006886\n",
            "iteration 10747 : loss : 0.023006, loss_ce: 0.007537\n",
            "iteration 10748 : loss : 0.023260, loss_ce: 0.006750\n",
            "iteration 10749 : loss : 0.020920, loss_ce: 0.004685\n",
            "iteration 10750 : loss : 0.023415, loss_ce: 0.005567\n",
            "iteration 10751 : loss : 0.022568, loss_ce: 0.008596\n",
            "iteration 10752 : loss : 0.024881, loss_ce: 0.006882\n",
            "iteration 10753 : loss : 0.030803, loss_ce: 0.007322\n",
            "iteration 10754 : loss : 0.024448, loss_ce: 0.007602\n",
            "iteration 10755 : loss : 0.023965, loss_ce: 0.008786\n",
            "iteration 10756 : loss : 0.025695, loss_ce: 0.008133\n",
            "iteration 10757 : loss : 0.020924, loss_ce: 0.008654\n",
            "iteration 10758 : loss : 0.024598, loss_ce: 0.009430\n",
            "iteration 10759 : loss : 0.025868, loss_ce: 0.009509\n",
            "iteration 10760 : loss : 0.022671, loss_ce: 0.009032\n",
            "iteration 10761 : loss : 0.021508, loss_ce: 0.006664\n",
            "iteration 10762 : loss : 0.022282, loss_ce: 0.004814\n",
            "iteration 10763 : loss : 0.030222, loss_ce: 0.007946\n",
            "iteration 10764 : loss : 0.023693, loss_ce: 0.005524\n",
            "iteration 10765 : loss : 0.025812, loss_ce: 0.008312\n",
            "iteration 10766 : loss : 0.040147, loss_ce: 0.005723\n",
            "iteration 10767 : loss : 0.024145, loss_ce: 0.006303\n",
            "iteration 10768 : loss : 0.026014, loss_ce: 0.011552\n",
            "iteration 10769 : loss : 0.024521, loss_ce: 0.009298\n",
            "iteration 10770 : loss : 0.027145, loss_ce: 0.015085\n",
            "iteration 10771 : loss : 0.073426, loss_ce: 0.005339\n",
            "iteration 10772 : loss : 0.122696, loss_ce: 0.003976\n",
            "iteration 10773 : loss : 0.077089, loss_ce: 0.009860\n",
            "iteration 10774 : loss : 0.022917, loss_ce: 0.008267\n",
            "iteration 10775 : loss : 0.031674, loss_ce: 0.008772\n",
            "iteration 10776 : loss : 0.023597, loss_ce: 0.010682\n",
            "iteration 10777 : loss : 0.024329, loss_ce: 0.008069\n",
            "iteration 10778 : loss : 0.021584, loss_ce: 0.008114\n",
            "iteration 10779 : loss : 0.027373, loss_ce: 0.010241\n",
            "iteration 10780 : loss : 0.025240, loss_ce: 0.007696\n",
            "iteration 10781 : loss : 0.025879, loss_ce: 0.010687\n",
            "iteration 10782 : loss : 0.022598, loss_ce: 0.007069\n",
            "iteration 10783 : loss : 0.021584, loss_ce: 0.003937\n",
            "iteration 10784 : loss : 0.068990, loss_ce: 0.004746\n",
            "iteration 10785 : loss : 0.022608, loss_ce: 0.007925\n",
            "iteration 10786 : loss : 0.025657, loss_ce: 0.009938\n",
            "iteration 10787 : loss : 0.018424, loss_ce: 0.006749\n",
            "iteration 10788 : loss : 0.023608, loss_ce: 0.008802\n",
            "iteration 10789 : loss : 0.027765, loss_ce: 0.009097\n",
            "iteration 10790 : loss : 0.024082, loss_ce: 0.008050\n",
            "iteration 10791 : loss : 0.021725, loss_ce: 0.008175\n",
            "iteration 10792 : loss : 0.077312, loss_ce: 0.008020\n",
            "iteration 10793 : loss : 0.022639, loss_ce: 0.007061\n",
            "iteration 10794 : loss : 0.023418, loss_ce: 0.008692\n",
            "iteration 10795 : loss : 0.024603, loss_ce: 0.012239\n",
            "iteration 10796 : loss : 0.023108, loss_ce: 0.007181\n",
            "iteration 10797 : loss : 0.030005, loss_ce: 0.012752\n",
            "iteration 10798 : loss : 0.024754, loss_ce: 0.010955\n",
            "iteration 10799 : loss : 0.025692, loss_ce: 0.010224\n",
            "iteration 10800 : loss : 0.074468, loss_ce: 0.005893\n",
            "iteration 10801 : loss : 0.025025, loss_ce: 0.012765\n",
            "iteration 10802 : loss : 0.025817, loss_ce: 0.011551\n",
            "iteration 10803 : loss : 0.026574, loss_ce: 0.008983\n",
            "iteration 10804 : loss : 0.076453, loss_ce: 0.005307\n",
            " 97%|███████████████████████████▎| 146/150 [4:23:38<07:13, 108.36s/it]iteration 10805 : loss : 0.020435, loss_ce: 0.005051\n",
            "iteration 10806 : loss : 0.028245, loss_ce: 0.009836\n",
            "iteration 10807 : loss : 0.028164, loss_ce: 0.011747\n",
            "iteration 10808 : loss : 0.027811, loss_ce: 0.011252\n",
            "iteration 10809 : loss : 0.022045, loss_ce: 0.008090\n",
            "iteration 10810 : loss : 0.018569, loss_ce: 0.006573\n",
            "iteration 10811 : loss : 0.022843, loss_ce: 0.007528\n",
            "iteration 10812 : loss : 0.022172, loss_ce: 0.007382\n",
            "iteration 10813 : loss : 0.022321, loss_ce: 0.004510\n",
            "iteration 10814 : loss : 0.020487, loss_ce: 0.005335\n",
            "iteration 10815 : loss : 0.022038, loss_ce: 0.005739\n",
            "iteration 10816 : loss : 0.025999, loss_ce: 0.015847\n",
            "iteration 10817 : loss : 0.022827, loss_ce: 0.009020\n",
            "iteration 10818 : loss : 0.026107, loss_ce: 0.006022\n",
            "iteration 10819 : loss : 0.021344, loss_ce: 0.007708\n",
            "iteration 10820 : loss : 0.025759, loss_ce: 0.012098\n",
            "iteration 10821 : loss : 0.023884, loss_ce: 0.007444\n",
            "iteration 10822 : loss : 0.028548, loss_ce: 0.012469\n",
            "iteration 10823 : loss : 0.025843, loss_ce: 0.010721\n",
            "iteration 10824 : loss : 0.025704, loss_ce: 0.006958\n",
            "iteration 10825 : loss : 0.078527, loss_ce: 0.007877\n",
            "iteration 10826 : loss : 0.021792, loss_ce: 0.007566\n",
            "iteration 10827 : loss : 0.020029, loss_ce: 0.006297\n",
            "iteration 10828 : loss : 0.021963, loss_ce: 0.005966\n",
            "iteration 10829 : loss : 0.022044, loss_ce: 0.004688\n",
            "iteration 10830 : loss : 0.024908, loss_ce: 0.005632\n",
            "iteration 10831 : loss : 0.025706, loss_ce: 0.007400\n",
            "iteration 10832 : loss : 0.025681, loss_ce: 0.009123\n",
            "iteration 10833 : loss : 0.021664, loss_ce: 0.005657\n",
            "iteration 10834 : loss : 0.023450, loss_ce: 0.012183\n",
            "iteration 10835 : loss : 0.027939, loss_ce: 0.013660\n",
            "iteration 10836 : loss : 0.024853, loss_ce: 0.010063\n",
            "iteration 10837 : loss : 0.077166, loss_ce: 0.009373\n",
            "iteration 10838 : loss : 0.025666, loss_ce: 0.005592\n",
            "iteration 10839 : loss : 0.019701, loss_ce: 0.009196\n",
            "iteration 10840 : loss : 0.026331, loss_ce: 0.010881\n",
            "iteration 10841 : loss : 0.025444, loss_ce: 0.011950\n",
            "iteration 10842 : loss : 0.022163, loss_ce: 0.008187\n",
            "iteration 10843 : loss : 0.023688, loss_ce: 0.009499\n",
            "iteration 10844 : loss : 0.019929, loss_ce: 0.004770\n",
            "iteration 10845 : loss : 0.077172, loss_ce: 0.007116\n",
            "iteration 10846 : loss : 0.028086, loss_ce: 0.005579\n",
            "iteration 10847 : loss : 0.025575, loss_ce: 0.007677\n",
            "iteration 10848 : loss : 0.022934, loss_ce: 0.007860\n",
            "iteration 10849 : loss : 0.028735, loss_ce: 0.007437\n",
            "iteration 10850 : loss : 0.022428, loss_ce: 0.004526\n",
            "iteration 10851 : loss : 0.020154, loss_ce: 0.008213\n",
            "iteration 10852 : loss : 0.034630, loss_ce: 0.008047\n",
            "iteration 10853 : loss : 0.019853, loss_ce: 0.005069\n",
            "iteration 10854 : loss : 0.021444, loss_ce: 0.008384\n",
            "iteration 10855 : loss : 0.027087, loss_ce: 0.010799\n",
            "iteration 10856 : loss : 0.024354, loss_ce: 0.008106\n",
            "iteration 10857 : loss : 0.019793, loss_ce: 0.005954\n",
            "iteration 10858 : loss : 0.023529, loss_ce: 0.010327\n",
            "iteration 10859 : loss : 0.024268, loss_ce: 0.009468\n",
            "iteration 10860 : loss : 0.027593, loss_ce: 0.009733\n",
            "iteration 10861 : loss : 0.024448, loss_ce: 0.008043\n",
            "iteration 10862 : loss : 0.022457, loss_ce: 0.007717\n",
            "iteration 10863 : loss : 0.076778, loss_ce: 0.005861\n",
            "iteration 10864 : loss : 0.025192, loss_ce: 0.007817\n",
            "iteration 10865 : loss : 0.024143, loss_ce: 0.010405\n",
            "iteration 10866 : loss : 0.027446, loss_ce: 0.012796\n",
            "iteration 10867 : loss : 0.025169, loss_ce: 0.009027\n",
            "iteration 10868 : loss : 0.022169, loss_ce: 0.005177\n",
            "iteration 10869 : loss : 0.022076, loss_ce: 0.006480\n",
            "iteration 10870 : loss : 0.024585, loss_ce: 0.009413\n",
            "iteration 10871 : loss : 0.024682, loss_ce: 0.009365\n",
            "iteration 10872 : loss : 0.027162, loss_ce: 0.010199\n",
            "iteration 10873 : loss : 0.023612, loss_ce: 0.009229\n",
            "iteration 10874 : loss : 0.024068, loss_ce: 0.009431\n",
            "iteration 10875 : loss : 0.020968, loss_ce: 0.003465\n",
            "iteration 10876 : loss : 0.076898, loss_ce: 0.007633\n",
            "iteration 10877 : loss : 0.035407, loss_ce: 0.009261\n",
            "iteration 10878 : loss : 0.031513, loss_ce: 0.010507\n",
            " 98%|███████████████████████████▍| 147/150 [4:25:28<05:26, 108.78s/it]iteration 10879 : loss : 0.029870, loss_ce: 0.008680\n",
            "iteration 10880 : loss : 0.024105, loss_ce: 0.005203\n",
            "iteration 10881 : loss : 0.022534, loss_ce: 0.006771\n",
            "iteration 10882 : loss : 0.030457, loss_ce: 0.009058\n",
            "iteration 10883 : loss : 0.022041, loss_ce: 0.008361\n",
            "iteration 10884 : loss : 0.022170, loss_ce: 0.004327\n",
            "iteration 10885 : loss : 0.030943, loss_ce: 0.009556\n",
            "iteration 10886 : loss : 0.023494, loss_ce: 0.006710\n",
            "iteration 10887 : loss : 0.025782, loss_ce: 0.011439\n",
            "iteration 10888 : loss : 0.025825, loss_ce: 0.006345\n",
            "iteration 10889 : loss : 0.022992, loss_ce: 0.006700\n",
            "iteration 10890 : loss : 0.023273, loss_ce: 0.010990\n",
            "iteration 10891 : loss : 0.021729, loss_ce: 0.007483\n",
            "iteration 10892 : loss : 0.027074, loss_ce: 0.010712\n",
            "iteration 10893 : loss : 0.020445, loss_ce: 0.006613\n",
            "iteration 10894 : loss : 0.021331, loss_ce: 0.005624\n",
            "iteration 10895 : loss : 0.021931, loss_ce: 0.008809\n",
            "iteration 10896 : loss : 0.025113, loss_ce: 0.006094\n",
            "iteration 10897 : loss : 0.027682, loss_ce: 0.010421\n",
            "iteration 10898 : loss : 0.024706, loss_ce: 0.010321\n",
            "iteration 10899 : loss : 0.021296, loss_ce: 0.011070\n",
            "iteration 10900 : loss : 0.026237, loss_ce: 0.010458\n",
            "iteration 10901 : loss : 0.025285, loss_ce: 0.009009\n",
            "iteration 10902 : loss : 0.020724, loss_ce: 0.005836\n",
            "iteration 10903 : loss : 0.023416, loss_ce: 0.008969\n",
            "iteration 10904 : loss : 0.024294, loss_ce: 0.009697\n",
            "iteration 10905 : loss : 0.020474, loss_ce: 0.009907\n",
            "iteration 10906 : loss : 0.076087, loss_ce: 0.006553\n",
            "iteration 10907 : loss : 0.026028, loss_ce: 0.008979\n",
            "iteration 10908 : loss : 0.022532, loss_ce: 0.010006\n",
            "iteration 10909 : loss : 0.023622, loss_ce: 0.008692\n",
            "iteration 10910 : loss : 0.022414, loss_ce: 0.008904\n",
            "iteration 10911 : loss : 0.023057, loss_ce: 0.007807\n",
            "iteration 10912 : loss : 0.020519, loss_ce: 0.006607\n",
            "iteration 10913 : loss : 0.024613, loss_ce: 0.004579\n",
            "iteration 10914 : loss : 0.024756, loss_ce: 0.012040\n",
            "iteration 10915 : loss : 0.024048, loss_ce: 0.008041\n",
            "iteration 10916 : loss : 0.021666, loss_ce: 0.006848\n",
            "iteration 10917 : loss : 0.022344, loss_ce: 0.007915\n",
            "iteration 10918 : loss : 0.026766, loss_ce: 0.008318\n",
            "iteration 10919 : loss : 0.022524, loss_ce: 0.007661\n",
            "iteration 10920 : loss : 0.022902, loss_ce: 0.009742\n",
            "iteration 10921 : loss : 0.033100, loss_ce: 0.009853\n",
            "iteration 10922 : loss : 0.023884, loss_ce: 0.009038\n",
            "iteration 10923 : loss : 0.021743, loss_ce: 0.006138\n",
            "iteration 10924 : loss : 0.024174, loss_ce: 0.011349\n",
            "iteration 10925 : loss : 0.024223, loss_ce: 0.006970\n",
            "iteration 10926 : loss : 0.024840, loss_ce: 0.010481\n",
            "iteration 10927 : loss : 0.023028, loss_ce: 0.008688\n",
            "iteration 10928 : loss : 0.027452, loss_ce: 0.009334\n",
            "iteration 10929 : loss : 0.025737, loss_ce: 0.006916\n",
            "iteration 10930 : loss : 0.024461, loss_ce: 0.010187\n",
            "iteration 10931 : loss : 0.072347, loss_ce: 0.005198\n",
            "iteration 10932 : loss : 0.076061, loss_ce: 0.005439\n",
            "iteration 10933 : loss : 0.023622, loss_ce: 0.008836\n",
            "iteration 10934 : loss : 0.029904, loss_ce: 0.009523\n",
            "iteration 10935 : loss : 0.076521, loss_ce: 0.004803\n",
            "iteration 10936 : loss : 0.022273, loss_ce: 0.008922\n",
            "iteration 10937 : loss : 0.021519, loss_ce: 0.006293\n",
            "iteration 10938 : loss : 0.018667, loss_ce: 0.005772\n",
            "iteration 10939 : loss : 0.019609, loss_ce: 0.006399\n",
            "iteration 10940 : loss : 0.025637, loss_ce: 0.009951\n",
            "iteration 10941 : loss : 0.075444, loss_ce: 0.008051\n",
            "iteration 10942 : loss : 0.025561, loss_ce: 0.008701\n",
            "iteration 10943 : loss : 0.024508, loss_ce: 0.008728\n",
            "iteration 10944 : loss : 0.026727, loss_ce: 0.012801\n",
            "iteration 10945 : loss : 0.022437, loss_ce: 0.009406\n",
            "iteration 10946 : loss : 0.022320, loss_ce: 0.005283\n",
            "iteration 10947 : loss : 0.029147, loss_ce: 0.010902\n",
            "iteration 10948 : loss : 0.026662, loss_ce: 0.007836\n",
            "iteration 10949 : loss : 0.020342, loss_ce: 0.007830\n",
            "iteration 10950 : loss : 0.024997, loss_ce: 0.006514\n",
            "iteration 10951 : loss : 0.024686, loss_ce: 0.007998\n",
            "iteration 10952 : loss : 0.020889, loss_ce: 0.007889\n",
            " 99%|███████████████████████████▋| 148/150 [4:27:16<03:37, 108.61s/it]iteration 10953 : loss : 0.023592, loss_ce: 0.009499\n",
            "iteration 10954 : loss : 0.023029, loss_ce: 0.007628\n",
            "iteration 10955 : loss : 0.023345, loss_ce: 0.008105\n",
            "iteration 10956 : loss : 0.028261, loss_ce: 0.010136\n",
            "iteration 10957 : loss : 0.027932, loss_ce: 0.006015\n",
            "iteration 10958 : loss : 0.025014, loss_ce: 0.009407\n",
            "iteration 10959 : loss : 0.075321, loss_ce: 0.007396\n",
            "iteration 10960 : loss : 0.022402, loss_ce: 0.008313\n",
            "iteration 10961 : loss : 0.022606, loss_ce: 0.007913\n",
            "iteration 10962 : loss : 0.026485, loss_ce: 0.009756\n",
            "iteration 10963 : loss : 0.027482, loss_ce: 0.007025\n",
            "iteration 10964 : loss : 0.027682, loss_ce: 0.012443\n",
            "iteration 10965 : loss : 0.021665, loss_ce: 0.006870\n",
            "iteration 10966 : loss : 0.022560, loss_ce: 0.006603\n",
            "iteration 10967 : loss : 0.024221, loss_ce: 0.008830\n",
            "iteration 10968 : loss : 0.026112, loss_ce: 0.011649\n",
            "iteration 10969 : loss : 0.023664, loss_ce: 0.010904\n",
            "iteration 10970 : loss : 0.018651, loss_ce: 0.006441\n",
            "iteration 10971 : loss : 0.024235, loss_ce: 0.011392\n",
            "iteration 10972 : loss : 0.021712, loss_ce: 0.007605\n",
            "iteration 10973 : loss : 0.025369, loss_ce: 0.008812\n",
            "iteration 10974 : loss : 0.021725, loss_ce: 0.006398\n",
            "iteration 10975 : loss : 0.027880, loss_ce: 0.008849\n",
            "iteration 10976 : loss : 0.023958, loss_ce: 0.011122\n",
            "iteration 10977 : loss : 0.026697, loss_ce: 0.011799\n",
            "iteration 10978 : loss : 0.022235, loss_ce: 0.006467\n",
            "iteration 10979 : loss : 0.022000, loss_ce: 0.006891\n",
            "iteration 10980 : loss : 0.077608, loss_ce: 0.009402\n",
            "iteration 10981 : loss : 0.022175, loss_ce: 0.008911\n",
            "iteration 10982 : loss : 0.026808, loss_ce: 0.006551\n",
            "iteration 10983 : loss : 0.020103, loss_ce: 0.007441\n",
            "iteration 10984 : loss : 0.021506, loss_ce: 0.006375\n",
            "iteration 10985 : loss : 0.021191, loss_ce: 0.007520\n",
            "iteration 10986 : loss : 0.029576, loss_ce: 0.007217\n",
            "iteration 10987 : loss : 0.024851, loss_ce: 0.009091\n",
            "iteration 10988 : loss : 0.025492, loss_ce: 0.008555\n",
            "iteration 10989 : loss : 0.020579, loss_ce: 0.007263\n",
            "iteration 10990 : loss : 0.024754, loss_ce: 0.009691\n",
            "iteration 10991 : loss : 0.024928, loss_ce: 0.008223\n",
            "iteration 10992 : loss : 0.021266, loss_ce: 0.007862\n",
            "iteration 10993 : loss : 0.023412, loss_ce: 0.008506\n",
            "iteration 10994 : loss : 0.075663, loss_ce: 0.003910\n",
            "iteration 10995 : loss : 0.023074, loss_ce: 0.005793\n",
            "iteration 10996 : loss : 0.024546, loss_ce: 0.010243\n",
            "iteration 10997 : loss : 0.073011, loss_ce: 0.004837\n",
            "iteration 10998 : loss : 0.022937, loss_ce: 0.007803\n",
            "iteration 10999 : loss : 0.025469, loss_ce: 0.010220\n",
            "iteration 11000 : loss : 0.023720, loss_ce: 0.009163\n",
            "iteration 11001 : loss : 0.021501, loss_ce: 0.008146\n",
            "iteration 11002 : loss : 0.023221, loss_ce: 0.008922\n",
            "iteration 11003 : loss : 0.021526, loss_ce: 0.003555\n",
            "iteration 11004 : loss : 0.022945, loss_ce: 0.007230\n",
            "iteration 11005 : loss : 0.020820, loss_ce: 0.009240\n",
            "iteration 11006 : loss : 0.075823, loss_ce: 0.004535\n",
            "iteration 11007 : loss : 0.074454, loss_ce: 0.006387\n",
            "iteration 11008 : loss : 0.025341, loss_ce: 0.012000\n",
            "iteration 11009 : loss : 0.076349, loss_ce: 0.006603\n",
            "iteration 11010 : loss : 0.022966, loss_ce: 0.007658\n",
            "iteration 11011 : loss : 0.029227, loss_ce: 0.007538\n",
            "iteration 11012 : loss : 0.028286, loss_ce: 0.012187\n",
            "iteration 11013 : loss : 0.022689, loss_ce: 0.006819\n",
            "iteration 11014 : loss : 0.024210, loss_ce: 0.007763\n",
            "iteration 11015 : loss : 0.025646, loss_ce: 0.009344\n",
            "iteration 11016 : loss : 0.022979, loss_ce: 0.009027\n",
            "iteration 11017 : loss : 0.022754, loss_ce: 0.004295\n",
            "iteration 11018 : loss : 0.024960, loss_ce: 0.009858\n",
            "iteration 11019 : loss : 0.027606, loss_ce: 0.010565\n",
            "iteration 11020 : loss : 0.021530, loss_ce: 0.006774\n",
            "iteration 11021 : loss : 0.022045, loss_ce: 0.006900\n",
            "iteration 11022 : loss : 0.023008, loss_ce: 0.007711\n",
            "iteration 11023 : loss : 0.021788, loss_ce: 0.008304\n",
            "iteration 11024 : loss : 0.075756, loss_ce: 0.007523\n",
            "iteration 11025 : loss : 0.075875, loss_ce: 0.007764\n",
            "iteration 11026 : loss : 0.026615, loss_ce: 0.010573\n",
            " 99%|███████████████████████████▊| 149/150 [4:29:03<01:48, 108.23s/it]iteration 11027 : loss : 0.022620, loss_ce: 0.009098\n",
            "iteration 11028 : loss : 0.036330, loss_ce: 0.006678\n",
            "iteration 11029 : loss : 0.023779, loss_ce: 0.007748\n",
            "iteration 11030 : loss : 0.030708, loss_ce: 0.013620\n",
            "iteration 11031 : loss : 0.027942, loss_ce: 0.006261\n",
            "iteration 11032 : loss : 0.021157, loss_ce: 0.006784\n",
            "iteration 11033 : loss : 0.023243, loss_ce: 0.007602\n",
            "iteration 11034 : loss : 0.019099, loss_ce: 0.003792\n",
            "iteration 11035 : loss : 0.024939, loss_ce: 0.008569\n",
            "iteration 11036 : loss : 0.023203, loss_ce: 0.008890\n",
            "iteration 11037 : loss : 0.026030, loss_ce: 0.011684\n",
            "iteration 11038 : loss : 0.079778, loss_ce: 0.006920\n",
            "iteration 11039 : loss : 0.025266, loss_ce: 0.006716\n",
            "iteration 11040 : loss : 0.026077, loss_ce: 0.008191\n",
            "iteration 11041 : loss : 0.022158, loss_ce: 0.008062\n",
            "iteration 11042 : loss : 0.021185, loss_ce: 0.007771\n",
            "iteration 11043 : loss : 0.025362, loss_ce: 0.008822\n",
            "iteration 11044 : loss : 0.022947, loss_ce: 0.008507\n",
            "iteration 11045 : loss : 0.024903, loss_ce: 0.009982\n",
            "iteration 11046 : loss : 0.023045, loss_ce: 0.009326\n",
            "iteration 11047 : loss : 0.038528, loss_ce: 0.009014\n",
            "iteration 11048 : loss : 0.023622, loss_ce: 0.008031\n",
            "iteration 11049 : loss : 0.026467, loss_ce: 0.005833\n",
            "iteration 11050 : loss : 0.025473, loss_ce: 0.004573\n",
            "iteration 11051 : loss : 0.023001, loss_ce: 0.008779\n",
            "iteration 11052 : loss : 0.026547, loss_ce: 0.010484\n",
            "iteration 11053 : loss : 0.075236, loss_ce: 0.008470\n",
            "iteration 11054 : loss : 0.077404, loss_ce: 0.010041\n",
            "iteration 11055 : loss : 0.021601, loss_ce: 0.009543\n",
            "iteration 11056 : loss : 0.020964, loss_ce: 0.007111\n",
            "iteration 11057 : loss : 0.024302, loss_ce: 0.008815\n",
            "iteration 11058 : loss : 0.022057, loss_ce: 0.006285\n",
            "iteration 11059 : loss : 0.024166, loss_ce: 0.009224\n",
            "iteration 11060 : loss : 0.021715, loss_ce: 0.008525\n",
            "iteration 11061 : loss : 0.025577, loss_ce: 0.012107\n",
            "iteration 11062 : loss : 0.025239, loss_ce: 0.009711\n",
            "iteration 11063 : loss : 0.023863, loss_ce: 0.006662\n",
            "iteration 11064 : loss : 0.023738, loss_ce: 0.008922\n",
            "iteration 11065 : loss : 0.024556, loss_ce: 0.007206\n",
            "iteration 11066 : loss : 0.026137, loss_ce: 0.007393\n",
            "iteration 11067 : loss : 0.022300, loss_ce: 0.007112\n",
            "iteration 11068 : loss : 0.020782, loss_ce: 0.005316\n",
            "iteration 11069 : loss : 0.029901, loss_ce: 0.006378\n",
            "iteration 11070 : loss : 0.025093, loss_ce: 0.010060\n",
            "iteration 11071 : loss : 0.022463, loss_ce: 0.007673\n",
            "iteration 11072 : loss : 0.077040, loss_ce: 0.009201\n",
            "iteration 11073 : loss : 0.023895, loss_ce: 0.008207\n",
            "iteration 11074 : loss : 0.022131, loss_ce: 0.008259\n",
            "iteration 11075 : loss : 0.022390, loss_ce: 0.005910\n",
            "iteration 11076 : loss : 0.026778, loss_ce: 0.007879\n",
            "iteration 11077 : loss : 0.022449, loss_ce: 0.008277\n",
            "iteration 11078 : loss : 0.019250, loss_ce: 0.006933\n",
            "iteration 11079 : loss : 0.024322, loss_ce: 0.010135\n",
            "iteration 11080 : loss : 0.022302, loss_ce: 0.007240\n",
            "iteration 11081 : loss : 0.020048, loss_ce: 0.005451\n",
            "iteration 11082 : loss : 0.020866, loss_ce: 0.005823\n",
            "iteration 11083 : loss : 0.023343, loss_ce: 0.005992\n",
            "iteration 11084 : loss : 0.024176, loss_ce: 0.009456\n",
            "iteration 11085 : loss : 0.025747, loss_ce: 0.012577\n",
            "iteration 11086 : loss : 0.023872, loss_ce: 0.004264\n",
            "iteration 11087 : loss : 0.021483, loss_ce: 0.007390\n",
            "iteration 11088 : loss : 0.022438, loss_ce: 0.009061\n",
            "iteration 11089 : loss : 0.073698, loss_ce: 0.006287\n",
            "iteration 11090 : loss : 0.019468, loss_ce: 0.004975\n",
            "iteration 11091 : loss : 0.023953, loss_ce: 0.009321\n",
            "iteration 11092 : loss : 0.027268, loss_ce: 0.009705\n",
            "iteration 11093 : loss : 0.030788, loss_ce: 0.013724\n",
            "iteration 11094 : loss : 0.024111, loss_ce: 0.010224\n",
            "iteration 11095 : loss : 0.024080, loss_ce: 0.009065\n",
            "iteration 11096 : loss : 0.025657, loss_ce: 0.009566\n",
            "iteration 11097 : loss : 0.029750, loss_ce: 0.012202\n",
            "iteration 11098 : loss : 0.023437, loss_ce: 0.008025\n",
            "iteration 11099 : loss : 0.026557, loss_ce: 0.009209\n",
            "iteration 11100 : loss : 0.026775, loss_ce: 0.008227\n",
            "save model to /content/project_TransUNet/project_TransUNet/model/TU_Synapse224/TU_pretrain_R50-ViT-B_16_skip3_epo150_bs24_224/epoch_149.pth\n",
            "save model to /content/project_TransUNet/project_TransUNet/model/TU_Synapse224/TU_pretrain_R50-ViT-B_16_skip3_epo150_bs24_224/epoch_149.pth\n",
            " 99%|███████████████████████████▊| 149/150 [4:30:53<01:49, 109.09s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --dataset Synapse --vit_name R50-ViT-B_16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgdQma4wmbk0",
        "outputId": "1e7593df-c859-4824-c947-5e936444fa6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/test.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Path to your project folder\n",
        "project_path = \"/content/project_TransUNet\"\n",
        "\n",
        "# Create a zip archive\n",
        "shutil.make_archive(\"/content/project_TransUNet_modified\", 'zip', project_path)\n",
        "\n",
        "# Download it\n",
        "files.download(\"/content/project_TransUNet_modified.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "y-yM6JAI0Dub",
        "outputId": "ea95e150-e8b2-452d-8144-b53156094223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1b21f856-9d50-49bb-900b-3750767c98ef\", \"project_TransUNet_modified.zip\", 1781081701)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}